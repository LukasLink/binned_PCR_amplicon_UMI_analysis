---
title: "comparing_results"
author: "Lukas"
date: "2025-12-04"
output: html_document
---

```{r setup, include=FALSE}
print(.libPaths())
knitr::opts_chunk$set(echo = FALSE)
options(bitmapType="cairo")
library(tidyverse)
library(Matrix)
library(conflicted)
library(MAUDE)
library(ggplot2)
library(optparse)
library(ggrepel)
library(writexl)
library(stringr)

conflicts_prefer(dplyr::rename)
conflicts_prefer(dplyr::filter)
conflicts_prefer(dplyr::select)
conflicts_prefer(dplyr::slice)

# Find a specific file by walking up parent directories
find_up_file <- function(start_dir, filename, max_up = 15) {
  d <- normalizePath(start_dir, mustWork = TRUE)

  for (i in 0:max_up) {
    candidate <- file.path(d, filename)
    if (file.exists(candidate)) return(candidate)

    parent <- dirname(d)
    if (identical(parent, d)) break
    d <- parent
  }

  stop("Could not find '", filename, "' searching upward from: ", start_dir)
}

# Now we find the location of the RMD file we are running
# (Either data_analysis_with_MAUDE.rmd or compare_results.rmd)
rmd_path <- Sys.getenv("SOURCE_RMD", unset = "")
start_dir <- if (nzchar(rmd_path) && file.exists(rmd_path)) {
  dirname(normalizePath(rmd_path, mustWork = TRUE))
} else {
  getwd()
}

# 1) If we are running from compare_results.rmd, we need to find the root_dir
anchor_rmd <- find_up_file(start_dir, "data_analysis_with_MAUDE.Rmd", max_up = 1)

# 2) The anchor's directory is the project root that contains /functions
project_root_dir <- dirname(anchor_rmd)

# 3) Source functions from there
source(file.path(project_root_dir, "functions", "zzz_source_all.R"))

#===============================================================================
# User Options (can be overrided via CLI)
#===============================================================================
# first_time will save all intermediary results, if FALSE will try to load them
first_time      <- FALSE

# Directories
# Mandatory output_folder
# output_folder   <- "/g/steinmetz/link/Amplicon_barcode_analysis/HepG2_dual_rep_PA_subsample/subsample_10"
output_folder   <- "/g/steinmetz/link/Amplicon_barcode_analysis/HepG2_dual_rep_GALNAC"
# output_folder   <- "/g/steinmetz/link/Amplicon_barcode_analysis/Liangfu_iBeer_2/David_January"
#optional folders for results from johns bcwithqc
john_rf_folder  <- "/g/steinmetz/link/Amplicon_barcode_analysis/NB_EXP030/john_read_filt"
john_folder <- ""
# If any files are to be skipped list their names here

skip_list <- c() # individual files, example: c("I_L3_5", "U_L1_2")
skip_list_sublib <- c() # entire sublibraries, example: c("L4","L5")
skip_list_sample <- c() # entire sample numbers, example c("1", "24")
# Warning: skipping entire sublibraries and sample numbers does not work for
# non numeric samples, or samples >9999

# Extra target list
# If any of the controls should be considered targeting (example EGFP and AAVS1)
# Nico HepG2 screen
include_controls_list <- c("EGFP","AAVS1_9", "AAVS1_13", "AAVS1_18", "AAVS1_19", "AAVS1_25", "AAVS1_35")
# include_controls_list <- c()
# Only Specific controls
# Liangfu wants only these controls to be used:
# Liangfu iBeer Screen
if (FALSE){
  include_controls_list <- c()
  use_only_these_controls_path <- "/g/steinmetz/link/Amplicon_barcode_analysis/Liangfu_iBeer_2/Liangfu_Non_targeting_sgRNA_list_Genomewide_Daniel Lib.csv"
  use_only_these_controls_list <- read.csv(use_only_these_controls_path, header = FALSE, stringsAsFactors = FALSE)$V1
} else {
  if (exists("use_only_these_controls_list")) {
    rm(use_only_these_controls_list)
  }
} 
# Set Options for pipline function
pipeline            <- "lukas"  # can be "john", "john_rf" or "lukas" use john for CellRanger and bcwithqc proccessed data.
data_type           <- "reads"   # can be "reads" or "umis"
method              <- ""    # can be "rep", "rep_sample", "rep_sublib", or "" 
norm_method         <- "control_median"       # can be "control_median" or ""
recover_input       <- TRUE     # bolean estimates missing input data
subsample_controls  <- FALSE     # bolean keeps 10% of control sgRNAs for reference.
use_custom_fraction <- FALSE    # bolean to use custom bin fractions. 
combine_for_guide_stats     <- "sample" # can be "", "sample", or "sublib".
combine_for_gene_stats <- "none" # can be "none", "all", "sample", or "sublib"


# Set Fractions for the upper and lower bins
upper_lower_percentage <- 0.10  # Fraction of the lower&upper bin 0.10 = 10%
                                # The Rest is used and removed by MAUDE for normalization.

# Custom suffix and optional simplified read filtering
extra_suffix  <- ""   # custom sufix, special behaviour when set to "rf"
                      # if extra_suffix is set to "rf" it applies simplified read filtering,  
                      # which removes all reads below simplified_rf_threshold
                      # "cf" does the same only for control guides
simplified_rf_threshold <- 2000 # threshold for simplified filtering
simplified_cf_threshold <- 2000 # threshold for simplified filtering

# Are all the non-targeting control sgRNAS the same in all sublibraries/replicates?
same_controls_in_all_sublibraries <- TRUE

# Remove rows without any data 
drop_0s <- FALSE  # bolean removes all guides with no UMIs/reads
strict_mode <- FALSE # bolean, removes all guides which don't have UMIs for all bins. 
min_guides_per_gene <- 0 # Minimum number of guides required to detect a gene, per replicate not total
auto_combine_replicates <- FALSE # automatically combines replicas

#===============================================================================
# Define command-line options
#===============================================================================
option_list <- list(
  make_option(c("--first_time"), type = "logical", default = first_time,
              help = "First run flag, will save files (default: TRUE)", metavar = "LOGICAL"),
  make_option(c("--output_folder"), type = "character", default = output_folder,
              help = "Output folder (default: '/g/steinmetz/link/Amplicon_barcode_analysis/NB_EXP030')", 
              metavar = "PATH"),
  make_option(c("--john_folder"), type = "character", default = john_folder,
              help = "John folder (default: '/g/steinmetz/link/Amplicon_barcode_analysis/NB_EXP030/john/')", 
              metavar = "PATH"),
  make_option(c("--john_rf_folder"), type = "character", default = john_rf_folder,
              help = "John RF folder (default: '/g/steinmetz/link/Amplicon_barcode_analysis/NB_EXP030/john_read_filt')", 
              metavar = "PATH"),
  make_option(c("--skip_list"), type = "character", default = paste(skip_list, collapse = ","),
              help = "If any files are to be skipped list their names here (comma-separated) (default: '')", 
              metavar = "LIST"),
  make_option(c("--skip_list_sublib"), type = "character", default = paste(skip_list_sublib, collapse = ","),
              help = "If any sublibraries are to be skipped list their names here (comma-separated) (default: '')", 
              metavar = "LIST"),
  make_option(c("--skip_list_sample"), type = "character", default = paste(skip_list_sample, collapse = ","),
              help = "If any samples are to be skipped list their names here (comma-separated) (default: '')", 
              metavar = "LIST"),
  make_option(c("--pipeline"), type = "character", default = pipeline, 
              help = "Pipeline name (default: 'lukas')", metavar = "CHARACTER"),
  make_option(c("--data_type"), type = "character", default = data_type, 
              help = "Data type (default: 'umis')", metavar = "CHARACTER"),
  make_option(c("--method"), type = "character", default = method, 
              help = "Method (default: '')", metavar = "CHARACTER"),
  make_option(c("--norm_method"), type = "character", default = norm_method, 
              help = "Normalization method (default: '')", metavar = "CHARACTER"),
  make_option(c("--recover_input"), type = "logical", default = recover_input, 
              help = "Recover missing input (default: TRUE)", metavar = "LOGICAL"),
  make_option(c("--subsample_controls"), type = "logical", default = subsample_controls, 
              help = "Subsample control guides so some appear in the results (default: TRUE)", metavar = "LOGICAL"),
  make_option(c("--same_controls_in_all_sublibraries"), type = "logical", default = same_controls_in_all_sublibraries, 
              help = "Set to FALSE if the individual sublibraries/replicates have different control sgRNAs (default: TRUE)", metavar = "LOGICAL"),
  make_option(c("--extra_suffix"), type = "character", default = extra_suffix, 
              help = "Suffix for additional options (default: '')", metavar = "CHARACTER"),
  make_option(c("--simplified_rf_threshold"), type = "integer", default = simplified_rf_threshold,
              help = "Threshold for simplified filtering (default: 1000)", metavar = "INTEGER"),
  make_option(c("--upper_lower_percentage"), type = "double", default = upper_lower_percentage,
              help = "Fraction of the lower&upper bin (default: 0.10)", metavar = "DOUBLE"),
  make_option(c("--drop_0s"), type = "logical", default = drop_0s, 
              help = "Drop rows where input, upper, and lower are all 0 (default: TRUE)", metavar = "LOGICAL")
)

#===============================================================================
# Parse the command-line arguments
#===============================================================================
opt_parser <- OptionParser(option_list = option_list)
opt <- parse_args(opt_parser)

#===============================================================================
# Override the defaults with CLI values
#===============================================================================
first_time                        <- opt$first_time
output_folder                     <- opt$output_folder
john_folder                       <- opt$john_folder
john_rf_folder                    <- opt$john_rf_folder
skip_list                         <- strsplit(opt$skip_list, ",")[[1]]
skip_list_sublib                  <- strsplit(opt$skip_list_sublib, ",")[[1]]
skip_list_sample                  <- strsplit(opt$skip_list_sample, ",")[[1]]
pipeline                          <- opt$pipeline
data_type                         <- opt$data_type
method                            <- opt$method
norm_method                       <- opt$norm_method
recover_input                     <- opt$recover_input
subsample_controls                <- opt$subsample_controls
same_controls_in_all_sublibraries <- opt$same_controls_in_all_sublibraries
extra_suffix                      <- opt$extra_suffix
simplified_rf_threshold           <- opt$simplified_rf_threshold
upper_lower_percentage            <- opt$upper_lower_percentage
drop_0s                           <- opt$drop_0s

#===============================================================================
# Print the options (for verification)
#===============================================================================
cat("first_time:                        ", first_time, "\n")
cat("output_folder:                     ", output_folder, "\n")
cat("john_folder:                       ", john_folder, "\n")
cat("john_rf_folder:                    ", john_rf_folder, "\n")
cat("skip_list:                         ", paste(skip_list, collapse = ", "), "\n")
cat("skip_list_sublib:                  ", paste(skip_list_sublib, collapse = ", "), "\n")
cat("skip_list_sample:                  ", paste(skip_list_sample, collapse = ", "), "\n")
cat("pipeline:                          ", pipeline, "\n")
cat("data_type:                         ", data_type, "\n")
cat("method:                            ", method, "\n")
cat("norm_method:                       ", norm_method, "\n")
cat("recover_input:                     ", recover_input, "\n")
cat("subsample_controls:                ", subsample_controls, "\n")
cat("same_controls_in_all_sublibraries: ", same_controls_in_all_sublibraries, "\n")
cat("extra_suffix:                      ", extra_suffix, "\n")
cat("simplified_rf_threshold:           ", simplified_rf_threshold, "\n")
cat("upper_lower_percentage:            ", upper_lower_percentage, "\n")
cat("strict_mode:                       ", strict_mode, "\n")
cat("min_guides_per_gene:               ", min_guides_per_gene, "\n")
cat("drop_0s:                           ", drop_0s, "\n")


#===============================================================================
# Condition for adding "RI" and "D0"
#===============================================================================

if (recover_input) {
  recover_input_suffix <- "RI"
} else {
  recover_input_suffix <- ""
}

if (drop_0s) {
  drop_0s_suffix <- "D0"
} else {
  drop_0s_suffix <- ""
}
if (strict_mode) {
  strict_mode_suffix <- "strict"
} else {
  strict_mode_suffix <- ""
}
if (auto_combine_replicates){
  auto_combine_replicates_suffix <- "acr"
} else {
  auto_combine_replicates_suffix <- ""
}
if (min_guides_per_gene > 0){
  min_guides_per_gene_suffix <- min_guides_per_gene
} else {
  min_guides_per_gene_suffix <- ""
}
if (combine_for_guide_stats == ""){
  combine_for_guide_stats_suffix <- ""
} else {
  combine_for_guide_stats_suffix <- paste0("comb_", combine_for_guide_stats)
}
#===============================================================================
# Construct the skip list
#===============================================================================

skip_list_and_suffix <- create_skip_list_and_suffix(skip_list,
                                                    skip_list_sublib,
                                                    skip_list_sample)
skip_list <- skip_list_and_suffix[[1]]
skip_suffix <- skip_list_and_suffix[[2]]

#===============================================================================
# Construct the file suffix
#===============================================================================
fs_parts <- c(pipeline,
           data_type,
           method,
           norm_method,
           recover_input_suffix,
           drop_0s_suffix,
           strict_mode_suffix,
           min_guides_per_gene_suffix,
           combine_for_guide_stats_suffix,
           auto_combine_replicates_suffix,
           skip_suffix,
           extra_suffix)

# keep only non-empty parts
fs_parts <- fs_parts[fs_parts != ""]

file_suffix <- paste0("_", paste(fs_parts, collapse = "_"), ".rds")

fi_parts <- c(pipeline,
              data_type,
              method,
              norm_method,
              recover_input_suffix,
              drop_0s_suffix,
              strict_mode_suffix,
              min_guides_per_gene_suffix,
              combine_for_guide_stats_suffix,
              auto_combine_replicates_suffix,
              skip_suffix,
              extra_suffix)

# keep only non-empty parts
fi_parts <- fi_parts[fi_parts != ""]

file_info_suffix <- paste(fi_parts, collapse = "_")

# Print the final file suffix
cat("File Suffix: ", file_suffix, "\n")

#===============================================================================
# Construct File Paths
#===============================================================================



data_dir <- get_file_path(project_root_dir,"data")
genome_output_folder <- make_clean_dir(output_folder, "/ref/")
dedup_output_folder <- make_clean_dir(output_folder, "/dedup/")
mapped_output_folder <- make_clean_dir(output_folder, "/mapped/")
rds_output_folder <- make_clean_dir(output_folder, "/rds/")
results_output_folder <- make_clean_dir(output_folder, "/results/")

merged_sgRNA_df <- readRDS(get_file_path(rds_output_folder,
                                         "merged_sgRNA_df.rds"))

```

``` {r load_comparision_specific_libs, eval=TRUE}
library(VennDiagram)
library(grid)
library(gridExtra)
```
# The following codeblock exists to do some basic familiarization with MAUDE,
and to troubleshoot it if things fail. You can ignore it.  
```{r make_example_df, eval=FALSE}
if (FALSE){
  getAnywhere(findGuideHitsAllScreens)
  getAnywhere(getElementwiseStats)
  getAnywhere(findGuideHits)
  getAnywhere(getZScalesWithNTGuides())
  getAnywhere(optim())
}


# Create the data for maude
maude_example_df_1 <- data.frame(sgRNA = c(LETTERS[1:6], "CONTROL_C_NONTARG_G", "CONTROL_C_NONTARG_H", "CONTROL_C_I", "CONTROL_C_J"),
                               input = c(4.1, 3, 5, 3, 8, 7, 5, 6, 7, 5),
                               upper = c(1, 9, 5, 0, 4, 2, 0, 1, 3, 2),
                               lower = c(4, 4, 1, 1, 3, 1, 0, 2, 2, 1),
                               sublib = "sublib_1")
maude_example_df_2 <- maude_example_df_1 %>%
  mutate(input = input + 1,
         upper = upper + 1,
         lower = lower + 1,
         exp = 'rep1',
         isNontargeting = case_when(str_detect(sgRNA, "^CONTROL_C_NONTARG_") ~ FALSE, # Anything else → FALSE
                                    str_detect(sgRNA, "^CONTROL_C_") ~ TRUE, # CONTROL_C_X → TRUE
                                    TRUE ~ FALSE # Anything else → FALSE) %>%
                                    )
  )

# Define bin stats with 10% for lower/upper each
lower_bin_end = 0.1
upper_bin_start = 1 - 0.1

maude_example_bins <- tibble(
  Bin = rep(c("upper", "lower"), length(unique(maude_example_df_2[["exp"]]))),  # Repeat 'upper' and 'lower' for each exp
  exp = rep(unique(maude_example_df_2[["exp"]]), each = 2),  # Repeat each exp value twice
  binStartQ = ifelse(rep(c("upper", "lower"), length(unique(maude_example_df_2[["exp"]]))) == "lower", 0.001, upper_bin_start),
  binEndQ = ifelse(rep(c("upper", "lower"), length(unique(maude_example_df_2[["exp"]]))) == "lower", lower_bin_end, 0.999),
  fraction = binEndQ - binStartQ,
  binStartZ = qnorm(binStartQ),
  binEndZ = qnorm(binEndQ)
) %>%
  select(Bin, binStartQ, binEndQ, fraction, binStartZ, binEndZ, exp) %>%
  as.data.frame()


maude_example_guide_stats <- findGuideHitsAllScreens(
  experiments = unique(maude_example_df_2['exp']),
  countDataFrame = maude_example_df_2,
  binStats = maude_example_bins,
  sortBins = c('lower', 'upper'),
  unsortedBin = 'input',
  negativeControl = 'isNontargeting'
)
```

## Generate the long format read/umi counts either from my pipline or from johns
Also provides information for each file about coverage and correct alignment

```{r get_count_df_long, eval=TRUE}
process_john_data_backup <- process_john_data
pseudocount_added <- FALSE

sink(get_file_path(rds_output_folder,paste0(file_info_suffix,"_coverage.txt")),
     split = TRUE) # capture output into a file

if (pipeline == "john"){
  count_df_long <- process_john_data(john_folder,
                                     data_type = data_type,
                                     merged_sgRNA_df = merged_sgRNA_df,
                                     skip_list = skip_list)
  if (extra_suffix == "rf"){
      count_df_long <- count_df_long %>% 
      mutate(count = ifelse(count < simplified_rf_threshold, 0, count))        
      }
} else {
  if (pipeline == "lukas"){
    if (data_type == "umis"){
      count_df_long <- process_folder_files(dedup_output_folder,
                                            skip_list = skip_list) #Add threshold df if thresholds should be applied 
    }
    if (data_type == "reads"){
      count_df_long <- process_folder_files(mapped_output_folder,
                                            skip_list = skip_list) #Add threshold df if thresholds should be applied 
      if (extra_suffix == "rf"){
        count_df_long <- count_df_long %>% 
        mutate(count = ifelse(count < simplified_rf_threshold, 0, count))        
      }

    }
       
  } else {
    if (pipeline == "john_rf"){
      count_df_long <- process_john_rf_data(john_rf_folder,
                                            data_type = data_type,
                                            merged_sgRNA_df = merged_sgRNA_df,
                                            skip_list = skip_list)
      
      process_john_data <- process_john_rf_data
      if (extra_suffix == "rf"){
        count_df_long <- count_df_long %>% 
        mutate(count = ifelse(count < simplified_rf_threshold, 0, count))        
      }
    } else {
      stop("Unsupported pipeline specified. Exiting. Pipline must be john, john_rf or lukas.")
    }
  }  
}
sink()
if (extra_suffix == "cf"){
  count_df_long <- count_df_long %>%
    filter(!(group != "targeting" & count < simplified_cf_threshold))
}

# Extend the include_controls_list if use_only_these_controls_list is given
if (exists("use_only_these_controls_list")) {
  if (length(use_only_these_controls_list) > 0){
    # list of sgRNAs that were not targeting (before) and not in allowed controls
    excluded_controls <- count_df_long %>%
      filter(group_category != "targeting", !sgRNA %in% use_only_these_controls_list) %>%
      distinct(sgRNA) %>%
      pull(sgRNA)
  
    include_controls_list <- c(include_controls_list, excluded_controls)
  }
}
if (length(include_controls_list) > 0){
  for (control_gene in include_controls_list){
    count_df_long$group_category[grepl(control_gene, count_df_long$sgRNA)] <- "targeting"
  }
}

```
```{r prepare_data_for_maude, eval=TRUE}
if (subsample_controls == TRUE){
  # count_df_long_old <- subsample_controls_func_old(count_df_long, merged_sgRNA_df)
  count_df_long <- subsample_controls_func(count_df_long, merged_sgRNA_df)
}

if (!(norm_method %in% c("","control_median"))){
  stop("Error: 'norm_method' must be one of '', 'control_median'. The script will now stop.")
}
if (norm_method == "control_median"){
  count_df_long <- normalize_count_df_long(count_df_long,
                                           norm_method = norm_method)
}


  
maude_counts_df <- count_df_long_to_wide(count_df_long = count_df_long,
                                         print = FALSE,
                                         drop_0s = drop_0s,
                                         recover_input = recover_input)
if (!(method %in% c("","rep","sum",'rep_sample','rep_sublib'))){
  stop("Error: 'method' must be one of '', 'rep', 'rep_sample', 'rep_sublib', or 'sum'. The script will now stop.")
}

if (method == ""){
  maude_counts_df <- maude_counts_df %>% 
    mutate(exp = "rep1")
}
if (method == "rep"){

}
if (method == "rep_sample"){
  maude_counts_df <- maude_counts_df %>%
    mutate(exp = sample)
}
if (method == "rep_sublib"){
  maude_counts_df <- maude_counts_df %>%
    mutate(exp = sublib)
}
if (method == "sum"){
  stop("Method 'sum' is deprecated, use the option combine_for_guide_stats instead")
  maude_counts_df <- count_df_long_to_wide(count_df_long = count_df_long,
                                         print = FALSE,
                                         drop_0s = drop_0s,
                                         recover_input = TRUE,
                                         for_sum = TRUE)
  # Group by sgRNA and summarize the required columns
  maude_counts_df <- maude_counts_df %>%
    group_by(sgRNA, sublib) %>%
    summarize(
      input = pmax(sum(input, na.rm = TRUE), 0),  # Sum and ensure minimum is 0
      upper = pmax(sum(upper, na.rm = TRUE), 0),  # Sum and ensure minimum is 0
      lower = pmax(sum(lower, na.rm = TRUE), 0),  # Sum and ensure minimum is 0
      isNontargeting = dplyr::first(isNontargeting),  # Take the first value of isNontargeting (same for all in the group)
      .groups = 'drop'  # Drop the group structure after summarizing
    ) %>%
    mutate(
      exp = "rep1",
      input = input + 1,
      upper = upper + 1,
      lower = lower + 1
    )
}

if (strict_mode){
  if (pseudocount_added){
    umi_threshold <- 2
  } else {
    umi_threshold <- 1
  } 
  cat("Strict Mode enabled\n")
  cat("Rows before strict mode: \t", nrow(maude_counts_df),"\n")
  maude_counts_df <- maude_counts_df %>%
    filter(if_any(c(input, upper, lower), ~ . <= umi_threshold))
  cat("Rows after strict mode: \t", nrow(maude_counts_df),"\n")
}
if (length(include_controls_list) > 0) {
  for (control_gene in include_controls_list) {
    maude_counts_df$isNontargeting[grepl(control_gene, maude_counts_df$sgRNA)] <- FALSE
  }
}
if (exists("use_only_these_controls_list")) {
  if (length(use_only_these_controls_list) > 0){
    maude_counts_df$isNontargeting[ !(maude_counts_df$sgRNA %in% use_only_these_controls_list) ] <- FALSE
  }
}
if (combine_for_guide_stats != ""){
  if (combine_for_guide_stats == "sample"){
    maude_counts_df <- maude_counts_df %>%
      group_by(sgRNA, sublib) %>%
      summarise(
        # set sample name for the combined rows
        sample = "sample_1",
        
        # add up integer count columns
        input = sum(input, na.rm = TRUE),
        lower = sum(lower, na.rm = TRUE),
        upper = sum(upper, na.rm = TRUE),
        
        # keep the first value for everything else
        exp = dplyr::first(exp),
        isNontargeting = dplyr::first(isNontargeting),
        
        # keep one sublib/sgRNA (also fine even though they're grouping keys)
        .groups = "drop"
      )
  }
  if (combine_for_guide_stats == "sublib"){
    maude_counts_df <- maude_counts_df %>%
      group_by(sgRNA, sample) %>%
      summarise(
        # set sample name for the combined rows
        sublib = "sublib_1",
        
        # add up integer count columns
        input = sum(input, na.rm = TRUE),
        lower = sum(lower, na.rm = TRUE),
        upper = sum(upper, na.rm = TRUE),
        
        # keep the first value for everything else
        exp = dplyr::first(exp),
        isNontargeting = dplyr::first(isNontargeting),
        
        # keep one sublib/sgRNA (also fine even though they're grouping keys)
        .groups = "drop"
      )    
  }
}  
```
## Some exploration options for the raw reads/umi counts
Mostly for comparing this pipeline to johns bcwithqc, ignore this. 
```{r basic_pipeline_comparision, eval=FALSE}
compare_john_lukas <- function(data_type,
                               john_function = process_john_data,
                               addage = "",
                               john_folder = john_folder,
                               lukas_umi_folder = dedup_output_folder,
                               lukas_read_folder = mapped_output_folder){

  if (!(data_type %in% c("umis","reads"))){
    print('ERROR: data_type must be "umis" or "reads"')
    return(NULL)
  }  
  
  if (addage != ""){
    addage <- paste0("(",addage,")")
  }
  
  john_df_long <- john_function(john_folder,sgRNA_df, data_type = data_type, merged_sgRNA_df = merged_sgRNA_df)
  if (data_type == "umis"){
    lukas_df_long <- process_folder_files(lukas_umi_folder) #Add threshold df if thresholds should be applied
    data_name <- "UMI"
  }
  if (data_type == "reads"){
    lukas_df_long <- process_folder_files(lukas_read_folder) #Add threshold df if thresholds should be applied
    data_name <- "Read"
  } 
  
  # Join the data frames on sgRNA and exp
  matched_df <- full_join(john_df_long, lukas_df_long, by = c("sgRNA", "condition","sublib","sample","group_category","exp"), suffix = c("_john", "_lukas")) %>%
    mutate(
      # Replace missing counts with 0
      count_john = ifelse(is.na(count_john), 0, count_john),
      count_lukas = ifelse(is.na(count_lukas), 0, count_lukas),
      
      # Fill in missing 'other' columns from available one
      # Example: if there’s another column like 'condition' or 'replicate'
      # replicate = coalesce(replicate_john, replicate_lukas)
      # (Uncomment and adapt as needed!)
    )

  # Compute the difference in count
  matched_df <- matched_df %>%
    mutate(diff = count_john - count_lukas)
  
  # Total difference
  total_diff <- sum(matched_df$diff)
  
  # Mean difference
  mean_diff <- mean(matched_df$diff)
  
  # Standard deviation
  sd_diff <- sd(matched_df$diff)
  
  
  
  # Print results
  cat("Total",data_name, addage, "Difference:", total_diff, "\n")
  cat("Mean",data_name, addage, "Difference:", mean_diff, "\n")
  cat(data_name, addage, "Standard Deviation:", sd_diff, "\n")
  


  total_df <- tibble(
    source = c("John", "Lukas"),
    total_count = c(sum(matched_df$count_john), sum(matched_df$count_lukas))
  )
  
  p <- ggplot(total_df, aes(x = source, y = total_count, fill = source)) +
    geom_bar(stat = "identity", width = 0.6) +
    geom_text(aes(label = total_count), vjust = -0.5) +
    labs(
      title = paste("Total",data_name, addage,"Counts"),
      x = "",
      y = paste("Total",data_name, addage,"Counts")
    ) +
    theme_minimal() +
    theme(legend.position = "none")
  print(p)
  
  nonzero_df <- tibble(
    source = c("John", "Lukas", "Max"),
    nonzero_count = c(sum(matched_df$count_john > 0), sum(matched_df$count_lukas > 0), nrow(matched_df))
  )
  
  p <- ggplot(nonzero_df, aes(x = source, y = nonzero_count, fill = source)) +
    geom_bar(stat = "identity", width = 0.6) +
    geom_text(aes(label = nonzero_count), vjust = -0.5) +
    labs(
      title = paste("Coverage of",data_name, addage,"Counts"),
      x = "",
      y = paste("Coverage of",data_name, addage,"Counts")
    ) +
    theme_minimal() +
    theme(legend.position = "none")
  print(p)
  
  # Assuming you've matched the two runs: count_john vs count_lukas
  p <- ggplot(matched_df, aes(x = count_john + 1, y = count_lukas + 1)) +
    geom_count(alpha = 0.7) +
    geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
    scale_size_area(max_size = 4) +  # optional: adjust max size
    scale_x_log10() + scale_y_log10() +
    labs(
      title = paste("Comparison of sgRNA", data_name, addage, "Counts"),
      x = paste("John", data_name, addage, "Counts"),
      y = paste("Lukas", data_name, addage, "Counts"),
      size = "Count overlap"
    ) +
    theme_minimal()
  print(p)
  # Histogram
  p <- ggplot(matched_df, aes(x = diff)) +
    geom_histogram(bins = 50, fill = "steelblue", color = "white") +
    labs(title = paste("Distribution of",data_name, addage, "Count Differences (John - Lukas)"),
         x = paste(data_name, addage,"Count Difference"),
         y = "Frequency") +
    xlim(-1000, 1000) +
    theme_minimal()
  print(p)
  # Compute the 2.5th and 97.5th percentiles (95% interval)
  x_limits <- quantile(matched_df$diff, probs = c(0.025, 0.975), na.rm = TRUE)
  
  # Plot with limited x-axis
  p <- ggplot(matched_df, aes(x = diff)) +
    geom_density(fill = "skyblue", alpha = 0.5) +
    coord_cartesian(xlim = x_limits) +  # Zoom in without removing data
    labs(title = paste("Density of",data_name, addage, "Count Differences (95% Range)"),
         x = "John - Lukas") +
    theme_minimal()
  print(p)
  x_limits <- quantile(matched_df$diff, probs = c(0.005, 0.995), na.rm = TRUE)
  
  # Plot with limited x-axis
  p <- ggplot(matched_df, aes(x = diff)) +
    geom_density(fill = "skyblue", alpha = 0.5) +
    coord_cartesian(xlim = x_limits) +  # Zoom in without removing data
    labs(title = paste("Density of",data_name, addage, "Count Differences (99% Range)"),
         x = "John - Lukas") +
    theme_minimal()
  print(p)
  matched_df <- matched_df %>%
    mutate(
      average = (count_john + count_lukas) / 2,
      diff = count_john - count_lukas
    )
  
  p <- ggplot(matched_df, aes(x = average, y = diff)) +
    geom_point(alpha = 0.5) +
    geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
    labs(title = paste("Bland–Altman Plot for",data_name, addage,"Counts"),
         x = paste("Average", data_name, addage, "Count"),
         y = "Difference (John - Lukas)") +
    theme_minimal()
  print(p)
  return(matched_df)
}
compare_john_lukas("reads",
                   john_function = process_john_data_backup)
compare_john_lukas("umis",
                   john_function = process_john_rf_data,
                   john_folder = john_rf_folder)
compare_john_lukas("umis",
                   lukas_umi_folder = "/g/steinmetz/link/Amplicon_barcode_analysis/NB_EXP030/dedup_no_filt/",
                   john_function = process_john_data_backup,
                   addage = "#NoFilter")

# Rank each row by count within each exp and condition group
count_ranked <- count_df_long %>%
  group_by(exp, condition) %>%
  arrange(desc(count), .by_group = TRUE) %>%
  mutate(rank = row_number())

ggplot(count_ranked, aes(x = rank, y = count, color = condition)) +
  geom_line() +
  facet_wrap(~exp, scales = "free_y") +  # if you want separate panels per experiment
  labs(title = "Ranked Counts per exp/condition",
       x = "Rank",
       y = "Count") +
  scale_y_log10() +
  scale_x_log10() +
  theme_minimal()
```

## Functions that add more information to the results, like the gene symbol

```{r check_MAUDE_results, eval=TRUE}

```

## Create QQplots for the p-values. 
Lots of debris from old runs in here. Use with caution

```{r QQplot_functions, eval=TRUE}
plot_qq_maude <- function(maude_gene_stats, data_name, mark_gene = "AHSA1") {
  # Check that required columns exist
  if (!"p.value" %in% names(maude_gene_stats) || !"symbol" %in% names(maude_gene_stats)) {
    stop("Input data frame must contain 'p.value' and 'symbol' columns.")
  }
  
  # Sort the observed p-values and keep corresponding symbols
  sorted_stats <- maude_gene_stats[order(maude_gene_stats$p.value), ]
  # observed_pvalues <- p.adjust(sorted_stats$p.value, method = "hochberg", n = length(sorted_stats$p.value))
  observed_pvalues <- sorted_stats$p.value
  gene_symbols <- sorted_stats$symbol
  
  # Expected p-values adjusted to observed max
  max_p <- max(observed_pvalues)
  expected_pvalues <- (1:length(observed_pvalues)) / (length(observed_pvalues) + 1) * max_p
  
  # Transform to -log10
  log_observed <- -log10(observed_pvalues)
  log_expected <- -log10(expected_pvalues)
  
  # Identify the point to mark
  mark_index <- which(gene_symbols == mark_gene)
  
  # Plot Q-Q plot
  plot(log_expected, log_observed,
       main = paste("p-values Q-Q plot for", data_name),
       xlab = "Expected -log(p-value)",
       ylab = "Observed -log(p-value)",
       pch = 20, col = "blue",
       xlim = c(0, 5), ylim = c(0, 5))
  
  # Reference line
  abline(0, 1, col = "red", lty = 2)
  
  # Highlight the specific gene
  if (length(mark_index) > 0) {
    points(log_expected[mark_index], log_observed[mark_index],
           col = "darkorange", pch = 17, cex = 1.5)
    text(log_expected[mark_index], log_observed[mark_index],
         labels = mark_gene, pos = 4, offset = 0.5, col = "darkorange")
  }
}

get_top_N <- function(df, N = 1000, lookup_df = merged_sgRNA_df){
  N_half <- round(N / 2) 
  df_N <- bind_rows(
    df %>% arrange(significanceZ) %>% head(N_half),      # lowest Z
    df %>% arrange(desc(significanceZ)) %>% head(N_half) # highest Z
  )
  return(df_N)
}

get_top_N_intersect <- function(df_1,df_2,N = 1000, lookup_df = merged_sgRNA_df){
  
  N_half <- round(N / 2)  
  
  # Get top and bottom N/2 from df_1
  df1_extreme <- bind_rows(
    df_1 %>% arrange(significanceZ) %>% head(N_half),      # lowest Z
    df_1 %>% arrange(desc(significanceZ)) %>% head(N_half) # highest Z
  )
  
  # Same for df_2
  df2_extreme <- bind_rows(
    df_2 %>% arrange(significanceZ) %>% head(N_half),
    df_2 %>% arrange(desc(significanceZ)) %>% head(N_half)
  )
  # Find common entrez values
  common_entrez <- base::intersect(df1_extreme$entrez, df2_extreme$entrez)
  
  # Filter both for common entrez
  df1_common <- df1_extreme %>% filter(entrez %in% common_entrez)
  df2_common <- df2_extreme %>% filter(entrez %in% common_entrez)
  
  # Create combined results
  results_df <- bind_rows(df1_common, df2_common) %>%
    distinct(entrez, .keep_all = TRUE)  # one row per entrez, from first found in either df
  
  # Join with lookup — only first match per entrez
  lookup_first <- lookup_df %>%
    group_by(entrez) %>%
    dplyr::slice(1) %>%  # keep only the first match
    ungroup() %>%
    select(entrez, sgrna_id, symbol) %>% 
    mutate(entrez = as.character(entrez))
  
  # Add to results
  results_df <- results_df %>%
    left_join(lookup_first, by = "entrez")
  
  return(results_df)
}

compare_versions <- function(base_name, file_path = "/home/link/NB_EXP030/MAUDE_gene_stats") {
  # Create a vector of suffixes
  suffixes <- c("", "_RI", "_D0", "_RI_D0")
  
  # Read the files based on combinations of base_name and suffixes
  files <- lapply(suffixes, function(suffix) {
    file <- paste0(file_path, "_", base_name, suffix, ".rds")
    readRDS(file)
  })
  
  # Assign meaningful names to each version (e.g., "lukas_reads", "john_reads", etc.)
  names(files) <- paste0(base_name, suffixes)
  
  # Perform the comparisons (you can adjust this logic depending on your requirements)
  comparisons <- list()
  for (i in 1:length(files)) {
    for (j in i:length(files)) {
      if (i != j) {
        comparison_name <- paste(names(files)[i], "vs", names(files)[j])
        comparisons[[comparison_name]] <- get_top_N_intersect(files[[i]], files[[j]])
      }
    }
  }
  
  return(comparisons)
}


compare_versions <- function(file_path = get("rds_output_folder", envir = .GlobalEnv),
                             base_names = c("lukas_reads", "john_reads", "lukas_umis", "john_rf_umis")) {

  # Create an empty list to store all comparisons
  comparisons <- list()

  # Suffixes to consider
  suffixes <- c("", "_RI", "_D0", "_RI_D0")
  
  AHSA1_position_finder <- function(file, name){
    # Sort the dataframe by 'significanceZ' in ascending order
    sorted_df <- file %>%
      arrange(significanceZ)  # Assuming 'significanceZ' is the column name
  
    # Find the row where the 'entrez' value is 10598
    target_row <- sorted_df %>% filter(entrez == 10598)
    
    if (nrow(target_row) > 0) {
      # Get the position (row number) and significanceZ value
      position <- which(sorted_df$entrez == 10598)
      significanceZ_value <- target_row$significanceZ
      
      # Print the result
      cat(paste("AHSA1 position in", name, "is", position, "with significanceZ value of", significanceZ_value, "\n"))
    } else {
      cat(paste("AHSA1 (entrez 10598) not found in", name, "\n"))
    }
  }
  
  name_list <- list()
  # Comparison 1: Compare all versions of each base name against each other
  for (base_name in base_names) {
    # Read files based on the base_name and suffixes
    files <- lapply(suffixes, function(suffix) {
      file <- paste0(file_path, "_", base_name, suffix, ".rds")
      if (file.exists(file)) {
        name_list <<- c(name_list, paste0(base_name, suffix))  # Use <<- to modify the global name_list
        return(readRDS(file))
      } else {
        cat(paste("File not found, skipping:", file, "\n"))
        return(NULL)  # Return NULL if file doesn't exist
      }
    })
    
    # Remove any NULL elements (files that were missing)
    files <- files[!sapply(files, is.null)]
    names(files) <- name_list

    # Perform comparisons between all versions of the base name
    for (i in 1:length(files)) {
      for (j in i:length(files)) {
        cat(paste("------------------------------------------------","\n"))
        if (i != j) {
          cat(paste("------------------------------------------------","\n"))
          comparison_name <- paste(names(files)[i], "vs", names(files)[j])
          intersect_df <- get_top_N_intersect(files[[i]], files[[j]], N = 100)
          cat(paste(comparison_name, "Number of intersects:",nrow(intersect_df),"\n"))
          AHSA1_position_finder(files[[i]], names(files)[i])
          AHSA1_position_finder(files[[j]], names(files)[j])
          comparisons[[paste(base_name, comparison_name)]] <- intersect_df
        }
      }
    }
  }
  
  # Comparison 2: Compare reads and umis between John and Lukas
  # Define pairs for Lukas vs. John comparisons for "reads" and "umis"
  john_lukas_comparisons <- list(
    c("lukas_reads", "john_reads"),
    c("lukas_umis", "john_rf_umis")
  )
  
  for (pair in john_lukas_comparisons) {
    for (suffix in suffixes) {
      cat(paste("------------------------------------------------","\n"))
      # Construct filenames for Lukas and John based on base names and suffixes
      lukas_file <- paste0(file_path, "_", pair[1], suffix, ".rds")
      john_file <- paste0(file_path, "_", pair[2], suffix, ".rds")
      
      # Check if the files exist
      if (file.exists(lukas_file) & file.exists(john_file)) {
        # Read the files
        lukas_data <- readRDS(lukas_file)
        john_data <- readRDS(john_file)
        
        # Perform the comparison between Lukas and John for each suffix combination
        comparison_name <- paste(pair[1], "vs", pair[2], "(", suffix, ")")
        intersect_df <- get_top_N_intersect(lukas_data, john_data, N = 100)
        cat(paste(comparison_name, "Number of intersects:",nrow(intersect_df),"\n"))
        comparisons[[paste(pair[1], pair[2], comparison_name)]] <- intersect_df
      } else {
        cat(paste("One or both files not found, skipping:", lukas_file, "and", john_file, "\n"))
      }
    }
  }

  return(comparisons)
}
plot_all_qq_plots <- function(dir_path) {
  # List all files in the directory ending with ".rds"
  rds_files <- list.files(dir_path, pattern = "\\.rds$", full.names = TRUE)

  # Filter files that start with "MAUDE_guide_stats_"
  matching_files <- rds_files[grepl("MAUDE_guide_stats_", basename(rds_files))]

  # Loop over each matching file
  for (file in matching_files) {
    # Extract the info_suffix
    filename <- basename(file)
    info_suffix <- sub("^MAUDE_guide_stats_", "", sub("\\.rds$", "", filename))

    # Run the commands
    Hits_current_settings <- add_info_wrapper(info_suffix)
    plot_qq_maude(Hits_current_settings, info_suffix)
  }
}


generate_qq_plots <- function(base_name,
                              file_path = get("rds_output_folder", envir = .GlobalEnv),
                              suffixes = c("", "_RI", "_D0", "_RI_D0")) {
  
  file_path <- paste0(file_path, "MAUDE_gene_stats")
  # Use invisible() to suppress unwanted NULL outputs
  invisible(lapply(suffixes, function(suffix) {
    # Create the file path for each suffix
    file <- paste0(file_path, "_", base_name, suffix, ".rds")
    
    # Check if the file exists before attempting to read it
    if (file.exists(file)) {
      maude_gene_stats <- readRDS(file)
      plot_qq_maude(maude_gene_stats, paste(base_name, suffix))
    } else {
      # If the file doesn't exist, print a message and skip this iteration
      cat(paste("File not found, skipping:", file, "\n"))
    }
  }))
}
compare_Hits <- function(df1, df2, top_N = 50) {
  
  # Sort both dataframes by FDR (low to high)
  df1_sorted <- df1[order(df1$FDR), ]
  df2_sorted <- df2[order(df2$FDR), ]
  
  # Get the top N entries based on FDR
  df1_top <- df1_sorted[1:top_N, ]
  df2_top <- df2_sorted[1:top_N, ]
  
  # 1. Overlap among top_N (by FDR)
  overlap <- merge(df1_top, df2_top, by = "entrez", all = FALSE)
  
  # 2. Dropouts among top_N (by FDR)
  dropouts <- base::setdiff(df1_top$entrez, df2_top$entrez)
  df1_dropouts <- df1_top[df1_top$entrez %in% dropouts, ]
  
  # 3. Statistics dataframe
  # Number of overlaps
  num_overlaps <- nrow(overlap)
  
  # Number of dropouts
  num_dropouts <- nrow(df1_dropouts)
  
  # Calculate ranks for FDR in both dataframes
  df1_sorted$rank_FDR <- rank(df1_sorted$FDR)
  df2_sorted$rank_FDR <- rank(df2_sorted$FDR)
  
  # Merge the two sorted dataframes by 'entrez' to match pairs
  merged_df <- merge(df1_sorted[, c("entrez", "rank_FDR")], 
                     df2_sorted[, c("entrez", "rank_FDR")], 
                     by = "entrez", 
                     suffixes = c("_df1", "_df2"))
  
  # 4. Correlation between ranks in top N (paired test)
  rank_correlation_topN <- cor(merged_df$rank_FDR_df1[1:top_N], merged_df$rank_FDR_df2[1:top_N], method = "pearson")
  
  # 5. Correlation between ranks for all entries (paired test)
  rank_correlation_all <- cor(merged_df$rank_FDR_df1, merged_df$rank_FDR_df2, method = "pearson")
  
  # Split significanceZ into > 0 and <= 0
  df1_top_posZ <- df1_top[df1_top$significanceZ > 0, ]
  df2_top_posZ <- df2_top[df2_top$significanceZ > 0, ]
  
  df1_top_negZ <- df1_top[df1_top$significanceZ <= 0, ]
  df2_top_negZ <- df2_top[df2_top$significanceZ <= 0, ]
  
  # Median and mean changes in significance Z and FDR for significanceZ > 0
  median_change_Z_pos <- median(df1_top_posZ$significanceZ - df2_top_posZ$significanceZ)
  mean_change_Z_pos <- mean(df1_top_posZ$significanceZ - df2_top_posZ$significanceZ)
  
  # Median and mean changes in significance Z and FDR for significanceZ <= 0
  median_change_Z_neg <- median(df1_top_negZ$significanceZ - df2_top_negZ$significanceZ)
  mean_change_Z_neg <- mean(df1_top_negZ$significanceZ - df2_top_negZ$significanceZ)
  
  # Median and mean changes in FDR
  median_change_FDR <- median(df1_top$FDR - df2_top$FDR)
  mean_change_FDR <- mean(df1_top$FDR - df2_top$FDR)
  
  # Create the statistics dataframe
  stats <- data.frame(
    Statistic = c(paste0("Number of overlaps (top ",top_N,")"),paste0("Number of dropouts (top ",top_N,")"), 
                  paste0("Correlation between ranks (top ",top_N,")"), "Correlation between ranks (all)", 
                  "Median change in significance Z+", "Mean change in significance Z+", 
                  "Median change in significance Z-", "Mean change in significance Z-", 
                  "Median change in FDR", "Mean change in FDR"),
    Value = c(num_overlaps, num_dropouts, rank_correlation_topN, rank_correlation_all, 
              median_change_Z_pos, mean_change_Z_pos, median_change_Z_neg, mean_change_Z_neg, 
              median_change_FDR, mean_change_FDR)
  )
  
  # Return the list of dataframes
  return(list(
    Overlap = overlap,
    Dropouts = df1_dropouts,
    Statistics = stats
  ))
}

# Create a smaller version of compare_versions for the specific four dataframes
compare_methods <- function(N = 100) {
  # List of the four dataframes
  df_list <- list(
    "Hits_lukas_umis" = Hits_lukas_umis,
    "Hits_lukas_umis_RI" = Hits_lukas_umis_RI,
    "Hits_lukas_umis_sum_RI" = Hits_lukas_umis_sum_RI,
    "Hits_lukas_umis_rep_RI" = Hits_lukas_umis_rep_RI
  )
  
  # Helper function to calculate AHSA1 position
  AHSA1_position_finder <- function(df, name) {
    sorted_df <- df %>%
      arrange(significanceZ)  # Sort by significanceZ (assuming column exists)
    
    # Find the row where the 'entrez' value is 10598
    target_row <- sorted_df %>% filter(entrez == 10598)
    
    if (nrow(target_row) > 0) {
      position <- which(sorted_df$entrez == 10598)
      significanceZ_value <- target_row$significanceZ
      cat(paste("AHSA1 position in", name, "is", position, "with significanceZ value of", significanceZ_value, "\n"))
    } else {
      cat(paste("AHSA1 (entrez 10598) not found in", name, "\n"))
    }
  }
  
  # Compare all combinations of the dataframes
  comparisons <- list()
  
  df_names <- names(df_list)
  
  # Loop through all possible pairs of dataframes
  for (i in 1:(length(df_names) - 1)) {
    cat(paste("------------------------------------------------","\n"))
    for (j in (i + 1):length(df_names)) {
      cat(paste("------------------------------------------------","\n"))
      name_i <- df_names[i]
      name_j <- df_names[j]
      
      # Get the dataframes
      df_i <- df_list[[name_i]]
      df_j <- df_list[[name_j]]
      
      # Calculate the intersection
      intersect_df <- get_top_N_intersect(df_i, df_j, N = N)
      n_intersect <- nrow(intersect_df)
      
      # Print intersection and AHSA1 positions
      cat(paste(name_i, "vs", name_j, "Number of intersects:", n_intersect, "\n"))
      AHSA1_position_finder(df_i, name_i)
      AHSA1_position_finder(df_j, name_j)
      
      # Store the results
      comparisons[[paste(name_i, "vs", name_j)]] <- list(
        intersect = intersect_df,
        n_intersect = n_intersect
      )
    }
  }
  
  return(comparisons)
}

```

## Create QQplots for the p-values. 
Lots of debris from old runs in here. Use with caution

```{r QQplot, eval=FALSE}
#===============================================================================
# Batch generate ALL qq plots
# add suffixes <- c(list_of_suffixes_without_.rds); example <- c("", "_RI")
#===============================================================================
plot_all_qq_plots(rds_output_folder)
#===============================================================================
# Batch generate specific qq plots
# add suffixes <- c(list_of_suffixes_without_.rds); example <- c("", "_RI")
#===============================================================================
generate_qq_plots("lukas_reads")
generate_qq_plots("lukas_umis")
generate_qq_plots("john_reads")
generate_qq_plots("john_rf_umis")

#===============================================================================
# Create Hit lists
#===============================================================================
# use my_Hits <- add_info_wrapper("my_file_suffix")
Hits_current_settings <- add_info_wrapper(file_info_suffix)
plot_qq_maude(Hits_current_settings, "Sublibraries as replicates combined")
plot_qq_maude(export_df, "Sublibraries as replicates combined")
Hits_sublib <- add_info_wrapper("lukas_umis_rep_sublib_control_median_RI")
Hits_lukas_umis_control_median_RI <- add_info_wrapper("lukas_umis_control_median_RI")
Hits_lukas_umis_sum_control_median_RI <- add_info_wrapper("lukas_umis_sum_control_median_RI")
Hits_sublib_combined <- add_info_wrapper("lukas_umis_rep_sublib_control_median_RI_0")

#===============================================================================
# Intersect 2 different Hit lists
#===============================================================================
top_1000_umis_intersect <- get_top_N_intersect(Hits_default,Hits_sublib_combined, N=1000)
top_100_umis_intersect <- get_top_N_intersect(Hits_default,Hits_sublib_combined, N=100)
top_100 <- get_top_N_intersect(Hits_current_settings,Hits_default, N=100)
top_100_2 <- get_top_N_intersect(Hits_current_settings,Hits_sum, N=100)



top_50_umis_intersect <- get_top_N_intersect(Hits_lukas_umis_RI,Hits_lukas_umis_sum_RI, N=50)
top_20_umis_intersect <- get_top_N_intersect(Hits_lukas_umis_RI,Hits_lukas_umis_sum_RI, N=20)
top_50_umis_intersect_sum_rep <- get_top_N_intersect(Hits_lukas_reads_sum_RI,Hits_lukas_reads_rep_RI_rf, N=50)
top_10_umis_intersect___sum <- get_top_N_intersect(Hits_lukas_umis_sum_RI,Hits_lukas_umis_RI, N=10)
top_15_umis_intersect_control_median <- get_top_N_intersect(Hits_lukas_umis_sum_control_median_RI,Hits_lukas_umis_control_median_RI, N=100)
top_10_umis_intersect_both <- get_top_N_intersect(top_15_umis_intersect_control_median,top_10_umis_intersect___sum, N=10)
top_10_umis_sum_control_median <- get_top_N_intersect(Hits_lukas_umis_sum_control_median_RI,Hits_lukas_umis_sum_control_median_RI, N=10)
saveRDS(get_top_N(Hits_lukas_umis_sum_RI, N=100), "/g/steinmetz/link/Amplicon_barcode_analysis/NB_EXP030/heatmaps/top_100.rds")
saveRDS(get_top_N(Hits_lukas_umis_sum_RI, N=50), "/g/steinmetz/link/Amplicon_barcode_analysis/NB_EXP030/heatmaps/top_50.rds")
saveRDS(get_top_N(Hits_lukas_umis_sum_RI,N=20), "/g/steinmetz/link/Amplicon_barcode_analysis/NB_EXP030/heatmaps/top_20.rds")
#===============================================================================
# Make individual qq-plots for the p-values of the hits. 
#===============================================================================
plot_qq_maude(Hits_lukas_umis_RI, "UMIs (one replicate method)")
plot_qq_maude(Hits_lukas_umis_sum_RI, "UMIs (sum method)")
plot_qq_maude(Hits_lukas_reads_RI, "reads (one replicate method)")
plot_qq_maude(Hits_lukas_reads_sum_RI, "reads (sum method)")

plot_qq_maude(Hits_lukas_umis_control_median_RI, "UMIs (one replicate method)(normalized)")
plot_qq_maude(Hits_lukas_umis_sum_control_median_RI, "UMIs (sum method)(normalized)")
plot_qq_maude(Hits_lukas_reads_control_median_RI, "reads (one replicate method)(normalized)")
plot_qq_maude(Hits_lukas_reads_sum_control_median_RI, "reads (sum method)(normalized)")

plot_qq_maude(Hits_lukas_reads, "Reads (no IR no RF)")
plot_qq_maude(Hits_john_reads, "John Reads (no IR no RF)")
plot_qq_maude(Hits_lukas_umis, "UMIs (no IR)")
plot_qq_maude(Hits_john_umis, "John UMIs (no IR no RF)")
plot_qq_maude(Hits_john_rf_umis, "John_rf UMIs (no IR)")

plot_qq_maude(Hits_lukas_reads_RI, "Reads (no IR)")
plot_qq_maude(Hits_john_reads_RI, "John Reads (no RF)")
plot_qq_maude(Hits_lukas_reads_RI_rf, "Reads")
# plot_qq_maude(Hits_john_reads_RI_rf, "John Reads")

plot_qq_maude(Hits_lukas_umis_RI, "UMIs")
plot_qq_maude(Hits_john_rf_umis_RI, "John UMIs")

plot_qq_maude(Hits_lukas_reads_sum_RI_rf, "Reads replicate summation")
plot_qq_maude(Hits_john_reads_sum_RI_rf, "John Reads replicate summation")
plot_qq_maude(Hits_lukas_umis_sum_RI, "UMIs replicate summation")
plot_qq_maude(Hits_john_rf_umis_sum_RI, "John UMIs replicate summation")

plot_qq_maude(Hits_lukas_reads_rep_RI_rf, "Reads multiple replicates")
plot_qq_maude(Hits_john_reads_rep_RI_rf, "John Reads multiple replicates")
plot_qq_maude(Hits_lukas_umis_rep_RI, "UMIs multiple replicates")
plot_qq_maude(Hits_john_rf_umis_rep_RI, "John UMIs multiple replicates")





# Call the function to perform the comparisons
results_methods <- compare_methods(N = 50)



# maude_gene_stats_lukas <- readRDS(paste0("/home/link/NB_EXP030/MAUDE_gene_stats", "_lukas_reads.rds"))
# maude_gene_stats_john <- readRDS(paste0("/home/link/NB_EXP030/MAUDE_gene_stats", "_john_reads.rds"))
# 
# top_1000_reads_intersect <- get_top_N_intersect(maude_gene_stats_lukas,maude_gene_stats_john)
# top_100_reads_intersect <- get_top_N_intersect(maude_gene_stats_lukas,maude_gene_stats_john, N=100)

```

``` {r compare_helper_functions, eval=TRUE}
# Helper function to apply FDR filter
apply_FDR_filter <- function(df, FDR_threshold) {
  df <- df %>%
    filter(FDR <= FDR_threshold)
  return(df)
}

# Helper function to calculate number of overlapping entrez
calculate_overlap <- function(reference_df, target_df) {
  reference_entrez <- reference_df$entrez
  target_entrez <- target_df$entrez
  overlap_count <- sum(target_entrez %in% reference_entrez)
  return(overlap_count)
}
# Helper function to calculate the correlation between a refrence_df
# and a target_df
calculate_correlation <- function(reference_df,
                                  target_df,
                                  method = "spearman",
                                  use = "complete.obs",
                                  FDR_threshold = 0.05,
                                  significance_filter = NULL) {
  # keep only needed cols, drop duplicates, sort by FDR, assign ranks
  if (!is.null(significance_filter)) {
    reference_df <- reference_df %>% filter(significanceZ * significance_filter > 0)
    target_df <- target_df %>% filter(significanceZ * significance_filter > 0)
  }
  
  ref <- reference_df[, c("entrez", "FDR")]
  tgt <- target_df[, c("entrez", "FDR")]

  ref <- ref[!is.na(ref$entrez) & !is.na(ref$FDR), ]
  tgt <- tgt[!is.na(tgt$entrez) & !is.na(tgt$FDR), ]

  ref <- ref %>% rename(ref_FDR = FDR)
  tgt <- tgt %>% rename(tgt_FDR = FDR)
  
  # pair by entrez (inner join)
  paired <- merge(ref, tgt, by = "entrez") %>%
    filter(ref_FDR <= FDR_threshold | tgt_FDR <= FDR_threshold)
  # if not enough paired points, correlation is undefined
  if (nrow(paired) < 2) return(NA_real_)

  correlation <- cor(paired$ref_FDR, paired$tgt_FDR, method = method, use = use)
  correlation <- round(correlation, 3)
  return(correlation)
}
# Function to process each scenario
# generates a dataframe with hits, and overlap to reference for each df in df_list

make_compare_df <- function(df_list, name_list, FDR_threshold, significance_filter = NULL, top_N = NULL) {
  
  if (length(df_list) != length(name_list)){
    stop(paste("ERROR: in make_compare_df -> length of df_list:",length(df_list), " must be equal to lenght of name_list:",length(name_list)))
  }
  # First dataframe as the reference (100% by definition)
  reference_df <- df_list[[1]] %>%
    apply_FDR_filter(FDR_threshold)
  if (!is.null(significance_filter)) {
    reference_df <- reference_df %>% filter(significanceZ * significance_filter > 0)
  }
  
  # Initialize empty lists for storing results
  Overlap <- list()
  Overlap_percentage <- list()
  Total_Hits <- list()

  # Loop through the dataframes and calculate overlap for each subsample percentage
  for (i in seq_along(df_list)) {
    
    target_df <- df_list[[i]]
    
    # Apply FDR filter to the target dataframe
    target_df <- apply_FDR_filter(target_df, FDR_threshold)
    
    # Apply additional significance filter if provided
    if (!is.null(significance_filter)) {
      target_df <- target_df %>% filter(significanceZ * significance_filter > 0)
    }

    # Check overlap with the reference
    overlap_count <- calculate_overlap(reference_df, target_df)
    
    # Calculate percentage overlap
    overlap_percentage_value <- round((overlap_count / nrow(reference_df)) * 100,2)
    
    total_hits_value <- nrow(target_df)
    
    # Append results to the lists
    Overlap <- c(Overlap, overlap_count)
    Overlap_percentage <- c(Overlap_percentage, overlap_percentage_value)
    Total_Hits <- c(Total_Hits, total_hits_value)
  }
  # Combine the lists into a final dataframe
  final_results <- data.frame(
    Name = name_list,
    Overlap = unlist(Overlap),
    Overlap_percentage = unlist(Overlap_percentage),
    Total_Hits = unlist(Total_Hits)
  )
  
  # Return the final dataframe
  return(final_results)
}
make_venn_from_overlap_df <- function(df,
                                      ncol = 3,
                                      main_title = "Venn Diagramm",
                                      comparing = "") {
  stopifnot(all(c("Name", "Overlap", "Total_Hits") %in% colnames(df)))
  if (nrow(df) < 2) stop("df needs at least 2 rows (1 reference + >=1 target).")
  
  if (comparing != ""){
    if (comparing == "subsamples"){
      df <- df %>% 
      mutate(Name = paste0("sub_perc_",Name))
    } else {
      stop("currently only '' (sublib) and 'subsamples' are viable for comparing ")
    }
  }

  
  ref_name <- df$Name[1]
  ref_total <- df$Total_Hits[1]

  grobs <- list()
  #This is supposed to stop it drawing a venn diagramm with draw.pairwise.venn
  tmp <- tempfile(fileext = ".pdf")
  grDevices::pdf(tmp)
  on.exit({ grDevices::dev.off(); unlink(tmp) }, add = TRUE)
  
  for (i in 2:nrow(df)) {
    tgt_name  <- df$Name[i]
    tgt_total <- df$Total_Hits[i]
    overlap   <- df$Overlap[i]

    # sanity (avoid negative/invalid overlaps)
    overlap <- max(0, overlap)
    overlap <- min(overlap, ref_total, tgt_total)
    

    g_list <- VennDiagram::draw.pairwise.venn(
      area1 = ref_total,
      area2 = tgt_total,
      cross.area = overlap,
      category = c(ref_name, tgt_name),
      fill = c("lightgreen", "lightblue"),
      alpha = c(0.6, 0.6),
      cat.cex = 1.0,
      cex = 1.3,
      col = c("darkgreen", "darkblue"),
      cat.fontface = "bold",
      cat.col = c("darkgreen", "darkblue"),      # category label colours
      label.col = c("darkgreen", "black", "darkblue"),  # left / overlap / right numbers
      cat.pos  = c(-60, 60),
      cat.dist = c(0.2, 0.2),
      ind = TRUE
    )
    
    # wrap list-of-grobs into a single grobTree so gridExtra can place it
    g <- grid::grobTree(gList = do.call(grid::gList, g_list))
    g <- grid::grobTree(g, vp = grid::viewport(width = 0.5, height = 0.7))
    grobs[[tgt_name]] <- g
  }

  title_grob <- grid::textGrob(main_title, gp = grid::gpar(fontsize = 14, fontface = "bold"))
  
  return(
    gridExtra::arrangeGrob(
      title_grob,
      gridExtra::arrangeGrob(grobs = grobs, ncol = ncol),
      ncol = ncol,
      heights = c(0.08, 0.92)
    )
  )
}
# Make the Correlation Heatmap
make_correlation_heatmap <- function(df_list,
                                     name_list,
                                     comparing = "",
                                     plot_title = NULL,
                                     significance_filter = NULL,
                                     FDR_threshold = 0.05) {
  
  if (comparing == "subsamples"){
    name_list = paste0("sub_perc_",name_list)
  }

  n <- length(df_list)

  # correlation matrix
  cor_mat <- matrix(
    NA_real_,
    nrow = n, ncol = n,
    dimnames = list(name_list, name_list)
  )

  for (i in seq_len(n)) {
    for (j in seq_len(n)) {
      cor_mat[i, j] <- calculate_correlation(
        df_list[[i]],
        df_list[[j]],
        FDR_threshold = FDR_threshold,
        significance_filter = significance_filter
      )
    }
  }

  cor_df <- as.data.frame(as.table(cor_mat))
  colnames(cor_df) <- c("Reference", "Target", "Correlation")

  p <- ggplot2::ggplot(cor_df, ggplot2::aes(x = Target, y = Reference, fill = Correlation)) +
    ggplot2::geom_tile() +
    ggplot2::geom_text(
      ggplot2::aes(label = ifelse(is.na(Correlation), "", sprintf("%.3f", Correlation))),
      size = 3
    ) +
    ggplot2::coord_equal() +
    ggplot2::theme_bw() +
    ggplot2::theme(
      axis.text.x = ggplot2::element_text(angle = 45, hjust = 1, vjust = 1),
      panel.grid = ggplot2::element_blank()
    ) +
    ggplot2::labs(
      title = paste("Pairwise Spearman Correlation of FDR Ranks for",plot_title),
      x = NULL, y = NULL,
      fill = "Rank corr"
    )

  return(p)
}
plot_overlap <- function(df, title, comparing = "") {
  # Ensure the input dataframe contains the necessary columns
  if (!all(c("Name", "Overlap", "Overlap_percentage", "Total_Hits") %in% colnames(df))) {
    stop("The dataframe must contain 'Subsample_percentage', 'Overlap', 'Total_Hits' and 'Overlap_percentage' columns.")
  }
  
  # Create the plot
  if (comparing == ""){
    p <- ggplot(df, aes(x = Name, y = Overlap_percentage)) +
      geom_point(size = 3) +
      theme_bw() +
      labs(
        title = paste("Percentage of correct Hits for", title),
        x = "",
        y = "Overlap Percentage"
      ) +
      theme(
        axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)
      )  
  }
  if (comparing == "subsamples") {
  
    # Extract trailing number from tags like "A25" / "subX10" / "25"
    df$Number <- as.integer(sub("^\\D*([0-9]+)$", "\\1", df$Name))
  
    # Safety check (optional)
    if (any(is.na(df$Number))) {
      stop("Some 'Name' entries do not end in a number (cannot extract Number).")
    }
  
    # Sort by numeric value so the line goes left -> right correctly
    df <- df[order(df$Number), ]
  
    if (anyDuplicated(df$Number) == 0) {
      # mbers are unique → simple plot
      p <- ggplot(df, aes(x = Number)) +
        geom_line(aes(y = Overlap_percentage), size = 1, group = 1) +
        geom_point(aes(y = Overlap_percentage), size = 3) +
        labs(
          title = paste("Percentage of correct Hits for", title),
          x = "Subsample Percentage",
          y = "Overlap Percentage"
        ) +
        theme_bw()
  
    } else {
      # Numbers NOT unique → plot mean per Number + error bars
  
      # Summarise mean + SE (swap to sd if you prefer)
      tmp <- split(df$Overlap_percentage, df$Number)
      df_sum <- data.frame(
        Number = as.integer(names(tmp)),
        mean   = sapply(tmp, mean),
        sd     = sapply(tmp, sd),
        n      = sapply(tmp, length)
      )
  
      df_sum$se <- df_sum$sd / sqrt(df_sum$n)
      df_sum$se[is.na(df_sum$se)] <- 0  # happens when n=1 (sd=NA)
  
      df_sum <- df_sum[order(df_sum$Number), ]
  
      p <- ggplot(df_sum, aes(x = Number)) +
        geom_line(aes(y = mean), size = 1, group = 1) +
        geom_point(aes(y = mean), size = 3) +
        geom_errorbar(
          aes(ymin = mean - se, ymax = mean + se),
          width = 0.2
        ) +
        labs(
          title = paste("Percentage of correct Hits with SE for", title),
          x = "Subsample Percentage",
          y = "Overlap Percentage"
        ) +
        theme_bw()
  
      # Optional: show the individual points too (nice for debugging)
      # p <- p + geom_point(data = df, aes(x = Number, y = Overlap_percentage), alpha = 0.4)
    }
  }

  return(p)
}

# Function for a line plot comparing total hits
# Currently depricated and replaced by venn diagramms
plot_total_hits <- function(df, title, comparing = "") {
  # Ensure the input dataframe contains the necessary columns
  if (!all(c("Name", "Overlap", "Overlap_percentage", "Total_Hits") %in% colnames(df))) {
    stop("The dataframe must contain 'Name', 'Overlap', 'Total_Hits' and 'Overlap_percentage' columns.")
  }
  if (comparing == ""){
    x_lab_text = ""
  }
  if (comparing == "subsamples"){
    x_lab_text = "Subsample Percentage"
  }
  # Create the plot
  p <- ggplot(df, aes(x = Name)) +
    geom_line(aes(y = Total_Hits), size = 1) + 
    geom_point(aes(y = Total_Hits), size = 3) +
    labs(
      title = paste("Number of all Hits (not necessarily correct ones) for",title),
      x = x_lab_text,
      y = "Total Hits"
    ) +
    theme_bw()

  # Return the plot
  return(p)
}
  
compare_df_list <- function(df_list,
                            name_list,
                            FDR_threshold = 0.05,
                            top_N = NULL,
                            comparing = "",
                            correlation_heatmap = TRUE,
                            overlap = TRUE,
                            venn_diagram = TRUE) {
  

  all_hits_df <- make_compare_df(df_list, name_list, FDR_threshold)
  print(all_hits_df)
  sig_up_hits_df <- make_compare_df(df_list, name_list, FDR_threshold, significance_filter = 1)
  sig_down_hits_df <- make_compare_df(df_list, name_list, FDR_threshold, significance_filter = -1)
  results_list <- list(all_hits_df, sig_up_hits_df, sig_down_hits_df)
  names(results_list) <- c("All_Hits", "Up_Hits" ,"Down_Hits")
  names(results_list) <- c("All_Hits", "Up_Hits" ,"Down_Hits")
  signif_map <- list(
    All_Hits  = NULL,
    Up_Hits   = 1,
    Down_Hits = -1
  )
  
  # Loop over all dataframes in the results list and plot them
  for (scenario_name in names(results_list)) {
    signif_filter_for_scenario <- signif_map[[scenario_name]]
    if (correlation_heatmap == TRUE){
      q <- make_correlation_heatmap(df_list,
                                    name_list,
                                    comparing = comparing,
                                    plot_title = scenario_name,
                                    significance_filter = signif_filter_for_scenario,
                                    FDR_threshold = FDR_threshold)
      print(q)      
    }
    if (overlap == TRUE){
      p <- plot_overlap(results_list[[scenario_name]],
                        scenario_name,
                        comparing = comparing)
      print(p)       
    }
    if (venn_diagram == TRUE){
      r <- make_venn_from_overlap_df(results_list[[scenario_name]],
                                     ncol = 1,
                                     comparing = comparing,
                                     main_title = scenario_name)
      grid::grid.newpage()
      grid::grid.draw(r)      
    }
  }
  return(results_list)
}
```

``` {r compare_subsamples_functions, eval=TRUE}
move_subsamples <- function(subsample_master_dir,
                            subsample_prefix = "",
                            output_folder = get("rds_output_folder",
                                                envir = .GlobalEnv),
                            file_info_suffix = get("file_info_suffix",
                                                   envir = .GlobalEnv)) {
  
  # Basic checks
  if (subsample_prefix != ""){
    is_alpha_only <- function(x) grepl("^[A-Za-z]+$", x)
    if (!is_alpha_only(subsample_prefix)){
      stop("subsample prefix can only contain alphatbetic characters: ",subsample_prefix)
    }
  }
  if (!dir.exists(subsample_master_dir)) {
    stop("subsample_master_dir does not exist: ", subsample_master_dir)
  }
  if (!dir.exists(output_folder)) {
    stop("rds_output_folder does not exist: ", output_folder)
  }
  if (!is.character(file_info_suffix) || length(file_info_suffix) != 1) {
    stop("file_info_suffix must be a single character string.")
  }
  
  # Find subdirectories like subsample_X
  subsample_dirs <- list.dirs(subsample_master_dir, recursive = FALSE, full.names = TRUE)
  subsample_dirs <- subsample_dirs[grepl("^subsample_", basename(subsample_dirs))]
  
  if (length(subsample_dirs) == 0) {
    message("No subdirectories named 'subsample_#' found in: ", subsample_master_dir)
    return(invisible(NULL))
  }
  
  # Build regex to match files ending in <file_info_suffix>.rds
  # Example: ".*_fileinfo\\.rds$" depending on suffix
  pattern <- paste0(".*", file_info_suffix, "\\.rds$")
  
  copied <- character(0)
  skipped <- character(0)
  
  for (sd in subsample_dirs) {
    sub_name <- basename(sd)                 # "subsample_X"
    X <- sub("^subsample_", "", sub_name)    # keep whatever is after "subsample_"
    
    rds_dir <- file.path(sd, "rds")
    if (!dir.exists(rds_dir)) {
      message("Skipping, no rds dir in: ", sd)
      next
    }
    
    files <- list.files(rds_dir, pattern = pattern, full.names = TRUE)
    if (length(files) == 0){
      message("Skipping, no files matching patterin in dir: ", rds_dir)
      next
    } 
    for (file in files) {
      base <- basename(file) # e.g. "something_suffix.rds"
      new_base <- sub("\\.rds$", paste0("_subsample_", subsample_prefix, X, ".rds"), base)
      dest <- file.path(output_folder, new_base)
      
      ok <- file.copy(from = file, to = dest, overwrite = TRUE)
      if (ok) {
        copied <- c(copied, dest)
      } else {
        skipped <- c(skipped, file)
      }
    }
  }
  
  message("Copied ", length(copied), " file(s) to: ", output_folder)
  if (length(skipped) > 0) {
    message("WARNING: Failed to copy ", length(skipped), " file(s).")
  }
  
  invisible(list(copied = copied, failed = skipped))
}


automate_subsample_comparison <- function(file_info_prefix = get("file_info_suffix",
                                                             envir = .GlobalEnv),
                                          FDR_threshold = 0.05,
                                          correlation_heatmap = TRUE,
                                          overlap = TRUE,
                                          venn_diagram = TRUE) {
  # Get the current settings from the global environment
  if(exists("Hits_current_settings")){
    Hits_current_settings <- get("Hits_current_settings", envir = .GlobalEnv)
  } else {
    Hits_current_settings <- add_info_wrapper(file_info_prefix)
  }
  
  rds_output_folder <- get("rds_output_folder", envir = .GlobalEnv)
  
  # 1) list files (now expecting subsample_<letters><digits>.rds)
  rds_files <- list.files(
    rds_output_folder,
    pattern = paste0(".*", file_info_prefix, "_subsample_[A-Za-z]+[0-9]+\\.rds$"),
    full.names = TRUE
  )
  
  # 2) extract the combined prefix+number part (e.g. "A25" from lukas_reads_control_median_RI_subsample_A25.rds)
  subsample_tag <- sub(
    paste0(".*", file_info_prefix, "_subsample_([A-Za-z]+[0-9]+)\\.rds$"),
    "\\1",
    basename(rds_files)
  )
  subsample_tag_unique <- unique(subsample_tag)
  # 4) split into prefixes and numbers
  prefixes <- sub("^([A-Za-z]+)[0-9]+$", "\\1", subsample_tag_unique)
  numbers  <- as.integer(sub("^[A-Za-z]+([0-9]+)$", "\\1", subsample_tag_unique))
  
  # Generate the percentage list (starting from 100 and then descending from the available numbers)
  tag_df <- data.frame(prefix = prefixes,
                   number = numbers,
                   tag = subsample_tag_unique,
                   stringsAsFactors = FALSE)

  tag_df <- tag_df[order(tag_df$number, decreasing = TRUE), ]
  # Generate Hits_sub_x using add_info_wrapper for each percentage in percentage_list
  df_list <- lapply(tag_df$tag, function(tag) {
    add_info_wrapper(paste0(file_info_prefix, "_subsample_", tag))
  })
  print(length(df_list))
  # Call compare_df_list with the generated df_list and percentage_list
  result <- compare_df_list(df_list = c(list(Hits_current_settings), df_list),
                            name_list = c(100, tag_df$tag),
                            FDR_threshold = FDR_threshold,
                            comparing = "subsamples",
                            top_N = NULL,
                            correlation_heatmap = correlation_heatmap,
                            overlap = overlap,
                            venn_diagram = venn_diagram)
  
  return(result)
}

```

``` {r compare_sublibraries_functions, eval=TRUE}
automate_sublibrary_comparison <- function(file_info_suffix = get("file_info_suffix", envir = .GlobalEnv),
                                           FDR_threshold = 0.05,
                                          correlation_heatmap = TRUE,
                                          overlap = TRUE,
                                          venn_diagram = TRUE) {
  # Get the current settings from the global environment
  Hits_all_sublibs <- add_info_wrapper(file_info_suffix)
  rds_output_folder <- get("rds_output_folder", envir = .GlobalEnv)
  
  # List all files in the rds output folder
  rds_files <- list.files(rds_output_folder, pattern = paste0(".*", file_info_suffix, "_no_sublib", "_L[0-9]+\\.rds$"), full.names = TRUE)
  
  # Extract everything between file_info_suffix + "_" and ".rds"
  # e.g. "...<file_info_suffix>_no_sublib_L1.rds" -> "no_sublib_L1"
  sublib_names <- sub(
    paste0(".*", file_info_suffix, "_(.+)\\.rds$"),
    "\\1",
    basename(rds_files)
  )
  sublib_names <- unique(sublib_names)
  sublib_suffixes <- paste0(file_info_suffix, "_", sublib_names)
  # Generate Hits_df_list using add_info_wrapper for each sublib_suffixes
  Hits_df_list <- lapply(sublib_names, function(sublib_names) {
    add_info_wrapper(paste0(file_info_suffix, "_", sublib_names))
  })

  # Call compare_sublibraries with the generated df_list and sublib_names
  result <- compare_df_list(df_list = c(list(Hits_all_sublibs), Hits_df_list),
                                name_list = c("all_sublibs", sublib_names),
                                FDR_threshold = FDR_threshold,
                                top_N = NULL,
                            correlation_heatmap = correlation_heatmap,
                            overlap = overlap,
                            venn_diagram = venn_diagram)
  
  return(result)
}

```

``` {r compare_calc_replicates_functions, eval=TRUE}

find_Hits_and_FDR_appearing_in_X_replicates <- function(df_list,
                                                        name_list,
                                                        FDR_threshold = 0.05,
                                                        X = NULL){
  if (is.null(X)){
    X <- length(df_list)
  }
  filtered_list <- vector("list", length(df_list))
  for (i in seq_along(df_list)){
    filtered_list[[i]] <- df_list[[i]] %>%
      apply_FDR_filter(FDR_threshold) %>% 
      mutate(source = name_list[i])
  }

  # Combine
  combined <- dplyr::bind_rows(filtered_list)

  # Count in how many *sources* each entrez appears (after filtering)
  entrez_keep <- combined %>%
    dplyr::distinct(entrez, source) %>%
    dplyr::count(entrez, name = "n_sources") %>%
    dplyr::filter(n_sources >= X) %>%
    dplyr::pull(entrez)

  # For kept entrez: choose the row with the highest FDR (ties broken deterministically)
  results_df <- combined %>%
    dplyr::filter(entrez %in% entrez_keep) %>%
    dplyr::arrange(entrez, dplyr::desc(FDR), source) %>%
    dplyr::group_by(entrez) %>%
    dplyr::slice(1) %>%
    dplyr::ungroup()

  new_FDR <- if (nrow(results_df) == 0) NA_real_ else max(results_df$FDR, na.rm = TRUE)
  return(list(results_df = results_df, new_FDR = new_FDR))
}

automate_calc_replicate_comparison <- function(file_info_suffix = get("file_info_suffix", envir = .GlobalEnv),
                                           FDR_threshold = 0.05,
                                           hits_in_X_reps = NULL,
                                          correlation_heatmap = TRUE,
                                          overlap = TRUE,
                                          venn_diagram = TRUE) {
  
  # Get the current settings from the global environment
  Hits_rep_0 <- add_info_wrapper(file_info_suffix)
  rds_output_folder <- get("rds_output_folder", envir = .GlobalEnv)
  
  # List all files in the rds output folder
  rds_files <- list.files(rds_output_folder, pattern = paste0(".*", file_info_suffix, "_rep[0-9]+\\.rds$"), full.names = TRUE)
  
  # Extract everything between file_info_suffix + "_" and ".rds"
  # e.g. "...<file_info_suffix>_no_sublib_L1.rds" -> "no_sublib_L1"
  rep_name <- sub(
    paste0(".*", file_info_suffix, "_rep(.+)\\.rds$"),
    "\\1",
    basename(rds_files)
  )
  rep_name <- unique(rep_name)
  rep_name_long <- paste0("calc_rep_", rep_name)
  rep_suffixes <- paste0(file_info_suffix, "_rep", rep_name)
  rep_suffixes <- unique(rep_suffixes)
  
  # Generate Hits_df_list using add_info_wrapper for each sublib_suffixes
  Hits_df_list <- lapply(rep_suffixes, function(rep_suffixes) {
    add_info_wrapper(rep_suffixes)
  })
  # Call compare_sublibraries with the generated df_list and sublib_names
  overlap_df <- compare_df_list(df_list = c(list(Hits_rep_0), Hits_df_list),
                                name_list = c("calc_rep_0", rep_name_long),
                                FDR_threshold = FDR_threshold,
                                top_N = NULL,
                            correlation_heatmap = correlation_heatmap,
                            overlap = overlap,
                            venn_diagram = venn_diagram)
  
  Hits_and_FDR <- find_Hits_and_FDR_appearing_in_X_replicates(df_list = c(list(Hits_rep_0), Hits_df_list),
                                                              name_list = c("calc_rep_0", rep_name_long),
                                                              X = hits_in_X_reps,
                                                              FDR_threshold = FDR_threshold)

  return(list(
    overlap_df = overlap_df,
    Hits_in_X_df = Hits_and_FDR$results_df,
    new_FDR = Hits_and_FDR$new_FDR
  ))
}
```

``` {r Calculated_replicated_analysis, eval=False}
high_confidence_hits <- automate_calc_replicate_comparison(FDR_threshold = 0.05,
                                                           hits_in_X_reps = 16,
                                                           correlation_heatmap = FALSE,
                                                           venn_diagram = FALSE)
explorative_hits <- automate_calc_replicate_comparison(FDR_threshold = 0.05,
                                                     hits_in_X_reps = 10,
                                                     correlation_heatmap = TRUE,
                                                     venn_diagram = FALSE)

excel_file_path <- sub("\\.rds$", ".xlsx", paste0(results_output_folder, "/", "Hits_high_confidence", file_suffix))
write_xlsx(high_confidence_hits$Hits_in_X_df, excel_file_path)
saveRDS(high_confidence_hits$Hits_in_X_df, get_file_path(rds_output_folder, paste0("high_confidence_hits","_",file_info_suffix,".rds")))
excel_file_path <- sub("\\.rds$", ".xlsx", paste0(results_output_folder, "/", "Hits_explorative", file_suffix))
write_xlsx(explorative_hits$Hits_in_X_df, excel_file_path)
saveRDS(explorative_hits$Hits_in_X_df, get_file_path(rds_output_folder, paste0("explorative_hits","_",file_info_suffix,".rds")))
```
## Compare Sublibraries 
For this to function You need to run data_analysis_with_MAUDE multiple times,
once without excluding sublibraries, and then at least once more with
one or more sublibraries excluded using the skip_list_sublib setting.
``` {r compare_sublibraries_analysis, eval=False}
test <- automate_sublibrary_comparison(FDR_threshold = 0.05)
```

``` {r compare_subsamples_analysis, eval=False}
if (FALSE){
  # run this once to move subsamples from the target dir, to the rds dir
  # of the current output folder
  move_subsamples("/g/steinmetz/link/Amplicon_barcode_analysis/PA_subsampeling/1/HepG2_dual_rep_PA_subsample", subsample_prefix = "A")
  move_subsamples("/g/steinmetz/link/Amplicon_barcode_analysis/PA_subsampeling/2/HepG2_dual_rep_PA_subsample", subsample_prefix = "B")
  move_subsamples("/g/steinmetz/link/Amplicon_barcode_analysis/PA_subsampeling/3/HepG2_dual_rep_PA_subsample", subsample_prefix = "C")
  move_subsamples("/g/steinmetz/link/Amplicon_barcode_analysis/PA_subsampeling/4/HepG2_dual_rep_PA_subsample", subsample_prefix = "D")
}
 
automate_subsample_comparison(FDR_threshold = 0.05)
```

``` {r control_distribution_heatmap, eval=FALSE}
library(pheatmap)
library(grid)
# 1) Add RPM per (condition, sublib, sample)
count_df_long2 <- count_df_long %>%
  group_by(condition, sublib, sample) %>%
  mutate(RPM = (count / sum(count)) * 1e6) %>%
  ungroup()

# 2) Remove targeting guides (not relevant for heatmap)
count_df_long2 <- count_df_long2 %>%
  filter(group_category != "targeting")

# 3) Make a column ID for the heatmap columns
count_df_long2 <- count_df_long2 %>%
  mutate(col_id = paste(condition, sublib, sample, sep = "_"))

# 4) Ensure 1 RPM value per (sgRNA, col_id)
#    (If there are duplicates, sum them — or you could use mean)
heatmap_df <- count_df_long2 %>%
  group_by(sgRNA, col_id) %>%
  summarise(RPM = sum(RPM), .groups = "drop")

# 5) Pivot to wide format for heatmap input
heatmap_wide <- heatmap_df %>%
  pivot_wider(names_from = col_id, values_from = RPM, values_fill = 0) %>%
  arrange(sgRNA)

# 6) Convert to matrix with sgRNA as rownames
heatmap_mat <- as.matrix(heatmap_wide[, -1])
rownames(heatmap_mat) <- heatmap_wide$sgRNA

chunk_size <- 60

# (optional) order rows by variance so "interesting" ones appear first
row_var <- apply(heatmap_mat, 1, var)
heatmap_mat <- heatmap_mat[order(row_var, decreasing = TRUE), , drop = FALSE]

# split row indices into chunks of 50
idx_list <- split(seq_len(nrow(heatmap_mat)),
                  ceiling(seq_len(nrow(heatmap_mat)) / chunk_size))

# list of matrices, each with up to 50 rows
heatmap_chunks <- lapply(idx_list, function(idx) heatmap_mat[idx, , drop = FALSE])

for (k in seq_along(heatmap_chunks)) {
  row_start <- min(idx_list[[k]])
  row_end   <- max(idx_list[[k]])

  pheatmap::pheatmap(
    heatmap_chunks[[k]],
    scale = "none",
    fontsize_row = 6,
    main = paste0("Heatmap ", k, " (rows ", row_start, "–", row_end, ")")
  )
}

pdf_file <- get_file_path(results_output_folder, "heatmaps_chunks_60rows.pdf")

grDevices::pdf(pdf_file, width = 10, height = 18, onefile = TRUE)
pdf_dev <- grDevices::dev.cur()   # <- store the pdf device id

for (k in seq_along(heatmap_chunks)) {

  row_start <- min(idx_list[[k]])
  row_end   <- max(idx_list[[k]])

  ph <- pheatmap::pheatmap(
    heatmap_chunks[[k]],
    scale = "none",
    main = paste0("Heatmap ", k, " (rows ", row_start, "–", row_end, ")"),
    fontsize_row = 6,
    silent = TRUE
  )

  grDevices::dev.set(pdf_dev)     # <- force drawing into the PDF device
  grid::grid.newpage()
  grid::grid.draw(ph$gtable)

  invisible(ph)                  # <- prevents knitr from printing it
}

grDevices::dev.off()


```

``` {r input_vs_plasmid_function, eval=TRUE}
scatter_merged_vs_input <- function(
  merged_sgRNA_df,
  count_df_long,
  normalization = c("none", "CPM"),
  group_category = "all",                 # "all" or c("entry1","entry2")
  condition_value = "input",
  sgrna_col_long = "sgRNA",
  sgrna_col_merged = "sgrna_id",
  count_col_long = "count",
  count_col_merged = "count",
  group_col = "group_category",
  condition_col = "condition",
  sample_col_long = "sample",             # optional; improves CPM
  sublib_col = "sublib",
  sublib_chosen = "all",
  transform = c("none", "log10", "log1p"),
  add_lm = TRUE,
  annotate_cor = TRUE,
  mark_outlier = TRUE,
  n_outliers = 10,
  symbol_col_merged = "symbol",           # used for labels; fall back to sgrna_id if missing/NA
  point_alpha = 0.5,
  point_size = 1,
  mark_essential = TRUE,
  essential_col_merged = "is_essential",
  essential_color = "red",
  essential_alpha = 0.9,
  essential_size = NULL,
  remove_essential = FALSE
) {
  normalization <- match.arg(normalization)
  transform <- match.arg(transform)

  stopifnot(
    all(c(sgrna_col_long, count_col_long, group_col, condition_col) %in% colnames(count_df_long)),
    all(c(sgrna_col_merged, count_col_merged) %in% colnames(merged_sgRNA_df))
  )
  if (!is.null(sample_col_long) && !(sample_col_long %in% colnames(count_df_long))) {
    stop("sample_col_long was provided but is not a column in count_df_long.")
  }

  # 1) filter to input + group_category selection
  df_in <- count_df_long %>%
    filter(.data[[condition_col]] == .env$condition_value)

  n_before <- nrow(df_in)
  if (!(length(group_category) == 1 && group_category == "all")) {
    df_in <- df_in %>%
      filter(.data[[group_col]] %in% .env$group_category)
  }
  n_after <- nrow(df_in)
  message("Rows before/after group filter: ", n_before, " -> ", n_after)
  
  n_before <- nrow(df_in)
  if (!(length(sublib_chosen) == 1 && sublib_chosen == "all")) {
    df_in <- df_in %>%
      filter(.data[[sublib_col]] %in% .env$sublib_chosen)
  }
  n_after <- nrow(df_in)
  message("Rows before/after sublibrary filter: ", n_before, " -> ", n_after)
  
  
  
  essential_df <- readRDS(file.path(data_dir, "dependency_df.rds")) %>%
    mutate(entrez = as.character(entrez_id)) %>%
    select(-c(gene_symbol, entrez_id)) %>%
    mutate(
      is_essential = if_any(
        c(essential_HepG2, essential_general, essential_liver),
        ~ tidyr::replace_na(.x, FALSE)
      )
    )
  
  merged_sgRNA_df <- merged_sgRNA_df %>%
    mutate(entrez = as.character(entrez)) %>%   # ensure same type for join
    left_join(essential_df, by = "entrez")
  
  # 2) normalize (optional) then mean per sgRNA
  if (normalization == "CPM") {
    if (!is.null(sample_col_long)) {
      df_in <- df_in %>%
        group_by(.data[[sample_col_long]]) %>%
        mutate(.cpm = (.data[[count_col_long]] / sum(.data[[count_col_long]], na.rm = TRUE)) * 1e6) %>%
        ungroup()

      in_sum <- df_in %>%
        group_by(.data[[sgrna_col_long]]) %>%
        summarise(input_mean = mean(.cpm, na.rm = TRUE), .groups = "drop")
    } else {
      total <- sum(df_in[[count_col_long]], na.rm = TRUE)
      df_in <- df_in %>% mutate(.cpm = (.data[[count_col_long]] / total) * 1e6)

      in_sum <- df_in %>%
        group_by(.data[[sgrna_col_long]]) %>%
        summarise(input_mean = mean(.cpm, na.rm = TRUE), .groups = "drop")
    }

    merged_plot_df <- merged_sgRNA_df %>%
      mutate(merged_value = (.data[[count_col_merged]] / sum(.data[[count_col_merged]], na.rm = TRUE)) * 1e6)
  } else {
    in_sum <- df_in %>%
      group_by(.data[[sgrna_col_long]]) %>%
      summarise(input_mean = mean(.data[[count_col_long]], na.rm = TRUE), .groups = "drop")

    merged_plot_df <- merged_sgRNA_df %>%
      mutate(merged_value = .data[[count_col_merged]])
  }

  # Build label: prefer symbol, fall back to sgrna_id; if symbol col missing, use sgrna_id
  has_symbol <- !is.null(symbol_col_merged) && (symbol_col_merged %in% colnames(merged_plot_df))
  merged_plot_df <- merged_plot_df %>%
    mutate(.label = if (has_symbol) {
      dplyr::coalesce(as.character(.data[[symbol_col_merged]]),
                     as.character(.data[[sgrna_col_merged]]))
    } else {
      as.character(.data[[sgrna_col_merged]])
    })

  # 3) join (match sgRNA ids) — use all_of() in tidyselect contexts
  in_sum2 <- in_sum %>%
    rename(sgrna_id_join = all_of(sgrna_col_long))

  merged_min <- merged_plot_df %>%
    select(all_of(c(sgrna_col_merged, "merged_value", ".label")),
           any_of(essential_col_merged)) %>%                # safe if column missing
    rename(sgrna_id_join = all_of(sgrna_col_merged)) %>%
    mutate(.essential = dplyr::coalesce(.data[[essential_col_merged]], FALSE))


  joined <- in_sum2 %>% inner_join(merged_min, by = "sgrna_id_join")
  
  if (remove_essential){
    joined <- joined %>% filter(!is_essential)
  }
  
  if (nrow(joined) == 0) {
    stop("Join produced 0 rows. Check that sgRNA IDs match between the two data frames.")
  }

  # Fit LM once (needed for outlier distances and optionally for drawing the line)
  fit <- lm(input_mean ~ merged_value, data = joined)
  b <- unname(coef(fit)[["(Intercept)"]])
  m <- unname(coef(fit)[["merged_value"]])

  # Perpendicular distance from point to line y = m x + b:
  # distance = | -m*x + y - b | / sqrt(m^2 + 1)
  if (mark_outlier) {
    joined <- joined %>%
      mutate(.dist = abs((-m) * merged_value + input_mean - b) / sqrt(m^2 + 1))
  
    n_keep <- min(n_outliers, nrow(joined))
  
    outliers <- joined %>%
      arrange(desc(.dist)) %>%
      slice_head(n = n_keep)
  }

  # 4) plot
  p <- ggplot(joined, aes(x = merged_value, y = input_mean)) +
    geom_point(alpha = point_alpha, size = point_size) +
    labs(
      x = paste0("plasmid count", ifelse(normalization == "CPM", " (CPM)", "")),
      y = paste0("mean input ", count_col_long, ifelse(normalization == "CPM", " (CPM)", "")),
      title = paste(
        "Plasmid counts vs mean input counts for",
        paste(group_category, collapse = ", "),
        "Norm:", normalization
      )
    ) +
    theme_classic()


  if (transform == "log10") {
    p <- p + scale_x_log10() + scale_y_log10()
  } else if (transform == "log1p") {
    p <- p + scale_x_continuous(trans = "log1p") + scale_y_continuous(trans = "log1p")
  }

  if (annotate_cor) {
    r <- suppressWarnings(cor(joined$merged_value, joined$input_mean, use = "pairwise.complete.obs"))
    p <- p + annotate(
      "text",
      x = Inf, y = Inf, hjust = 1.1, vjust = 1.2,
      label = sprintf("Pearson r = %.3f\nn = %d", r, nrow(joined))
    )
  }

  # label top outliers
  if (mark_outlier && nrow(outliers) > 0) {
    if (requireNamespace("ggrepel", quietly = TRUE)) {
      p <- p + ggrepel::geom_text_repel(
        data = outliers,
        aes(label = .label),
        max.overlaps = Inf
      )
    } else {
      p <- p + geom_text(
        data = outliers,
        aes(label = .label),
        vjust = -0.5,
        check_overlap = TRUE
      )
    }
  }
  if (mark_essential) {
    if (is.null(essential_size)) essential_size <- point_size
    p <- p + geom_point(
      data = dplyr::filter(joined, .essential),
      aes(x = merged_value, y = input_mean),
      color = essential_color,
      alpha = essential_alpha,
      size = essential_size
    )
  }
    # draw LM line (using the same fit we used for distances)
  if (add_lm) {
    p <- p + geom_abline(intercept = b, slope = m, color = "blue")
  }
  
  print(p)
  list(plot = p, data = joined)
}

```

```{r input_vs_plasmid, eval=FALSE}
res <- scatter_merged_vs_input(merged_sgRNA_df, count_df_long,
                               normalization = "CPM",
                               group_category = "all",
                               point_size = 0.5)
res <- scatter_merged_vs_input(merged_sgRNA_df, count_df_long,
                               normalization = "CPM",
                               group_category = "all",
                               remove_essential = TRUE,
                               point_size = 0.5)

res <- scatter_merged_vs_input(merged_sgRNA_df, count_df_long,
                               normalization = "CPM",
                               group_category = c("targeting"),
                               sublib_chosen = "sublib_4",
                               point_size = 0.5)
res <- scatter_merged_vs_input(merged_sgRNA_df, count_df_long,
                               normalization = "CPM",
                               group_category = c("non_targeting_control"),
                               sublib_chosen = "sublib_4",
                               mark_outlier = FALSE,
                               point_size = 0.5)
res <- scatter_merged_vs_input(merged_sgRNA_df, count_df_long,
                               normalization = "none",
                               group_category = c("non_targeting_control"),
                               sublib_chosen = "sublib_4",
                               mark_outlier = FALSE,
                               point_size = 0.5)

```

``` {r Manhattan_plot, eval=False}
Hits_current_settings <- add_info_wrapper(file_info_suffix)
if (length(include_controls_list) > 0) {
  for (control_gene in include_controls_list) {
    # here we remove everything after the last _, so stuff like AAVS1_9 and
    # AAVS1_13 are both treated as AAVS1
    control_gene <- sub("_[^_]*$", "", control_gene)
    Hits_current_settings$symbol[grepl(control_gene, Hits_current_settings$entrez)] <- control_gene
  }
  # Filter out rows where the 'symbol' is in the include_controls_list
  Hits_current_settings_no_controls <- Hits_current_settings %>% 
    filter(!symbol %in% include_controls_list | is.na(symbol))
}
Hits_df <- Hits_current_settings %>% 
  filter(significanceZ <= 0) %>% 
  mutate(logP = -log10(FDR))

# Define the cluster and protein names
clusters <- data.frame(
  cluster_name = c(
    "Protein ufmylation", 
    "mTORC1-mediated signalling (Ragulator complex/RagC protein)", 
    "vesicles thetering complex (HOPS complex)", 
    "ER membrane insertion complex, and GET complex", 
    "GTPase activating proteins (GAP)", 
    "Regulation of lysosome size (BLOC-1 and BORC complexes)", 
    "Other VPS proteins", 
    "Other Rab proteins"
  ),
  color = c(
    "#ff0000", "#ffe065", "#47b200", "#65ffa3", 
    "#008eb2", "#6566ff", "black", "black"
  ),
  proteins = c(
    "UFL1, CDK5RAP3, UFM1, UBA5", 
    "LAMTOR1, RRAGC, LAMTOR5", 
    "VPS39, VPS33A, VPS41", 
    "BAG6, GET1, GET4", 
    "RAB3GAP1, RAB3GAP2, TBC1D20", 
    "BLOC1S1, SNAPIN", 
    "VPS13C, VPS53", 
    "RAB18"
  )
)

# Flatten protein names into a list
protein_list <- unlist(strsplit(clusters$proteins, ", "))

# Create a new column in Hits_df to mark the cluster for each protein
Hits_df$cluster <- sapply(Hits_df$symbol, function(x) {
  # Check which cluster the protein belongs to
  match <- which(sapply(clusters$proteins, function(proteins) x %in% strsplit(proteins, ", ")[[1]]))
  if (length(match) > 0) {
    return(clusters$cluster_name[match])
  } else {
    return("Other")  # Default category for proteins not listed
  }
})

Hits_df$cluster_color <- sapply(Hits_df$cluster, function(x) {
  # Check if the cluster is in the list, else assign grey
  if (x %in% clusters$cluster_name) {
    return(clusters$color[clusters$cluster_name == x])
  } else {
    return("grey")  # Assign grey to other genes
  }
})
# Define the clusters excluding "Other"
clusters_excluding_other <- unique(Hits_df$cluster[Hits_df$cluster != "Other"])

# Define the number of clusters excluding "Other"
num_clusters <- length(clusters_excluding_other)

# Define the size of each cluster's range (divide 1000 by the number of clusters - 1)
range_size <- 1000 / (num_clusters)

# Initialize a vector to store the ranks
rank_vector <- numeric(nrow(Hits_df))

# Loop through each cluster excluding "Other"
for (cluster_name in clusters_excluding_other) {
  # Get the rows for the current cluster
  cluster_rows <- Hits_df$cluster == cluster_name
  
  # Calculate the range for this cluster
  cluster_start <- (which(clusters_excluding_other == cluster_name) - 1) * range_size + 1
  cluster_end <- cluster_start + range_size - 1
  
  # Assign random ranks within this cluster's range
  rank_vector[cluster_rows] <- sample(cluster_start:cluster_end, sum(cluster_rows), replace = TRUE)
}

# Assign ranks to "Other" cluster (random ranks from 1 to 1000)
rank_vector[Hits_df$cluster == "Other"] <- sample(1:1000, sum(Hits_df$cluster == "Other"), replace = TRUE)

# Add the new rank column to the Hits_df dataframe
Hits_df$rank <- rank_vector

# Create the Manhattan plot
p <- ggplot(Hits_df, aes(x = rank, y = significanceZ, color = cluster_color)) +
  geom_point(aes(size = ifelse(cluster != "Other", 3, 1)), alpha = 0.8) +
  scale_size_continuous(range = c(1, 5)) +
  scale_y_reverse() +
  #scale_y_log10() +
  scale_color_identity() +  # Use the actual colors defined for each cluster
  labs(
    title = "Non-Essential Gene Groups",
    y = "significanceZ"
  ) +
  theme_classic() +
  theme(
    legend.position = "none",  # Remove legend for clusters (you can add one if needed)
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    
    # Remove X-axis and its label, ticks, and lines
    axis.line.x = element_blank(),
    axis.text.x = element_blank(),
    axis.title.x = element_blank(),
    axis.ticks.x = element_blank()
  ) + 
  # Use geom_text_repel to avoid label overlap and label non-"Other" points
  geom_text_repel(
    data = subset(Hits_df, cluster != "Other"),  # Only label non-"Other" points
    aes(x = rank, y = significanceZ, label = symbol),
    color = "black",
    size = 3,
    box.padding = 0.1,  # Increase to move text away from points if needed
    point.padding = 0.2,  # Adjust text padding around points
    max.overlaps = 10,   # Adjust this value to limit the number of overlaps
    segment.color = NA,  # No lines connecting text and point
    vjust = -2          # Position text above the dot
  )

# Display the plot
print(p)

cluster_labels <- clusters
# Create a blank plot with adjusted limits
# Create a blank plot with adjusted limits
# Create a blank plot with adjusted limits
plot(
  x = 1, y = 1, type = "n", 
  xlim = c(0, 500), ylim = c(1, nrow(cluster_labels) + 1),  # Increase xlim to make space for the text
  xlab = "", ylab = "", 
  axes = FALSE,  # Remove axes
  main = "Cluster Names and Colors"
)

# Plot each cluster with a single dot and its name next to it
for (i in 1:nrow(cluster_labels)) {
  # Plot the dot on the left (x = 0) for each cluster (ensure the dot is visible)
  points(1, nrow(cluster_labels) - i + 1, pch = 16, cex = 2, col = cluster_labels$color[i])  
  # Add the cluster name to the right of the dot (slightly shifted right)
  text(1.5, nrow(cluster_labels) - i + 1, cluster_labels$cluster_name[i], pos = 4, cex = 1.2)  
}

```

``` {r test_1s, eval=FALSE}
# 1. Count the number of 1s in the input, lower, and upper columns individually
count_1s_input <- sum(maude_counts_df$input == 1)
count_1s_lower <- sum(maude_counts_df$lower == 1)
count_1s_upper <- sum(maude_counts_df$upper == 1)

# Print individual counts
cat("Count of 1's in 'input':", count_1s_input, "\n")
cat("Count of 1's in 'lower':", count_1s_lower, "\n")
cat("Count of 1's in 'upper':", count_1s_upper, "\n")

# 2. Count rows where all three columns are 1 (input, lower, upper)
count_all_ones <- sum(maude_counts_df$input == 1 & maude_counts_df$lower == 1 & maude_counts_df$upper == 1)
cat("Rows where all three columns are 1:", count_all_ones, "\n")

# 3. Separate counts based on 'isNontargeting' column (TRUE and FALSE)

# For rows where 'isNontargeting' is TRUE
df_true <- maude_counts_df[maude_counts_df$isNontargeting == TRUE, ]
count_1s_input_true <- sum(df_true$input == 1)
count_1s_lower_true <- sum(df_true$lower == 1)
count_1s_upper_true <- sum(df_true$upper == 1)
count_all_ones_true <- sum(df_true$input == 1 & df_true$lower == 1 & df_true$upper == 1)

cat("\nFor isNontargeting == TRUE:\n")
cat("Count of 1's in 'input':", count_1s_input_true, "\n")
cat("Count of 1's in 'lower':", count_1s_lower_true, "\n")
cat("Count of 1's in 'upper':", count_1s_upper_true, "\n")
cat("Rows where all three columns are 1:", count_all_ones_true, "\n")

# For rows where 'isNontargeting' is FALSE
df_false <- maude_counts_df[maude_counts_df$isNontargeting == FALSE, ]
count_1s_input_false <- sum(df_false$input == 1)
count_1s_lower_false <- sum(df_false$lower == 1)
count_1s_upper_false <- sum(df_false$upper == 1)
count_all_ones_false <- sum(df_false$input == 1 & df_false$lower == 1 & df_false$upper == 1)

cat("\nFor isNontargeting == FALSE:\n")
cat("Count of 1's in 'input':", count_1s_input_false, "\n")
cat("Count of 1's in 'lower':", count_1s_lower_false, "\n")
cat("Count of 1's in 'upper':", count_1s_upper_false, "\n")
cat("Rows where all three columns are 1:", count_all_ones_false, "\n")

```

```{r Roche_compare_functions, eval=FALSE}
Hits_current_settings <- add_info_wrapper(file_info_suffix)
if (length(include_controls_list) > 0) {
  for (control_gene in include_controls_list) {
    # here we remove everything after the last _, so stuff like AAVS1_9 and
    # AAVS1_13 are both treated as AAVS1
    control_gene <- sub("_[^_]*$", "", control_gene)
    Hits_current_settings$symbol[grepl(control_gene, Hits_current_settings$entrez)] <- control_gene
  }
  # Filter out rows where the 'symbol' is in the include_controls_list
  Hits_current_settings_no_controls <- Hits_current_settings %>% 
    filter(!symbol %in% include_controls_list | is.na(symbol))
}

roche_folder <- make_clean_dir(output_folder, "/Roche_compare")
sup_3_path <- get_file_path(roche_folder, "41467_2025_61039_MOESM5_ESM.xls")
sup_3 <- read_excel(sup_3_path)
sup_3$GeneID <- gsub("GeneID:", "", sup_3$GeneID)

compare_df <- sup_3 %>% 
  rename(Rho_pos = Rho_Round1Pos_to_Bulk_enriched,
         Rho_neg = Rho_Round1Neg_to_Bulk_enriched,
         entrez = GeneID,
         symbol = Symbol,
         LFC_pos = MedianLFC_Round1Pos_to_Bulk_enriched,
         LFC_neg = MedianLFC_Round1Neg_to_Bulk_enriched) %>% 
  select(entrez, symbol, Rho_pos, Rho_neg, LFC_pos,LFC_neg)

waterfall_roche_compare <- function(Hits_df,
                                      comp_df,
                                      signif_lines = TRUE,
                                      signif_level = 0.05,
                                      box_padding = 0.8,
                                      no_text = FALSE,
                                      mark_special = NULL,
                                      rho_neg_thresh = 0.0001,
                                      rho_pos_thresh = 0.0001,
                                      lfc_neg_thresh = 1.5,
                                      lfc_pos_thresh = 1.5) {
  
  # Create rank column
  Hits_df <- Hits_df %>%
    mutate(rank = rank(significanceZ, ties.method = "first"))
  signif_df <- Hits_df %>% 
    filter(FDR <= signif_level)
  # Define the Limits for annotation boxes
  y_min   <- min(Hits_df$significanceZ, na.rm = TRUE)
  y_max   <- max(Hits_df$significanceZ, na.rm = TRUE)
  y_range <- y_max - y_min
  
  # Box geometry (relative to overall range)
  box_height <- 0.06 * y_range   # 8% of range high
  box_gap    <- 0.02 * y_range   # 3% of range between boxes
  
  # Centers of the two boxes (on y-axis)
  y_center1 <- y_min           # lower box
  y_center2 <- y_center1 + box_height + box_gap    # upper box
  
  # x range (can reuse for both boxes)
  x_min_box <- max(Hits_df$rank) - 3000
  x_max_box <- max(Hits_df$rank) + 500
  
  # Filter for Rho_neg and Rho_pos hits from comp_df
  rho_neg_hits_df <- comp_df %>%
    filter(Rho_neg <= rho_neg_thresh & 2^LFC_neg >= lfc_neg_thresh) %>%
    rename(symbol_rho = symbol)  # Rename the symbol to avoid conflict
  
  rho_pos_hits_df <- comp_df %>%
    filter(Rho_pos <= rho_pos_thresh & 2^LFC_pos >= lfc_pos_thresh) %>%
    rename(symbol_rho = symbol)  # Rename the symbol to avoid conflict
  
  # Filter only the rows in Hits_df that are in rho_neg_hits_df and rho_pos_hits_df
  rho_neg_hits_df <- inner_join(Hits_df, rho_neg_hits_df, by = "entrez")
  rho_pos_hits_df <- inner_join(Hits_df, rho_pos_hits_df, by = "entrez")
  
  # Start base plot
  p <- ggplot(Hits_df, aes(x = rank, y = significanceZ)) +
    geom_point(color = "lightgrey", size = 1) +
    geom_hline(yintercept = 0, linetype = "dashed", color = "black", size = 0.3) +
    theme_bw() +
    labs(
      x = "Gene rank",
      y = "Significance Z-score",
      title = "Significance Z-score by gene rank"
    )
  
  # Mark Rho_neg hits
  if (nrow(rho_neg_hits_df) > 0) {
    p <- p + 
      geom_point(
        data = rho_neg_hits_df,
        aes(x = rank, y = significanceZ),
        color = "cyan", size = 2
      ) +
      annotate("rect",
               xmin = x_min_box,
               xmax = x_max_box,
               ymin = y_center2 - box_height / 2,
               ymax = y_center2 + box_height / 2,
               fill = "white", color = "black", size = 0.3) +
      annotate("point",
               x = x_min_box + 200,
               y = y_center2,
               color = "cyan", size = 2) +
      annotate("text",
               x = x_min_box + 400,
               y = y_center2,
               label = "Rho Neg hits", hjust = 0, size = 3)
  }

  # Mark Rho_pos hits
  if (nrow(rho_pos_hits_df) > 0) {
    p <- p + 
      geom_point(
        data = rho_pos_hits_df,
        aes(x = rank, y = significanceZ),
        color = "orange", size = 2
      ) +
      annotate("rect",
               xmin = x_min_box,
               xmax = x_max_box,
               ymin = y_center1 - box_height / 2,
               ymax = y_center1 + box_height / 2,
               fill = "white", color = "black", size = 0.3) +
      annotate("point",
               x = x_min_box + 200,
               y = y_center1,
               color = "orange", size = 2) +
      annotate("text",
               x = x_min_box + 400,
               y = y_center1,
               label = "Rho Pos hits", hjust = 0, size = 3)
  }

  # Add lines if requested (now based on input threshold for significance)
  
  if (isTRUE(signif_lines)) {

    ## Lowest positive significanceZ (closest to zero, > 0)
    pos_df <- signif_df %>% filter(significanceZ > 0)
    if (nrow(pos_df) > 0) {
      y_pos <- min(pos_df$significanceZ, na.rm = TRUE)
      p <- p +
        geom_hline(
          yintercept = y_pos,
          linetype = "dashed",
          color = "red",
          size = 0.3
        )
    }

    ## Negative significanceZ with smallest absolute value (closest to zero)
    neg_df <- signif_df %>% filter(significanceZ < 0)
    if (nrow(neg_df) > 0) {
      # largest negative value, e.g. -1 is "closer to zero" than -3
      y_neg <- max(neg_df$significanceZ, na.rm = TRUE)
      p <- p +
        geom_hline(
          yintercept = y_neg,
          linetype = "dashed",
          color = "red",
          size = 0.3
        )
    }
  }

  
  # Mark special symbols (can be multiple)
  if (!is.null(mark_special) && length(mark_special) > 0 && "symbol" %in% names(Hits_df)) {
    special_df <- Hits_df %>% filter(symbol %in% mark_special)
    
    if (nrow(special_df) > 0) {
      p <- p +
        geom_point(
          data = special_df,
          aes(x = rank, y = significanceZ),
          shape = 17,
          color = "orange",
          size = 4
        ) +
        geom_text_repel(
          data = special_df,
          aes(x = rank, y = significanceZ, label = symbol),
          color = "orange",
          size = 4,
          box.padding = 1,
          nudge_x = ifelse(special_df$significanceZ > 0, -500, 500),
          nudge_y = ifelse(special_df$significanceZ > 0, y_range * (0.05), y_range * (-0.05)),
          force = 4
        )
    }
  }
  
  return(p)
}

make_cor_heatmap <- function(df, name = ""){
  # Select only the numeric columns (exclude non-numeric columns like symbol, entrez, etc.)
  cor_df <- df %>% select(-c(symbol, entrez, numGuides, seq, sgRNA))
  
  # Compute the Pearson correlation matrix
  cor_matrix <- cor(cor_df, method = "pearson")
  
  # Reshape the correlation matrix for ggplot2
  melted_cor_matrix <- reshape::melt(cor_matrix)
  
  # Ensure the variable names are correctly assigned for ggplot
  colnames(melted_cor_matrix) <- c("Var1", "Var2", "value")  # Rename columns
  
  # Create a heatmap of the correlation matrix
  p <- ggplot(melted_cor_matrix, aes(x = Var1, y = Var2, fill = value)) +
    geom_tile() +
    scale_fill_gradient2(low = "red", high = "green", mid = "white", midpoint = 0) +
    theme_bw() +
    labs(title = paste("Pearson Correlation Heatmap", name)) +
    theme(axis.text.x = element_text(angle = 25, hjust = 1)) 
  
  print(p)
  return(cor_matrix)
}


```

``` {r Roche_compare, eval=FALSE}

roche_folder <- make_clean_dir(output_folder, "/Roche_compare")
sup_3_path <- get_file_path(roche_folder, "41467_2025_61039_MOESM5_ESM.xls")
sup_3 <- read_excel(sup_3_path)

sup_3$GeneID <- gsub("GeneID:", "", sup_3$GeneID)
sup_3 <- sup_3 %>%
  rename(
    entrez = GeneID,
    Rho_enriched = Rho_Bulk_to_Reference_enriched,
    MedianLFC_enriched = MedianLFC_Bulk_to_Reference_enriched,
    AdjPval_enriched = AdjPval_Bulk_to_Reference_enriched,
    Pval_enriched = Pval_Bulk_to_Reference_enriched,
    RhoRank_enriched = RhoRank_Bulk_to_Reference_enriched,
    Rho_depleted = Rho_Bulk_to_Reference_depleted,
    MedianLFC_depleted = MedianLFC_Bulk_to_Reference_depleted,
    AdjPval_depleted = AdjPval_Bulk_to_Reference_depleted,
    Pval_depleted = Pval_Bulk_to_Reference_depleted,
    RhoRank_depleted = RhoRank_Bulk_to_Reference_depleted
  ) %>% 
  select(
    entrez,
    Rho_enriched,
    MedianLFC_enriched,
    AdjPval_enriched,
    Pval_enriched,
    RhoRank_enriched,
    Rho_depleted,
    MedianLFC_depleted,
    AdjPval_depleted,
    Pval_depleted,
    RhoRank_depleted
  )
compare_df <- merge(sup_3, export_df, by = "entrez")
###############################################################################
# Venn Diagramm as requested by Nico
nico_compare_df <- sup_3 %>% 
  rename(Rho_pos = Rho_Round1Pos_to_Bulk_enriched,
         Rho_neg = Rho_Round1Neg_to_Bulk_enriched,
         entrez = GeneID,
         symbol = Symbol,
         LFC_pos = MedianLFC_Round1Pos_to_Bulk_enriched,
         LFC_neg = MedianLFC_Round1Neg_to_Bulk_enriched) %>% 
  select(entrez, symbol, Rho_pos, Rho_neg, LFC_pos,LFC_neg)
nico_compare_df <- merge(nico_compare_df, export_df, by = "entrez")

  

nico_hits_intersect_top_neg <- nico_compare_df %>% filter(significanceZ > 0 & FDR <= 0.05 & Rho_neg <= 0.0001 & 2^LFC_neg >= 1.5)
nico_hits_intersect_low_pos <- nico_compare_df %>% filter(significanceZ < 0 & FDR <= 0.05 & Rho_pos <= 0.0001 & 2^LFC_pos >= 1.5)

our_hits_df <- nico_compare_df %>% filter(significanceZ > 0 & FDR <= 0.05)
roche_hits_df <- nico_compare_df %>% filter(Rho_neg <= 0.0001 & 2^LFC_neg >= 1.5)

our_hits <- our_hits_df$entrez
roche_hits <- roche_hits_df$entrez


# Create the Venn as a grob (plot object)
venn_2 <- venn.diagram(
  x = list(
    our_hits = our_hits,
    roche_hits = roche_hits
  ),
  filename = NULL,          # NULL = return a grid object instead of saving to file
  fill = c("purple", "cyan"),
  alpha = 0.5,              # transparency
  cex = 1.5, 
  cat.pos  = c(0, 0),      # 90° = above each circle
  cat.dist = c(0.05, 0.05),  # distance from the circle border
  cat.cex  = 1.5# size of set names
)

# Draw it in the plotting window
grid.newpage()
grid.draw(venn_2)


our_hits_df <- nico_compare_df %>% filter(significanceZ < 0 & FDR <= 0.05)
roche_hits_df <- nico_compare_df %>% filter(Rho_pos <= 0.0001 & 2^LFC_pos >= 1.5)

our_hits <- our_hits_df$entrez
roche_hits <- roche_hits_df$entrez


# Create the Venn as a grob (plot object)
venn_2 <- venn.diagram(
  x = list(
    our_hits = our_hits,
    roche_hits = roche_hits
  ),
  filename = NULL,          # NULL = return a grid object instead of saving to file
  fill = c("red", "yellow"),
  alpha = 0.5,              # transparency
  cex = 1.5, 
  cat.pos  = c(0, 0),      # 90° = above each circle
  cat.dist = c(0.05, 0.05),  # distance from the circle border
  cat.cex  = 1.5# size of set names
)

# Draw it in the plotting window
grid.newpage()
grid.draw(venn_2)
###############################################################################





waterfall_roche_compare(Hits_current_settings_no_controls, compare_df)



################################################################################
upper_cut <- compare_df %>% 
  filter(significanceZ > 0)
under_cut <- compare_df %>% 
  filter(significanceZ < 0)

significant_df <- compare_df %>%
  filter(FDR <= 0.05 | AdjPval_enriched <= 0.05 | AdjPval_depleted <= 0.05)

significanter_df <- compare_df %>%
  filter((FDR <= 0.05 & AdjPval_enriched <= 0.05) | (AdjPval_depleted <= 0.05 & FDR <= 0.05))

colnames(compare_df)
ggplot(compare_df, aes(x = MedianLFC_enriched, y = significanceZ)) +
  geom_point() +  # Add points for scatter plot
  labs(x = "Median LFC Enriched", y = "Significance Z", 
       title = "compare_df: Median LFC Enriched vs. Significance Z") +
  theme_bw()  # Optional: for a clean, minimalistic theme
ggplot(significant_df, aes(x = MedianLFC_enriched, y = significanceZ)) +
  geom_point() +  # Add points for scatter plot
  labs(x = "Median LFC Enriched", y = "Significance Z", 
       title = "significant_df: Median LFC Enriched vs. Significance Z") +
  theme_bw()  # Optional: for a clean, minimalistic theme
# Calculate Spearman rank correlation between two columns
spearman_corr <- cor.test(compare_df$AdjPval_enriched, compare_df$FDR, method = "spearman")
# Print the result
print(spearman_corr)

spearman_corr <- cor.test(compare_df$Pval_enriched, compare_df$p.value, method = "spearman")
# Print the result
print(spearman_corr)

spearman_corr <- cor.test(compare_df$MedianLFC_enriched, compare_df$significanceZ, method = "spearman")
# Print the result
print(spearman_corr)
spearman_corr <- cor.test(significant_df$MedianLFC_depleted, significant_df$significanceZ, method = "spearman")
# Print the result
print(spearman_corr)

cor_df <- compare_df %>% select(-c(symbol, entrez, numGuides, seq, sgRNA, ))
cor_matrix <- cor(cor_df, method = "pearson")



make_cor_heatmap(compare_df, "compare_df")
make_cor_heatmap(under_cut, "under_cut")
make_cor_heatmap(upper_cut, "upper_cut")
print(make_cor_heatmap(significant_df, "significant_df"))

excel_file_path <- get_file_path(output_folder,"roche_us_overlap.xlsx")
write_xlsx(significanter_df, excel_file_path)
```

``` {r Autophagy_compare, eval=FALSE}
autophagy_path <- get_file_path(roche_folder, "Autophagy_Genes.xlsx")
autophagy_df <- read_excel(autophagy_path)
autophagy_compare_df <- merge(autophagy_df, Hits_current_settings, by = "entrez")

print(setdiff(autophagy_df$Autophagy_gene, autophagy_compare_df$Autophagy_gene))
```

``` {r sublibrary_compare, eval=FALSE}
library(dplyr)
library(tidyr)
library(stringr)
library(purrr)
library(ggplot2)
library(tibble)

norm_count_df_long <- normalize_count_df_long(count_df_long, norm_method = "control_median")

df <- norm_count_df_long %>%
  left_join(
    merged_sgRNA_df %>% select(sgrna_id, entrez),
    by = c("sgRNA" = "sgrna_id")
  ) %>%
  mutate(
    # EXACTLY what you asked: NA entrez -> sgRNA
    feature = if_else(is.na(entrez), sgRNA, as.character(entrez))

    # If you prefer matching across sublibs for the NA cases, use this instead:
    # feature = if_else(is.na(entrez), str_remove(sgRNA, "_\\d+$"), as.character(entrez))
  )
df_aggr <- df %>%
  group_by(condition, sublib, feature) %>%
  summarise(value = sum(count), .groups = "drop")
df_wide <- df_aggr %>%
  pivot_wider(names_from = sublib, values_from = value)

g <- df_wide %>% group_by(condition)
keys <- group_keys(g)$condition

cors_by_condition <- g %>%
  group_map(~{
    mat <- as.matrix(select(.x, where(is.numeric)))
    cor(mat, method = "spearman", use = "pairwise.complete.obs")
  }) %>%
  set_names(keys)



plot_cor_heatmap <- function(C, title = NULL) {
  as.data.frame(C) %>%
    rownames_to_column("lib1") %>%
    pivot_longer(-lib1, names_to = "lib2", values_to = "rho") %>%
    ggplot(aes(x = lib1, y = lib2, fill = rho)) +
    geom_tile() +
    geom_text(aes(label = sprintf("%.2f", rho)), size = 3) +
    coord_equal() +
    scale_fill_gradient2(limits = c(-1, 1)) +
    labs(title = title, x = NULL, y = NULL, fill = "Spearman\nρ") +
    theme_minimal(base_size = 12) +
    theme(
      panel.grid = element_blank(),
      axis.text.x = element_text(angle = 45, hjust = 1)
    )
}

# Create one plot per condition (cors_by_condition is a named list)
cor_plots <- imap(cors_by_condition, ~plot_cor_heatmap(.x, title = paste("Correlation heatmap:", .y)))
# 
# # Show one (e.g. input)
# cor_plots$input

# Or print all
walk(cor_plots, print)
```

``` {r Liangfu_Plots_1, eval=FALSE}
library(dplyr)
library(ggplot2)

count_df_long %>%
  filter(count > 0) %>%                      # log2 needs >0
  mutate(log2_count = log2(count)) %>%       # bins in log2 space
  ggplot(aes(x = log2_count)) +
  geom_histogram(bins = 50, boundary = 0) +
  facet_grid(condition ~ sublib) +
  labs(x = "log2(read count)", y = "Number of sgRNAs") +
  theme_bw()
# all unique (condition, sublib) combinations
groups <- count_df_long %>%
  distinct(condition, sublib)

for (i in seq_len(nrow(groups))) {

  this_condition <- groups$condition[i]
  this_sublib    <- groups$sublib[i]

  df_sub <- count_df_long %>%
    filter(condition == this_condition,
           sublib == this_sublib,
           count > 0) %>%                # needed for log2()
    mutate(log2_count = log2(count))

  p <- ggplot(df_sub, aes(x = log2_count)) +
    geom_histogram(bins = 50, fill = "blue", color = "white") +
    labs(
      title = paste("Condition:", this_condition, "| SubLib:", this_sublib),
      x = "log2(read count)",
      y = "Number of sgRNAs"
    ) +
    theme_bw() +
    theme(
      plot.margin = margin(t = 15, r = 10, b = 10, l = 10),
      plot.title = element_text(margin = margin(b = 10))
    ) +
    coord_cartesian(xlim = c(0, 15), ylim = c(0, 3000))
  print(p)  # important inside a loop
}

library(dplyr)
library(tibble)

coverage_df <- tibble(
  sample = c("I_L1_1", "I_L3_1", "I_L5_1",
             "L_L1_1", "L_L3_1", "L_L5_1",
             "U_L1_1", "U_L3_1", "U_L5_1"),
  coverage = c(100.00, 100.00, 100.00,
               99.99,  99.99,  99.96,
               99.99,  99.98,  99.99)
)
coverage_df <- tibble(
  sample = c("I_L1_1", "I_L3_1", "I_L5_1",
             "L_L1_1", "L_L3_1", "L_L5_1",
             "U_L1_1", "U_L3_1", "U_L5_1"),
  coverage = c(100.00, 100.00, 100.00,
               100.00,  100.00,  100.00,
               100.00,  100.00,  100.00)
)
coverage_df <- tibble(
  sample = c("I_L1_1", "I_L3_1", "I_L5_1",
             "L_L1_1", "L_L3_1", "L_L5_1",
             "U_L1_1", "U_L3_1", "U_L5_1"),
  coverage = c(100.00, 100.00, 100.00,
               100.00,  100.00,  99.99,
               99.99,  100.00,  100.00)
)
ggplot(coverage_df, aes(x = sample, y = coverage)) +
  geom_col(fill = "blue") +
  labs(
    title = "Correlation coverage",
    x = "Sample",
    y = "sgRNA coverage (%)"
  ) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  coord_cartesian(ylim = c(99.9, 100))   # zoom in so you can see differences

library(dplyr)
library(ggplot2)

groups <- count_df_long %>%
  distinct(condition, sublib)

for (i in seq_len(nrow(groups))) {

  this_condition <- groups$condition[i]
  this_sublib    <- groups$sublib[i]

  rank_df <- count_df_long %>%
    filter(condition == this_condition,
           sublib == this_sublib,
           count > 0) %>%                 # needed for log scale
    arrange(desc(count)) %>%              # highest -> lowest
    mutate(rank = row_number()) %>%       # rank index
    select(rank, count)

  p <- ggplot(rank_df, aes(x = rank, y = count)) +
    geom_line(color = "blue") +
    labs(
      title = paste("Knee plot of sgRNA read counts |", this_condition, "|", this_sublib),
      x = "Rank (sorted by count)",
      y = "Count (log10)"
    ) +
    scale_y_log10() +
    theme_bw() +
    theme(
      plot.margin = margin(t = 15, r = 10, b = 10, l = 10),
      plot.title = element_text(margin = margin(b = 10))
    )

  print(p)
}

```

``` {r Liangfu_Plots_1, eval=FALSE}
lg2fc_df <- maude_counts_df %>%
    left_join(merged_sgRNA_df %>% select(sgrna_id, Gene, count), by = c("sgRNA" = "sgrna_id")) %>% 
  rename(plasmid_count = count) %>% 
  filter(!isNontargeting)



plot_l2fc_scatter <- function(df,
                             baseline,
                             x_axis,
                             y_axis,
                             save_image_file_path = NULL,
                             genes = NULL,
                             mark_N_special = NULL,
                             pseudocount = 1e-9) {
  # Packages used: dplyr, ggplot2, ggrepel, rlang
  if (!is.data.frame(df)) stop("df must be a data.frame / tibble.")
  if (!"Gene" %in% names(df)) stop("df must contain a column named 'Gene'.")

  baseline_nm <- rlang::as_string(rlang::ensym(baseline))
  x_nm        <- rlang::as_string(rlang::ensym(x_axis))
  y_nm        <- rlang::as_string(rlang::ensym(y_axis))

  missing_cols <- base::setdiff(c(baseline_nm, x_nm, y_nm), names(df))
  if (length(missing_cols) > 0) {
    stop("Missing columns in df: ", paste(missing_cols, collapse = ", "))
  }

  means <- df |>
    dplyr::group_by(.data$Gene) |>
    dplyr::summarise(
      baseline_mean = mean(.data[[baseline_nm]], na.rm = TRUE),
      x_mean        = mean(.data[[x_nm]],        na.rm = TRUE),
      y_mean        = mean(.data[[y_nm]],        na.rm = TRUE),
      .groups = "drop"
    ) |>
    dplyr::mutate(
      L2FC_x = log2((x_mean + pseudocount) / (baseline_mean + pseudocount)),
      L2FC_y = log2((y_mean + pseudocount) / (baseline_mean + pseudocount)),
      delta  = L2FC_y - L2FC_x
    )

  genes <- if (is.null(genes)) character(0) else unique(as.character(genes))

  top_genes <- bottom_genes <- character(0)
  if (!is.null(mark_N_special) && is.finite(mark_N_special) && mark_N_special > 0) {
    n <- as.integer(mark_N_special)
    tmp <- means |>
      dplyr::filter(!is.na(.data$delta))

    top_genes <- tmp |>
      dplyr::slice_max(.data$delta, n = n, with_ties = FALSE) |>
      dplyr::pull(.data$Gene)

    bottom_genes <- tmp |>
      dplyr::slice_min(.data$delta, n = n, with_ties = FALSE) |>
      dplyr::pull(.data$Gene)
  }

  plot_df <- means |>
    dplyr::mutate(
      category = dplyr::case_when(
        .data$Gene %in% genes       ~ "highlight",
        .data$Gene %in% top_genes   ~ "top",
        .data$Gene %in% bottom_genes~ "bottom",
        TRUE                        ~ "other"
      ),
      label = dplyr::if_else(.data$category == "other", NA_character_, .data$Gene)
    )
  
  print(paste("NAs in L2FC_x:", sum(is.na(means$L2FC_x))))
  print(paste("NAs in L2FC_y:", sum(is.na(means$L2FC_y))))
  
  p <- ggplot2::ggplot(plot_df, ggplot2::aes(x = .data$L2FC_x, y = .data$L2FC_y, color = .data$category)) +
    ggplot2::geom_point(alpha = 0.8, size = 1.7) +
    ggrepel::geom_text_repel(
      ggplot2::aes(label = .data$label),
      size = 3,
      max.overlaps = Inf,
      box.padding = 0.35,
      point.padding = 0.2,
      show.legend = FALSE
    ) +
    ggplot2::scale_color_manual(values = c(
      other     = "grey80",
      top       = "red3",
      bottom    = "dodgerblue3",
      highlight = "darkgreen"
    )) +
    ggplot2::labs(
      title = paste0("L2FC vs ", baseline_nm),
      x = paste0("log2FC(", x_nm, " / ", baseline_nm, ")"),
      y = paste0("log2FC(", y_nm, " / ", baseline_nm, ")"),
      color = NULL
    ) +
    ggplot2::geom_vline(xintercept = 0, linetype = "dashed", colour = "grey70") +
    ggplot2::geom_hline(yintercept = 0, linetype = "dashed", colour = "grey70") +
    ggplot2::theme_classic()

  if (!is.null(save_image_file_path) && nzchar(save_image_file_path)) {
    ggplot2::ggsave(filename = save_image_file_path, plot = p, width = 7, height = 6, dpi = 300)
  }

  print(p)
  invisible(list(means = means, plot = p))
}
vs_input <- plot_l2fc_scatter(lg2fc_df,
                 baseline = "input",
                 x_axis = "upper",
                 y_axis = "lower",
                 save_image_file_path = NULL,
                 genes = c("EGFP","AGO2"),
                 mark_N_special = 8,
                 pseudocount = 1e-9)
  
vs_plasmid <- plot_l2fc_scatter(lg2fc_df,
                 baseline = "plasmid_count",
                 x_axis = "upper",
                 y_axis = "lower",
                 save_image_file_path = NULL,
                 genes = c("EGFP","AGO2"),
                 mark_N_special = 8,
                 pseudocount = 1e-9)

csv_file_path <- get_file_path(results_output_folder,"L2FC_vs_input.csv")
write_csv(vs_input$means, csv_file_path)
csv_file_path <- get_file_path(results_output_folder,"L2FC_vs_plasmid.csv")
write_csv(vs_plasmid$means, csv_file_path)
```