---
title: "PCR_Amplicon_March"
author: "Lukas"
date: "2025-03-18"
output: html_document
---
# Set User options here
```{r setup, include=FALSE}
print(.libPaths())
knitr::opts_chunk$set(echo = FALSE)
options(bitmapType="cairo")
library(tidyverse)
library(Matrix)
library(conflicted)
library(MAUDE)
library(ggplot2)
library(optparse)
library(ggrepel)
library(writexl)
library(stringr)

conflicts_prefer(dplyr::rename)
conflicts_prefer(dplyr::filter)
conflicts_prefer(dplyr::select)
conflicts_prefer(dplyr::slice)

# Find a specific file by walking up parent directories
find_up_file <- function(start_dir, filename, max_up = 15) {
  d <- normalizePath(start_dir, mustWork = TRUE)

  for (i in 0:max_up) {
    candidate <- file.path(d, filename)
    if (file.exists(candidate)) return(candidate)

    parent <- dirname(d)
    if (identical(parent, d)) break
    d <- parent
  }

  stop("Could not find '", filename, "' searching upward from: ", start_dir)
}

# Now we find the location of the RMD file we are running
# (Either data_analysis_with_MAUDE.rmd or compare_results.rmd)
rmd_path <- Sys.getenv("SOURCE_RMD", unset = "")
start_dir <- if (nzchar(rmd_path) && file.exists(rmd_path)) {
  dirname(normalizePath(rmd_path, mustWork = TRUE))
} else {
  getwd()
}

# 1) If we are running from compare_results.rmd, we need to find the root_dir
anchor_rmd <- find_up_file(start_dir, "data_analysis_with_MAUDE.Rmd", max_up = 1)

# 2) The anchor's directory is the project root that contains /functions
project_root_dir <- dirname(anchor_rmd)

# 3) Source functions from there
source(file.path(project_root_dir, "functions", "zzz_source_all.R"))

#===============================================================================
# User Options (can be overrided via CLI)
#===============================================================================
# first_time will save all intermediary results, if FALSE will try to load them
first_time      <- FALSE

# Directories
# Mandatory output_folder
# output_folder   <- "/g/steinmetz/link/Amplicon_barcode_analysis/HepG2_dual_rep_PA_subsample/subsample_10"
output_folder   <- "/g/steinmetz/link/Amplicon_barcode_analysis/HepG2_dual_rep_GALNAC"
# output_folder   <- "/g/steinmetz/link/Amplicon_barcode_analysis/Liangfu_iBeer_2/David_January"
#optional folders for results from johns bcwithqc
john_rf_folder  <- "/g/steinmetz/link/Amplicon_barcode_analysis/NB_EXP030/john_read_filt"
john_folder <- ""
# If any files are to be skipped list their names here

skip_list <- c() # individual files, example: c("I_L3_5", "U_L1_2")
skip_list_sublib <- c() # entire sublibraries, example: c("L4","L5")
skip_list_sample <- c() # entire sample numbers, example c("1", "24")
# Warning: skipping entire sublibraries and sample numbers does not work for
# non numeric samples, or samples >9999

# Extra target list
# If any of the controls should be considered targeting (example EGFP and AAVS1)
# Nico HepG2 screen
include_controls_list <- c("EGFP","AAVS1_9", "AAVS1_13", "AAVS1_18", "AAVS1_19", "AAVS1_25", "AAVS1_35")
# include_controls_list <- c()
# Only Specific controls
# Liangfu wants only these controls to be used:
# Liangfu iBeer Screen
if (FALSE){
  include_controls_list <- c()
  use_only_these_controls_path <- "/g/steinmetz/link/Amplicon_barcode_analysis/Liangfu_iBeer_2/Liangfu_Non_targeting_sgRNA_list_Genomewide_Daniel Lib.csv"
  use_only_these_controls_list <- read.csv(use_only_these_controls_path, header = FALSE, stringsAsFactors = FALSE)$V1
} else {
  if (exists("use_only_these_controls_list")) {
    rm(use_only_these_controls_list)
  }
} 
# Set Options for pipline function
pipeline            <- "lukas"  # can be "john", "john_rf" or "lukas" use john for CellRanger and bcwithqc proccessed data.
data_type           <- "reads"   # can be "reads" or "umis"
method              <- ""    # can be "rep", "rep_sample", "rep_sublib", or "" 
norm_method         <- "control_median"       # can be "control_median" or ""
recover_input       <- TRUE     # bolean estimates missing input data
subsample_controls  <- FALSE     # bolean keeps 10% of control sgRNAs for reference.
use_custom_fraction <- FALSE    # bolean to use custom bin fractions. 
combine_for_guide_stats     <- "sample" # can be "", "sample", or "sublib".
combine_for_gene_stats <- "none" # can be "none", "all", "sample", or "sublib"


# Set Fractions for the upper and lower bins
upper_lower_percentage <- 0.10  # Fraction of the lower&upper bin 0.10 = 10%
                                # The Rest is used and removed by MAUDE for normalization.

# Custom suffix and optional simplified read filtering
extra_suffix  <- ""   # custom sufix, special behaviour when set to "rf"
                      # if extra_suffix is set to "rf" it applies simplified read filtering,  
                      # which removes all reads below simplified_rf_threshold
                      # "cf" does the same only for control guides
simplified_rf_threshold <- 2000 # threshold for simplified filtering
simplified_cf_threshold <- 2000 # threshold for simplified filtering

# Are all the non-targeting control sgRNAS the same in all sublibraries/replicates?
same_controls_in_all_sublibraries <- TRUE

# Remove rows without any data 
drop_0s <- FALSE  # bolean removes all guides with no UMIs/reads
strict_mode <- FALSE # bolean, removes all guides which don't have UMIs for all bins. 
min_guides_per_gene <- 0 # Minimum number of guides required to detect a gene, per replicate not total
auto_combine_replicates <- FALSE # automatically combines replicas

#===============================================================================
# Define command-line options
#===============================================================================
option_list <- list(
  make_option(c("--first_time"), type = "logical", default = first_time,
              help = "First run flag, will save files (default: TRUE)", metavar = "LOGICAL"),
  make_option(c("--output_folder"), type = "character", default = output_folder,
              help = "Output folder (default: '/g/steinmetz/link/Amplicon_barcode_analysis/NB_EXP030')", 
              metavar = "PATH"),
  make_option(c("--john_folder"), type = "character", default = john_folder,
              help = "John folder (default: '/g/steinmetz/link/Amplicon_barcode_analysis/NB_EXP030/john/')", 
              metavar = "PATH"),
  make_option(c("--john_rf_folder"), type = "character", default = john_rf_folder,
              help = "John RF folder (default: '/g/steinmetz/link/Amplicon_barcode_analysis/NB_EXP030/john_read_filt')", 
              metavar = "PATH"),
  make_option(c("--skip_list"), type = "character", default = paste(skip_list, collapse = ","),
              help = "If any files are to be skipped list their names here (comma-separated) (default: '')", 
              metavar = "LIST"),
  make_option(c("--skip_list_sublib"), type = "character", default = paste(skip_list_sublib, collapse = ","),
              help = "If any sublibraries are to be skipped list their names here (comma-separated) (default: '')", 
              metavar = "LIST"),
  make_option(c("--skip_list_sample"), type = "character", default = paste(skip_list_sample, collapse = ","),
              help = "If any samples are to be skipped list their names here (comma-separated) (default: '')", 
              metavar = "LIST"),
  make_option(c("--pipeline"), type = "character", default = pipeline, 
              help = "Pipeline name (default: 'lukas')", metavar = "CHARACTER"),
  make_option(c("--data_type"), type = "character", default = data_type, 
              help = "Data type (default: 'umis')", metavar = "CHARACTER"),
  make_option(c("--method"), type = "character", default = method, 
              help = "Method (default: '')", metavar = "CHARACTER"),
  make_option(c("--norm_method"), type = "character", default = norm_method, 
              help = "Normalization method (default: '')", metavar = "CHARACTER"),
  make_option(c("--recover_input"), type = "logical", default = recover_input, 
              help = "Recover missing input (default: TRUE)", metavar = "LOGICAL"),
  make_option(c("--subsample_controls"), type = "logical", default = subsample_controls, 
              help = "Subsample control guides so some appear in the results (default: TRUE)", metavar = "LOGICAL"),
  make_option(c("--same_controls_in_all_sublibraries"), type = "logical", default = same_controls_in_all_sublibraries, 
              help = "Set to FALSE if the individual sublibraries/replicates have different control sgRNAs (default: TRUE)", metavar = "LOGICAL"),
  make_option(c("--extra_suffix"), type = "character", default = extra_suffix, 
              help = "Suffix for additional options (default: '')", metavar = "CHARACTER"),
  make_option(c("--simplified_rf_threshold"), type = "integer", default = simplified_rf_threshold,
              help = "Threshold for simplified filtering (default: 1000)", metavar = "INTEGER"),
  make_option(c("--upper_lower_percentage"), type = "double", default = upper_lower_percentage,
              help = "Fraction of the lower&upper bin (default: 0.10)", metavar = "DOUBLE"),
  make_option(c("--drop_0s"), type = "logical", default = drop_0s, 
              help = "Drop rows where input, upper, and lower are all 0 (default: TRUE)", metavar = "LOGICAL")
)

#===============================================================================
# Parse the command-line arguments
#===============================================================================
opt_parser <- OptionParser(option_list = option_list)
opt <- parse_args(opt_parser)

#===============================================================================
# Override the defaults with CLI values
#===============================================================================
first_time                        <- opt$first_time
output_folder                     <- opt$output_folder
john_folder                       <- opt$john_folder
john_rf_folder                    <- opt$john_rf_folder
skip_list                         <- strsplit(opt$skip_list, ",")[[1]]
skip_list_sublib                  <- strsplit(opt$skip_list_sublib, ",")[[1]]
skip_list_sample                  <- strsplit(opt$skip_list_sample, ",")[[1]]
pipeline                          <- opt$pipeline
data_type                         <- opt$data_type
method                            <- opt$method
norm_method                       <- opt$norm_method
recover_input                     <- opt$recover_input
subsample_controls                <- opt$subsample_controls
same_controls_in_all_sublibraries <- opt$same_controls_in_all_sublibraries
extra_suffix                      <- opt$extra_suffix
simplified_rf_threshold           <- opt$simplified_rf_threshold
upper_lower_percentage            <- opt$upper_lower_percentage
drop_0s                           <- opt$drop_0s

#===============================================================================
# Print the options (for verification)
#===============================================================================
cat("first_time:                        ", first_time, "\n")
cat("output_folder:                     ", output_folder, "\n")
cat("john_folder:                       ", john_folder, "\n")
cat("john_rf_folder:                    ", john_rf_folder, "\n")
cat("skip_list:                         ", paste(skip_list, collapse = ", "), "\n")
cat("skip_list_sublib:                  ", paste(skip_list_sublib, collapse = ", "), "\n")
cat("skip_list_sample:                  ", paste(skip_list_sample, collapse = ", "), "\n")
cat("pipeline:                          ", pipeline, "\n")
cat("data_type:                         ", data_type, "\n")
cat("method:                            ", method, "\n")
cat("norm_method:                       ", norm_method, "\n")
cat("recover_input:                     ", recover_input, "\n")
cat("subsample_controls:                ", subsample_controls, "\n")
cat("same_controls_in_all_sublibraries: ", same_controls_in_all_sublibraries, "\n")
cat("extra_suffix:                      ", extra_suffix, "\n")
cat("simplified_rf_threshold:           ", simplified_rf_threshold, "\n")
cat("upper_lower_percentage:            ", upper_lower_percentage, "\n")
cat("strict_mode:                       ", strict_mode, "\n")
cat("min_guides_per_gene:               ", min_guides_per_gene, "\n")
cat("drop_0s:                           ", drop_0s, "\n")


#===============================================================================
# Condition for adding "RI" and "D0"
#===============================================================================

if (recover_input) {
  recover_input_suffix <- "RI"
} else {
  recover_input_suffix <- ""
}

if (drop_0s) {
  drop_0s_suffix <- "D0"
} else {
  drop_0s_suffix <- ""
}
if (strict_mode) {
  strict_mode_suffix <- "strict"
} else {
  strict_mode_suffix <- ""
}
if (auto_combine_replicates){
  auto_combine_replicates_suffix <- "acr"
} else {
  auto_combine_replicates_suffix <- ""
}
if (min_guides_per_gene > 0){
  min_guides_per_gene_suffix <- min_guides_per_gene
} else {
  min_guides_per_gene_suffix <- ""
}
if (combine_for_guide_stats == ""){
  combine_for_guide_stats_suffix <- ""
} else {
  combine_for_guide_stats_suffix <- paste0("comb_", combine_for_guide_stats)
}
#===============================================================================
# Construct the skip list
#===============================================================================

skip_list_and_suffix <- create_skip_list_and_suffix(skip_list,
                                                    skip_list_sublib,
                                                    skip_list_sample)
skip_list <- skip_list_and_suffix[[1]]
skip_suffix <- skip_list_and_suffix[[2]]

#===============================================================================
# Construct the file suffix
#===============================================================================
fs_parts <- c(pipeline,
           data_type,
           method,
           norm_method,
           recover_input_suffix,
           drop_0s_suffix,
           strict_mode_suffix,
           min_guides_per_gene_suffix,
           combine_for_guide_stats_suffix,
           auto_combine_replicates_suffix,
           skip_suffix,
           extra_suffix)

# keep only non-empty parts
fs_parts <- fs_parts[fs_parts != ""]

file_suffix <- paste0("_", paste(fs_parts, collapse = "_"), ".rds")

fi_parts <- c(pipeline,
              data_type,
              method,
              norm_method,
              recover_input_suffix,
              drop_0s_suffix,
              strict_mode_suffix,
              min_guides_per_gene_suffix,
              combine_for_guide_stats_suffix,
              auto_combine_replicates_suffix,
              skip_suffix,
              extra_suffix)

# keep only non-empty parts
fi_parts <- fi_parts[fi_parts != ""]

file_info_suffix <- paste(fi_parts, collapse = "_")

# Print the final file suffix
cat("File Suffix: ", file_suffix, "\n")

#===============================================================================
# Construct File Paths
#===============================================================================



data_dir <- get_file_path(project_root_dir,"data")
genome_output_folder <- make_clean_dir(output_folder, "/ref/")
dedup_output_folder <- make_clean_dir(output_folder, "/dedup/")
mapped_output_folder <- make_clean_dir(output_folder, "/mapped/")
rds_output_folder <- make_clean_dir(output_folder, "/rds/")
results_output_folder <- make_clean_dir(output_folder, "/results/")

merged_sgRNA_df <- readRDS(get_file_path(rds_output_folder,
                                         "merged_sgRNA_df.rds"))

```

## Generate the long format read/umi counts either from my pipline or from johns
Also provides information for each file about coverage and correct alignment

```{r get_count_df_long, eval=TRUE}



process_john_data_backup <- process_john_data
pseudocount_added <- FALSE

sink(get_file_path(rds_output_folder,paste0(file_info_suffix,"_coverage.txt")),
     split = TRUE) # capture output into a file

if (pipeline == "john"){
  count_df_long <- process_john_data(john_folder,
                                     data_type = data_type,
                                     merged_sgRNA_df = merged_sgRNA_df,
                                     skip_list = skip_list)
  if (extra_suffix == "rf"){
      count_df_long <- count_df_long %>% 
      mutate(count = ifelse(count < simplified_rf_threshold, 0, count))        
      }
} else {
  if (pipeline == "lukas"){
    if (data_type == "umis"){
      count_df_long <- process_folder_files(dedup_output_folder,
                                            skip_list = skip_list) #Add threshold df if thresholds should be applied 
    }
    if (data_type == "reads"){
      count_df_long <- process_folder_files(mapped_output_folder,
                                            skip_list = skip_list) #Add threshold df if thresholds should be applied 
      if (extra_suffix == "rf"){
        count_df_long <- count_df_long %>% 
        mutate(count = ifelse(count < simplified_rf_threshold, 0, count))        
      }

    }
       
  } else {
    if (pipeline == "john_rf"){
      count_df_long <- process_john_rf_data(john_rf_folder,
                                            data_type = data_type,
                                            merged_sgRNA_df = merged_sgRNA_df,
                                            skip_list = skip_list)
      
      process_john_data <- process_john_rf_data
      if (extra_suffix == "rf"){
        count_df_long <- count_df_long %>% 
        mutate(count = ifelse(count < simplified_rf_threshold, 0, count))        
      }
    } else {
      stop("Unsupported pipeline specified. Exiting. Pipline must be john, john_rf or lukas.")
    }
  }  
}
sink()
if (extra_suffix == "cf"){
  count_df_long <- count_df_long %>%
    filter(!(group != "targeting" & count < simplified_cf_threshold))
}

# Extend the include_controls_list if use_only_these_controls_list is given
if (exists("use_only_these_controls_list")) {
  if (length(use_only_these_controls_list) > 0){
    # list of sgRNAs that were not targeting (before) and not in allowed controls
    excluded_controls <- count_df_long %>%
      filter(group_category != "targeting", !sgRNA %in% use_only_these_controls_list) %>%
      distinct(sgRNA) %>%
      pull(sgRNA)
  
    include_controls_list <- c(include_controls_list, excluded_controls)
  }
}
if (length(include_controls_list) > 0){
  for (control_gene in include_controls_list){
    count_df_long$group_category[grepl(control_gene, count_df_long$sgRNA)] <- "targeting"
  }
}

# Combine either samples or sublibraries of the same condition. 
if (combine_for_guide_stats != ""){
  if (combine_for_guide_stats == "sample"){
    count_df_long <- count_df_long %>%
      group_by(sgRNA, sublib, condition) %>%
      summarise(
        # set sample name for the combined rows
        sample = "sample_1",
        count = sum(count, na.rm = TRUE),
        exp = dplyr::first(exp),
        group_category = dplyr::first(group_category),
        
        # keep one sublib/sgRNA (also fine even though they're grouping keys)
        .groups = "drop"
      )
  }
  if (combine_for_guide_stats == "sublib"){
    count_df_long <- count_df_long %>%
      group_by(sgRNA, sample, condition) %>%
      summarise(
        sublib = "sublib_1",
        count = sum(count, na.rm = TRUE),
        exp = dplyr::first(exp),
        group_category = dplyr::first(group_category),
        
        # keep one sublib/sgRNA (also fine even though they're grouping keys)
        .groups = "drop"
      )    
  }
}  
```

```{r make_coverage_output, eval=TRUE}

df_cov <- parse_coverage_file(get_file_path(
  rds_output_folder, paste0(file_info_suffix, "_coverage.txt")
))

mapping_results_df <- add_star_log_stats(df_cov, mapped_output_folder)

rm(df_cov)

overall_targeting <- count_df_long %>%
  summarise(
    total_counts     = sum(count, na.rm = TRUE),
    targeting_counts = sum(count[group_category == "targeting"], na.rm = TRUE),
    targeting_perc   = 100 * targeting_counts / total_counts
  ) %>%
  mutate(targeting_perc = sprintf("%.2f%%", targeting_perc))

targeting_by_group <- count_df_long %>%
  group_by(condition, sublib, sample) %>%
  summarise(
    total_counts     = sum(count, na.rm = TRUE),
    targeting_counts = sum(count[group_category == "targeting"], na.rm = TRUE),
    targeting_perc   = 100 * targeting_counts / total_counts,
    .groups = "drop"
  ) %>%
  mutate(targeting_perc = sprintf("%.2f%%", targeting_perc))

overall_targeting_merged <- merged_sgRNA_df %>%
  summarise(
    total_counts     = sum(count, na.rm = TRUE),
    targeting_counts = sum(count[!is.na(entrez)], na.rm = TRUE),
    targeting_perc   = 100 * targeting_counts / total_counts
  ) %>%
  mutate(targeting_perc = sprintf("%.2f%%", targeting_perc))


# ---- Write everything into ONE excel file as separate sheets ----
write_xlsx(
  list(
    mapping_results          = mapping_results_df,
    overall_targeting        = overall_targeting,
    targeting_by_group       = targeting_by_group,
    overall_targeting_reference = overall_targeting_merged
  ),
  get_file_path(results_output_folder,
                paste0(file_info_suffix, "_mapping_results.xlsx"))
)

```
## More detailed data exploration based on the long format read/umi counts 
Run this to check the plots
```{r data_exploration_violin, eval=FALSE}

generate_all_violin_plots_and_summaries(count_df_long, y_limit = 8000, non_targeting = TRUE)
generate_all_violin_plots_and_summaries(count_df_long, norm_method = "control_median", y_limit = 8000, non_targeting = TRUE) 



summary_medians <- get_grouped_summary_wide(count_df_long)
summary_means <- get_grouped_summary_wide(count_df_long, stat = "mean")
print(summary_medians)
print(summary_means)
count_df_norm <- normalize_count_df_long(count_df_long, norm_method = "control_median")
plots <- plot_violin_by_sublib_sample(count_df_long)
for (i in 1:length(plots)) {
  print(plots[[i]])
}
plots <- plot_violin_by_sublib_sample(count_df_long, norm_method = "control_median")
for (i in 1:length(plots)) {
  print(plots[[i]])
}

```

## Bring the long form read/umi counts into a format accepted by MAUDE (wide format with input, upper and lower columns)

```{r prepare_data_for_maude, eval=TRUE}

if (subsample_controls == TRUE){
  # count_df_long_old <- subsample_controls_func_old(count_df_long, merged_sgRNA_df)
  count_df_long <- subsample_controls_func(count_df_long, merged_sgRNA_df)
}

if (!(norm_method %in% c("","control_median"))){
  stop("Error: 'norm_method' must be one of '', 'control_median'. The script will now stop.")
}
if (norm_method == "control_median"){
  count_df_long <- normalize_count_df_long(count_df_long,
                                           norm_method = norm_method)
}


  
maude_counts_df <- count_df_long_to_wide(count_df_long = count_df_long,
                                         print = FALSE,
                                         drop_0s = drop_0s,
                                         recover_input = recover_input)
if (!(method %in% c("","rep","sum",'rep_sample','rep_sublib'))){
  stop("Error: 'method' must be one of '', 'rep', 'rep_sample', 'rep_sublib', or 'sum'. The script will now stop.")
}

if (method == ""){
  maude_counts_df <- maude_counts_df %>% 
    mutate(exp = "rep1")
}
if (method == "rep"){

}
if (method == "rep_sample"){
  maude_counts_df <- maude_counts_df %>%
    mutate(exp = sample)
}
if (method == "rep_sublib"){
  maude_counts_df <- maude_counts_df %>%
    mutate(exp = sublib)
}
if (method == "sum"){
  stop("Method 'sum' is deprecated, use the option combine_for_guide_stats instead")
  maude_counts_df <- count_df_long_to_wide(count_df_long = count_df_long,
                                         print = FALSE,
                                         drop_0s = drop_0s,
                                         recover_input = TRUE,
                                         for_sum = TRUE)
  # Group by sgRNA and summarize the required columns
  maude_counts_df <- maude_counts_df %>%
    group_by(sgRNA, sublib) %>%
    summarize(
      input = pmax(sum(input, na.rm = TRUE), 0),  # Sum and ensure minimum is 0
      upper = pmax(sum(upper, na.rm = TRUE), 0),  # Sum and ensure minimum is 0
      lower = pmax(sum(lower, na.rm = TRUE), 0),  # Sum and ensure minimum is 0
      isNontargeting = dplyr::first(isNontargeting),  # Take the first value of isNontargeting (same for all in the group)
      .groups = 'drop'  # Drop the group structure after summarizing
    ) %>%
    mutate(
      exp = "rep1",
      input = input + 1,
      upper = upper + 1,
      lower = lower + 1
    )
}

if (strict_mode){
  if (pseudocount_added){
    umi_threshold <- 2
  } else {
    umi_threshold <- 1
  } 
  cat("Strict Mode enabled\n")
  cat("Rows before strict mode: \t", nrow(maude_counts_df),"\n")
  maude_counts_df <- maude_counts_df %>%
    filter(if_any(c(input, upper, lower), ~ . <= umi_threshold))
  cat("Rows after strict mode: \t", nrow(maude_counts_df),"\n")
}
if (length(include_controls_list) > 0) {
  for (control_gene in include_controls_list) {
    maude_counts_df$isNontargeting[grepl(control_gene, maude_counts_df$sgRNA)] <- FALSE
  }
}
if (exists("use_only_these_controls_list")) {
  if (length(use_only_these_controls_list) > 0){
    maude_counts_df$isNontargeting[ !(maude_counts_df$sgRNA %in% use_only_these_controls_list) ] <- FALSE
  }
}

```

## Exploration of the read/umi counts in MAUDE format

```{r check_data_for_maude, eval=FALSE}
if (data_type == "umis"){
    data_name <- "UMIs"
  }
if (data_type == "reads"){
    data_name <- "reads"
  } 


control_sanity_check(maude_counts_df)

# Change FALSE to input_recovery if desired
if (FALSE){
  title_sufix_1 <- "(without input recovery)"
  title_sufix_2 <- "(with input recovery)"
} else {
  title_sufix_1 <- "(before MAUDE preperation)"
  title_sufix_2 <- "(ready for MAUDE)"
}

# 1. Count unique sgRNAs per (condition, exp)
sgRNA_counts <- count_df_long %>%
  group_by(condition, exp) %>%
  summarise(total_count = sum(count), .groups = "drop") %>%
  mutate(Sample = interaction(condition, exp, drop = TRUE),
         Bin = condition)  # for x-axis

# 2. Plot
o <- ggplot(sgRNA_counts, aes(x = Sample, y = total_count, fill = Bin)) +
  geom_col() +
  labs(
    title = paste("Sum of", data_name, "per sample"),
    x = "Sample",
    y = paste("Sum of", data_name)
  ) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, face = "bold"),
        axis.text.y = element_text(face = "bold"),
        legend.position = "none")


# 1. Count unique sgRNAs per (condition, exp)
sgRNA_counts <- count_df_long %>%
  group_by(condition, exp) %>%
  summarise(num_sgRNAs = n(), .groups = "drop") %>%
  mutate(Sample = interaction(condition, exp, drop = TRUE),
         Bin = condition)  # for x-axis

# 2. Plot
p <- ggplot(sgRNA_counts, aes(x = Sample, y = num_sgRNAs, fill = Bin)) +
  geom_col() +
  labs(
    title = paste("Number of sgRNA entries per sample",title_sufix_1),
    x = "Sample",
    y = "Number of sgRNA entries"
  ) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, face = "bold"),
        axis.text.y = element_text(face = "bold"),
        legend.position = "none")

# 1. Count unique sgRNAs per (condition, exp)
sgRNA_counts <- count_df_long %>%
  group_by(condition) %>%
  summarise(num_sgRNAs = n(), .groups = "drop") %>%
  mutate(Bin = condition)  # for x-axis

# 2. Plot
q <- ggplot(sgRNA_counts, aes(x = Bin, y = num_sgRNAs, fill = Bin)) +
  geom_col() +
  labs(
    title = paste("Number of sgRNA entries per bin", title_sufix_1),
    x = "Bin",
    y = "sgRNA entries"
  ) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, face = "bold"),
        axis.text.y = element_text(face = "bold"),
        legend.position = "none")

totals_df <- maude_counts_df %>% 
  summarise(
    input = sum(!is.na(input)),
    upper = sum(!is.na(upper)),
    lower = sum(!is.na(lower))
  ) %>% 
  pivot_longer(
    cols       = everything(),
    names_to   = "Bin",
    values_to  = "count_non_na"
  )

r <- ggplot(totals_df, aes(x = Bin, y = count_non_na, fill = Bin)) +
  geom_col() +
  labs(
    title = paste("Number of sgRNA entries per bin", title_sufix_2),
    x = "Bin",
    y = "Number of sgRNA entries"
  ) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, face = "bold"),
        axis.text.y = element_text(face = "bold"),
        legend.position = "none")

# 1. Summarise total counts per condition
totals_df <- maude_counts_df %>% 
  summarise(
    input = sum(input, na.rm=TRUE),
    upper = sum(upper, na.rm=TRUE),
    lower = sum(lower, na.rm=TRUE)
  ) %>% 
  pivot_longer(
    cols = everything(),
    names_to  = "Bin",
    values_to = "total_count"
  )

# 2. Plot
s <- ggplot(totals_df, aes(x = Bin, y = total_count, fill = Bin)) +
  geom_col() +
  labs(
    title = paste("Sum of", data_name, "per bin"),
    x     = "Bin",
    y     = "Total counts"
  ) +
  theme_bw() +
  theme(
    axis.text.x  = element_text(angle = 45, hjust = 1),
    legend.position = "none"
  )


print(q)
print(r)
print(s)
print(o)
print(p)        
plot_maude_qc(maude_counts_df)
plot_maude_qc(maude_counts_df, add_0s = TRUE)
```

## Run MAUDE and generate maude_guide_hits and maude_gene_hits

```{r run_MAUDE, eval=TRUE}

unique_exp <- unique(maude_counts_df$exp)

# Define bin stats with 10% for lower/upper each
lower_bin_end = upper_lower_percentage
upper_bin_start = 1 - upper_lower_percentage

maude_bins <- tibble(Bin = rep(c('upper', 'lower'), length(unique_exp)),  # Repeat 'upper' and 'lower' for each exp
                     exp = rep(unique_exp, each = 2),  # Repeat each exp value twice for 'upper' and 'lower'
                     binStartQ = ifelse(rep(c('upper', 'lower'), length(unique_exp)) == 'lower', 0.001, upper_bin_start),
                     binEndQ = ifelse(rep(c('upper', 'lower'), length(unique_exp)) == 'lower', lower_bin_end, 0.999),
                     fraction = binEndQ - binStartQ,
                     binStartZ = qnorm(binStartQ),
                     binEndZ = qnorm(binEndQ)) %>%
  select(Bin, binStartQ, binEndQ, fraction, binStartZ, binEndZ, exp) %>%
  as.data.frame()



if (first_time == TRUE){
  ## The input dataframe needs to have the lower, upper and input columns.
  ## use maude to calculate guide level statistics.
  maude_guide_stats <- findGuideHitsAllScreens(
    experiments = unique(maude_counts_df['exp']),
    countDataFrame = maude_counts_df,
    binStats = maude_bins,
    sortBins = c('lower', 'upper'),
    unsortedBin = 'input',
    negativeControl = 'isNontargeting'
  )
  
  saveRDS(maude_guide_stats,file.path(rds_output_folder,
                                      paste0("MAUDE_guide_stats", file_suffix)))
} else {
  maude_guide_stats <- readRDS(file.path(rds_output_folder,
                                         paste0("MAUDE_guide_stats", file_suffix)))
}


if (first_time == TRUE){
  
  maude_guide_stats <- maude_guide_stats %>%
    left_join(
      merged_sgRNA_df %>%
        select(sgrna_id, entrez) %>%
        distinct(sgrna_id, .keep_all = TRUE),
      by = c("sgRNA" = "sgrna_id")
    ) %>%
    mutate(entrez = coalesce(as.character(entrez), sgRNA))
  
  # any entries from include_controls_list are manually turned into genes
  if (length(include_controls_list) > 0) {
    for (control_gene in include_controls_list) {
      # here we remove everything after the last _, so stuff like AAVS1_9 and
      # AAVS1_13 are both treated as AAVS1
      control_gene <- sub("_[^_]*$", "", control_gene)
      maude_guide_stats$entrez[grepl(control_gene, maude_guide_stats$sgRNA)] <- control_gene
    }
  }
 
  if (combine_for_gene_stats != "none"){
    if (!(combine_for_gene_stats %in% c("all","sublib","sample"))){
      stop("combine_for_gene_stats must be one of: 'all','none','sublib','sample'")
    }
    if (combine_for_gene_stats == "all"){
      maude_guide_stats$exp <- "rep1"
    }
    if (combine_for_gene_stats == "sublib"){
      maude_guide_stats <- maude_guide_stats %>% 
        mutate(exp = sample)
    }
    if (combine_for_gene_stats == "sample"){
      maude_guide_stats <- maude_guide_stats %>% 
        mutate(exp = sublib)
    }    
  }
  
  ## calculate gene-level summarized scores
  maude_gene_stats <- getElementwiseStats(
    experiments = unique(maude_guide_stats['exp']),
    normNBSummaries = maude_guide_stats,
    negativeControl = 'isNontargeting',
    elementIDs = 'entrez'
  )
  
  # Filter out all genes with not enough guides pointing to them
  maude_gene_stats <- maude_gene_stats %>%
    filter(numGuides >= min_guides_per_gene)
  
  saveRDS(maude_gene_stats,file.path(rds_output_folder,
                                     paste0("MAUDE_gene_stats", file_suffix)))
} else {
  maude_gene_stats <- readRDS(file.path(rds_output_folder,
                                        paste0("MAUDE_gene_stats", file_suffix)))
}

maude_guide_stats <- readRDS(file.path(rds_output_folder,
                                       paste0("MAUDE_guide_stats", file_suffix)))
maude_gene_stats <- readRDS(file.path(rds_output_folder,
                                      paste0("MAUDE_gene_stats", file_suffix)))


```
## Functions that add more information to the results, like the gene symbol

```{r check_MAUDE_results, eval=TRUE}

```


## Generate Waterfall plots for the data
```{r Waterfall_plot, eval=FALSE}
Hits_current_settings <- add_info_wrapper(file_info_suffix)
if (length(include_controls_list) > 0) {
  for (control_gene in include_controls_list) {
    # here we remove everything after the last _, so stuff like AAVS1_9 and
    # AAVS1_13 are both treated as AAVS1
    control_gene <- sub("_[^_]*$", "", control_gene)
    Hits_current_settings$symbol[grepl(control_gene, Hits_current_settings$entrez)] <- control_gene
  }
  # Filter out rows where the 'symbol' is in the include_controls_list
  Hits_current_settings_no_controls <- Hits_current_settings %>% 
    filter(!symbol %in% include_controls_list | is.na(symbol))
}


# Basic plot
plot_significance_by_rank(Hits_current_settings)

# Mark a special gene and top 10 hits
plot_significance_by_rank(Hits_current_settings,
                          mark_special = "EGFP",
                          mark_cntrl = FALSE,
                          mark_all_signif_level = 0.05,
                          signif_lines = TRUE,
                          box_padding = 0.6)

plot_significance_by_rank(Hits_current_settings_no_controls,
                          mark_special = c("AHSA1","AGO2"),
                          mark_all_signif_level = 0.05,
                          mark_cntrl = FALSE,
                          signif_lines = TRUE,
                          mark_N_top_hits = 3,
                          box_padding = 0.6)

plot_significance_by_rank(Hits_current_settings,
                          mark_special = "AHSA1",
                          mark_N_top_hits = 3,
                          box_padding = 0.6,
                          no_text = TRUE)
# Just highlight controls
plot_significance_by_rank(Hits_current_settings, mark_cntrl = TRUE)
plot_significance_by_rank(export_df, mark_cntrl = TRUE, mark_N_top_hits = 3, box_padding = 0.9)
```

# Combine replicas if auto_combine_repicates is set to TRUE

``` {r auto_combine_replicates, eval=TRUE}
if (auto_combine_replicates){
  # if we have replicates, handle them now
  if (length(unique(maude_gene_stats$exp)) > 1){
    genes_with_rep <- add_info_wrapper(file_info_suffix)
  
    export_df <- genes_with_rep %>%
      group_by(symbol, entrez) %>%
      summarise(
        numGuides = sum(numGuides, na.rm = TRUE),
        seq       = first(seq),
        sgRNA     = first(sgRNA),
        meanZ     = mean(meanZ, na.rm = TRUE),
  
        # Stoufferâ€™s method (equal weights); use count of non-NA Zs in the denominator
        stoufferZ = sum(significanceZ, na.rm = TRUE) /
                    sqrt(sum(!is.na(significanceZ))),
        # For clarity: final significance Z = stoufferZ
        significanceZ = stoufferZ,
        
        .groups = "drop"
      ) %>%
      mutate(
        # two-sided p from Stouffer Z
        p.value = 2 * pnorm(abs(stoufferZ), lower.tail = FALSE),
        FDR     = p.adjust(p.value, method = "BH")
      )
    export_df <- export_df %>%
      select(symbol, entrez, numGuides, stoufferZ, meanZ, significanceZ, p.value, FDR, seq, sgRNA)
  } else {
    print("No replicates present, skipping replicate combination")
    export_df <- add_info_wrapper(file_info_suffix)
  }
} else {
  export_df <- add_info_wrapper(file_info_suffix)
}

if (length(include_controls_list) > 0) {
  for (control_gene in include_controls_list) {
    export_df$symbol[export_df$entrez == control_gene] <- control_gene
  }
}

```

# Export the Data as CSV and excel file

``` {r basic_export, eval=TRUE}

# Write to Excel
csv_file_path <- sub(".rds",".csv",file.path(results_output_folder,
                                             paste0("MAUDE_Hits", file_suffix)))
write_csv(export_df, csv_file_path)

excel_file_path <- sub("\\.rds$", ".xlsx", file.path(results_output_folder,
                                             paste0("MAUDE_Hits", file_suffix)))
write_xlsx(export_df, excel_file_path)
```

``` {r read_count_export, eval=FALSE}
# Save read counts to csv and rds
rds_count_file_path <- get_file_path(rds_output_folder, paste0("maude_counts",file_suffix))

counts_df <- maude_counts_df %>% left_join(merged_sgRNA_df %>% 
                                             select(sgrna_id, entrez, Gene),
                                           by = c("sgRNA" = "sgrna_id"))
saveRDS(counts_df, rds_count_file_path)
# csv_file_path <- sub(".rds",".csv",paste0(results_output_folder, "/", "Counts", file_suffix))
# write_csv(maude_counts_df, csv_file_path)

```



