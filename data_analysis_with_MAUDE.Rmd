---
title: "PCR_Amplicon_March"
author: "Lukas"
date: "2025-03-18"
output: html_document
---
# Set User options here
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
options(bitmapType="cairo")
library(tidyverse)
library(Matrix)
library(conflicted)
library(MAUDE)
library(ggplot2)
library(optparse)
library(ggrepel)
library(writexl)
library(metap) 

conflicts_prefer(dplyr::rename)
conflicts_prefer(dplyr::filter)
conflicts_prefer(dplyr::select)
conflicts_prefer(dplyr::slice)

#===============================================================================
# User Options (can be overrided via CLI)
#===============================================================================
# first_time will save all intermediary results, if FALSE will try to load them
first_time      <- FALSE

# Directories
# Mandatory output_folder
# output_folder   <- "/g/steinmetz/link/Amplicon_barcode_analysis/HepG2_dual_rep_PA_subsample/subsample_10"
output_folder   <- "/g/steinmetz/link/Amplicon_barcode_analysis/HepG2_dual_rep_PA"
# output_folder   <- "/g/steinmetz/link/Amplicon_barcode_analysis/Liangfu_iBeer_2/Atto"
#optional folders for results from johns bcwithqc
john_rf_folder  <- "/g/steinmetz/link/Amplicon_barcode_analysis/NB_EXP030/john_read_filt"
john_folder <- ""
# If any files are to be skipped list their names here

skip_list <- c() # individual files, example: c("I_L3_5", "U_L1_2")
skip_list_sublib <- c() # entire sublibraries, example: c("L4","L5")
skip_list_sample <- c() # entire sample numbers, example c("1", "24")
# Warning: skipping entire sublibraries and sample numbers does not work for
# non numeric samples, or samples >9999

# Extra target list
# If any of the controls should be considered targeting (example EGFP and AAVS1)
# Nico HepG2 screen
include_controls_list <- c("EGFP","AAVS1_9", "AAVS1_13", "AAVS1_18", "AAVS1_19", "AAVS1_25", "AAVS1_35")
# include_controls_list <- c()

# Only Specific controls
# Liangfu wants only these controls to be used:
# Liangfu iBeer Screen
if (FALSE){
  use_only_these_controls_path <- "/g/steinmetz/link/Amplicon_barcode_analysis/Liangfu_iBeer_2/Liangfu_Non_targeting_sgRNA_list_Genomewide_Daniel Lib.csv"
  use_only_these_controls_list <- read.csv(use_only_these_controls_path, header = FALSE, stringsAsFactors = FALSE)$V1
}
# Set Options for pipline function
pipeline            <- "lukas"  # can be "john", "john_rf" or "lukas" use john for CellRanger and bcwithqc proccessed data.
data_type           <- "reads"   # can be "reads" or "umis"
method              <- ""    # can be "rep", "rep_sample", "rep_sublib", "sum" or ""
norm_method         <- "control_median"       # can be "control_median" or ""
recover_input       <- TRUE     # bolean estimates missing input data
subsample_controls  <- FALSE     # bolean keeps 10% of control sgRNAs for reference.
combine_samples     <- "sample" # can be "", "sample", or "sublib".


# Set Fractions for the upper and lower bins
upper_lower_percentage <- 0.10  # Fraction of the lower&upper bin 0.10 = 10%
                                # The Rest is used and removed by MAUDE for normalization.

# Custom suffix and optional simplified read filtering
extra_suffix  <- ""   # custom sufix, special behaviour when set to "rf"
                      # if extra_suffix is set to "rf" it applies simplified read filtering,  
                      # which removes all reads below simplified_rf_threshold
                      # "cf" does the same only for control guides
simplified_rf_threshold <- 2000 # threshold for simplified filtering
simplified_cf_threshold <- 2000 # threshold for simplified filtering

# Are all the non-targeting control sgRNAS the same in all sublibraries/replicates?
same_controls_in_all_sublibraries <- TRUE

# Remove rows without any data 
drop_0s <- FALSE  # bolean removes all guides with no UMIs/reads
strict_mode <- FALSE # bolean, removes all guides which don't have UMIs for all bins. 
min_guides_per_gene <- 0 # Minimum number of guides required to detect a gene, per replicate not total
auto_combine_replicates <- FALSE # automatically combines replicas

#===============================================================================
# Define command-line options
#===============================================================================
option_list <- list(
  make_option(c("--first_time"), type = "logical", default = first_time,
              help = "First run flag, will save files (default: TRUE)", metavar = "LOGICAL"),
  make_option(c("--output_folder"), type = "character", default = output_folder,
              help = "Output folder (default: '/g/steinmetz/link/Amplicon_barcode_analysis/NB_EXP030')", 
              metavar = "PATH"),
  make_option(c("--john_folder"), type = "character", default = john_folder,
              help = "John folder (default: '/g/steinmetz/link/Amplicon_barcode_analysis/NB_EXP030/john/')", 
              metavar = "PATH"),
  make_option(c("--john_rf_folder"), type = "character", default = john_rf_folder,
              help = "John RF folder (default: '/g/steinmetz/link/Amplicon_barcode_analysis/NB_EXP030/john_read_filt')", 
              metavar = "PATH"),
  make_option(c("--skip_list"), type = "character", default = paste(skip_list, collapse = ","),
              help = "If any files are to be skipped list their names here (comma-separated) (default: 'L_L4_3,U_L4_3')", 
              metavar = "LIST"),
  make_option(c("--pipeline"), type = "character", default = pipeline, 
              help = "Pipeline name (default: 'lukas')", metavar = "CHARACTER"),
  make_option(c("--data_type"), type = "character", default = data_type, 
              help = "Data type (default: 'umis')", metavar = "CHARACTER"),
  make_option(c("--method"), type = "character", default = method, 
              help = "Method (default: '')", metavar = "CHARACTER"),
  make_option(c("--norm_method"), type = "character", default = norm_method, 
              help = "Normalization method (default: '')", metavar = "CHARACTER"),
  make_option(c("--recover_input"), type = "logical", default = recover_input, 
              help = "Recover missing input (default: TRUE)", metavar = "LOGICAL"),
  make_option(c("--subsample_controls"), type = "logical", default = subsample_controls, 
              help = "Subsample control guides so some appear in the results (default: TRUE)", metavar = "LOGICAL"),
  make_option(c("--same_controls_in_all_sublibraries"), type = "logical", default = same_controls_in_all_sublibraries, 
              help = "Set to FALSE if the individual sublibraries/replicates have different control sgRNAs (default: TRUE)", metavar = "LOGICAL"),
  make_option(c("--extra_suffix"), type = "character", default = extra_suffix, 
              help = "Suffix for additional options (default: '')", metavar = "CHARACTER"),
  make_option(c("--simplified_rf_threshold"), type = "integer", default = simplified_rf_threshold,
              help = "Threshold for simplified filtering (default: 1000)", metavar = "INTEGER"),
  make_option(c("--upper_lower_percentage"), type = "double", default = upper_lower_percentage,
              help = "Fraction of the lower&upper bin (default: 0.10)", metavar = "DOUBLE"),
  make_option(c("--drop_0s"), type = "logical", default = drop_0s, 
              help = "Drop rows where input, upper, and lower are all 0 (default: TRUE)", metavar = "LOGICAL")
)

#===============================================================================
# Parse the command-line arguments
#===============================================================================
opt_parser <- OptionParser(option_list = option_list)
opt <- parse_args(opt_parser)

#===============================================================================
# Override the defaults with CLI values
#===============================================================================
first_time                        <- opt$first_time
output_folder                     <- opt$output_folder
john_folder                       <- opt$john_folder
john_rf_folder                    <- opt$john_rf_folder
skip_list                         <- strsplit(opt$skip_list, ",")[[1]]
pipeline                          <- opt$pipeline
data_type                         <- opt$data_type
method                            <- opt$method
norm_method                       <- opt$norm_method
recover_input                     <- opt$recover_input
subsample_controls                <- opt$subsample_controls
same_controls_in_all_sublibraries <- opt$same_controls_in_all_sublibraries
extra_suffix                      <- opt$extra_suffix
simplified_rf_threshold           <- opt$simplified_rf_threshold
upper_lower_percentage            <- opt$upper_lower_percentage
drop_0s                           <- opt$drop_0s

#===============================================================================
# Print the options (for verification)
#===============================================================================
cat("first_time:                        ", first_time, "\n")
cat("output_folder:                     ", output_folder, "\n")
cat("john_folder:                       ", john_folder, "\n")
cat("john_rf_folder:                    ", john_rf_folder, "\n")
cat("skip_list:                         ", paste(skip_list, collapse = ", "), "\n")
cat("pipeline:                          ", pipeline, "\n")
cat("data_type:                         ", data_type, "\n")
cat("method:                            ", method, "\n")
cat("norm_method:                       ", norm_method, "\n")
cat("recover_input:                     ", recover_input, "\n")
cat("subsample_controls:                ", subsample_controls, "\n")
cat("same_controls_in_all_sublibraries: ", same_controls_in_all_sublibraries, "\n")
cat("extra_suffix:                      ", extra_suffix, "\n")
cat("simplified_rf_threshold:           ", simplified_rf_threshold, "\n")
cat("upper_lower_percentage:            ", upper_lower_percentage, "\n")
cat("strict_mode:                       ", strict_mode, "\n")
cat("min_guides_per_gene:               ", min_guides_per_gene, "\n")
cat("drop_0s:                           ", drop_0s, "\n")


#===============================================================================
# Condition for adding "RI" and "D0"
#===============================================================================

if (recover_input) {
  recover_input_suffix <- "RI"
} else {
  recover_input_suffix <- ""
}

if (drop_0s) {
  drop_0s_suffix <- "D0"
} else {
  drop_0s_suffix <- ""
}
if (strict_mode) {
  strict_mode_suffix <- "strict"
} else {
  strict_mode_suffix <- ""
}
if (auto_combine_replicates){
  auto_combine_replicates_suffix <- "acr"
} else {
  auto_combine_replicates_suffix <- ""
}
if (min_guides_per_gene > 0){
  min_guides_per_gene_suffix <- min_guides_per_gene
} else {
  min_guides_per_gene_suffix <- ""
}
if (combine_samples == ""){
  combine_samples_suffix <- ""
} else {
  combine_samples_suffix <- paste0("comb_", combine_samples)
}
#===============================================================================
# Construct the skip list
#===============================================================================
# WARNING, this is a weird hot fix that does not work properly for non numeric samples

create_skip_list_and_suffix <- function(skip_list, skip_list_sublib, skip_list_sample){
  skip_suffix <- ""
  
  bin <- c("I","L","U")

  # Z variants: 1..999 plus 01..99 and 001..999 (all as strings)
  possible_sample_numbers <- unique(c(
    as.character(1:999),
    sprintf("%02d", 1:999),
    sprintf("%03d", 1:999)
  ))
  
  if (length(skip_list_sublib) > 0) {
    df <- expand.grid(bin = bin, sublib = skip_list_sublib, sample = possible_sample_numbers, stringsAsFactors = FALSE)
    skip_list <- c(skip_list, paste(df$bin, df$sublib, df$sample, sep = "_"))
    skip_suffix <- paste0(skip_suffix, "no_sublib_", paste0(skip_list_sublib, collapse = "_"))
  }
  if (length(skip_list_sample) > 0) {
    if (length(skip_list_sublib) > 0) {
      skip_suffix <- paste0(skip_suffix, "_")
    }
    possible_sublib_numbers <- unique(c(
      paste0("L", 1:999),
      paste0("L", sprintf("%02d", 1:999)),
      paste0("L", sprintf("%03d", 1:999))
    ))
    df <- expand.grid(bin = bin, sublib = possible_sublib_numbers, sample = skip_list_sample, stringsAsFactors = FALSE)
    skip_list <- c(skip_list, paste(df$bin, df$sublib, df$sample, sep = "_"))
    skip_suffix <- paste0(skip_suffix, "no_sample_", paste0(skip_list_sample, collapse = "_"))
  }
  skip_list <- unique(skip_list)
  return(list(skip_list, skip_suffix))
}
skip_list_and_suffix <- create_skip_list_and_suffix(skip_list,
                                                    skip_list_sublib,
                                                    skip_list_sample)
skip_list <- skip_list_and_suffix[[1]]
skip_suffix <- skip_list_and_suffix[[2]]

#===============================================================================
# Construct the file suffix
#===============================================================================
fs_parts <- c(pipeline,
           data_type,
           method,
           norm_method,
           recover_input_suffix,
           drop_0s_suffix,
           strict_mode_suffix,
           min_guides_per_gene_suffix,
           combine_samples_suffix,
           auto_combine_replicates_suffix,
           skip_suffix,
           extra_suffix)

# keep only non-empty parts
fs_parts <- fs_parts[fs_parts != ""]

file_suffix <- paste0("_", paste(fs_parts, collapse = "_"), ".rds")

fi_parts <- c(pipeline,
              data_type,
              method,
              norm_method,
              recover_input_suffix,
              drop_0s_suffix,
              strict_mode_suffix,
              min_guides_per_gene_suffix,
              combine_samples_suffix,
              auto_combine_replicates_suffix,
              skip_suffix,
              extra_suffix)

# keep only non-empty parts
fi_parts <- fi_parts[fi_parts != ""]

file_info_suffix <- paste(fi_parts, collapse = "_")

# Print the final file suffix
cat("File Suffix: ", file_suffix, "\n")

#===============================================================================
# Construct File Paths
#===============================================================================
make_clean_dir <- function(base_path, sub_path) {
  
  full_path <- paste0(base_path, "/", sub_path)
  
  full_path <- gsub("///", "/", full_path, fixed = TRUE)
  full_path <- gsub("//", "/", full_path, fixed = TRUE)
  
  if (!dir.exists(full_path)) {
    dir.create(full_path, recursive = TRUE)
  }
  return(full_path)
}
get_file_path <- function(folder_path, file_name){
  full_path <- paste0(folder_path, "/",file_name)
  full_path <- gsub("///", "/", full_path, fixed = TRUE)
  full_path <- gsub("//", "/", full_path, fixed = TRUE)
  return(full_path)
}

genome_output_folder <- make_clean_dir(output_folder, "/ref/")
dedup_output_folder <- make_clean_dir(output_folder, "/dedup/")
mapped_output_folder <- make_clean_dir(output_folder, "/mapped/")
rds_output_folder <- make_clean_dir(output_folder, "/rds/")
results_output_folder <- make_clean_dir(output_folder, "/results/")

merged_sgRNA_df <- readRDS(get_file_path(rds_output_folder,
                                         "merged_sgRNA_df.rds"))

```

## Generate the long format read/umi counts either from my pipline or from johns
Also provides information for each file about coverage and correct alignment

```{r get_count_df_long, eval=TRUE}

read_file_to_df <- function(file_name,
                            folder_path = dedup_output_folder,
                            suffix_to_rm = "_dedup_idxstats.txt",
                            threshold_df = NULL,
                            check_alignments = TRUE
                            ){
  
  file_path <- paste0(folder_path,file_name)  
  df <- read.table(file_path, header=FALSE, sep="\t", stringsAsFactors=FALSE)
  name <- sub(suffix_to_rm,"",file_name)
  sub_lib <- str_match(name, "^[A-Za-z]+_L(\\d+)_\\d+")[, 2]
  sub_lib <- paste0("ICS_",sub_lib)
  exp <- str_replace(name, "^([^_]+_)", "")
  if(is.null(threshold_df)){
    threshold <- 0
  } else {
    threshold <- threshold_df$threshold[threshold_df$replicate == name]
  }
  
  df <- df %>% 
    rename(sgRNA = V1, count = V3, length = V2) %>%
    select(-V4) %>%
    mutate(count = if_else(count <= threshold, 0, count),
           exp = exp) %>%
    filter(sgRNA != "*")
  
  check_df <- merged_sgRNA_df %>% select(sgrna_id, sublib)
  # First try: plain left_join
  joined_df <- df %>%
    left_join(check_df, by = c("sgRNA" = "sgrna_id"))
  
  # Check for non-unique sgRNA in the result
  if (any(duplicated(joined_df$sgRNA))) {
    warning("Non-unique `sgRNA` after join; redoing join with 1:1 pairing by order.\n")
    
    # Add within-id index on both sides
    df_idx <- df %>%
      group_by(sgRNA) %>%
      mutate(.pair_id = row_number()) %>%
      ungroup()
    
    check_idx <- check_df %>%
      group_by(sgrna_id) %>%
      mutate(.pair_id = row_number()) %>%
      ungroup()
    
    # Redo join using sgRNA/sgrna_id + the position
    joined_df <- df_idx %>%
      left_join(
        check_idx,
        by = c("sgRNA" = "sgrna_id", ".pair_id")
      ) %>%
      select(-.pair_id)      # clean up helper column
    df <- joined_df
  } else {
    df <- joined_df
  }
  
  if (check_alignments == TRUE) {
    cat("Checking wrong allignments for: ", name,"\n")
    # Filter non-control rows with count > 0
    non_control_df <- df %>%
      filter(!grepl("^CONTROL_", sgRNA), count > 0)

    # Count sum stats
    correct_sum <- non_control_df %>% filter(sublib == sub_lib) %>% summarise(total = sum(count)) %>% pull(total)
    wrong_sum <- non_control_df %>% filter(sublib != sub_lib) %>% summarise(total = sum(count)) %>% pull(total)
    total_sum <- correct_sum + wrong_sum
    
    cat("UMI/read count allignment Stats:\n")
    cat(sprintf("  Correct (aligned to sgRNA in sublibary):     %d (%.2f%%)\n", 
                correct_sum, 100 * correct_sum / total_sum))
    cat(sprintf("  Wrong   (aligned to sgRNA not in sublibary): %d (%.2f%%)\n\n", 
                wrong_sum, 100 * wrong_sum / total_sum))
  }
  
  same_controls_in_all_sublibraries <- get("same_controls_in_all_sublibraries", envir = .GlobalEnv)
  if (same_controls_in_all_sublibraries == TRUE){
    df <- df %>%
      filter(sublib == sub_lib | grepl("^CONTROL_", sgRNA)) %>%
      select(-sublib)
  } else {
    df <- df %>%
      filter(sublib == sub_lib) %>%
      select(-sublib)
  }
  
  if (check_alignments == TRUE) {
    cat(sprintf("sgRNA coverage: %.2f%%\n", sum(df$count > 0) / nrow(df) * 100))
    cat("--------------------------------------------\n")
  }
    
  df <- df %>%
    mutate(group_category = case_when(
      # grepl("^CONTROL_C_EGFP_", sgRNA) ~ "EGFP_control",
      grepl("^CONTROL_C_NONTARG_", sgRNA) ~ "non_targeting_control",
      grepl("^CONTROL_C_", sgRNA) ~ "targeting_control",
      TRUE ~ "targeting"
    ))
  return(df)
}

process_folder_files <- function(folder_path,
                                 threshold_df = NULL,
                                 skip_list = c(),
                                 check_alignments = TRUE){
  
  data_type <- get("data_type", envir = .GlobalEnv)

  # List all matching files in the folder
  if (data_type == "umis") {
    files <- list.files(
      folder_path,
      pattern = "^[ILU]_L\\d+_\\d+_dedup_idxstats\\.txt$",
      full.names = TRUE
    )
  
  } else if (data_type == "reads") {
    files <- list.files(
      folder_path,
      pattern = "^[ILU]_L\\d+_\\d+_Aligned\\.sortedByCoord\\.out_idxstats\\.txt$",
      full.names = TRUE
    )
  
  } else {
    stop("Invalid data_type. data_type must be 'reads' or 'umis'")
  }

  
  
  # Read each file and combine them
  combined_df <- bind_rows(lapply(files, function(file) {
    # Extract the filename
    file_name <- basename(file)
    if (data_type == "umis"){
      name <- sub("_dedup_idxstats.txt","",file_name)
      # Extract condition (X), sublib (L#), and sample (#) using regex
      matches <- str_match(file_name, "^([ILU])_L(\\d+)_(\\d+)_dedup_idxstats\\.txt$")
      suffix_to_remove <- "_dedup_idxstats.txt"
    }
    if (data_type == "reads"){
      name <- sub("_Aligned.sortedByCoord.out_idxstats.txt","",file_name)
      # Extract condition (X), sublib (L#), and sample (#) using regex
      matches <- str_match(file_name, "^([ILU])_L(\\d+)_(\\d+)_Aligned\\.sortedByCoord\\.out_idxstats\\.txt$")
      suffix_to_remove <- "_Aligned.sortedByCoord.out_idxstats.txt"
    }
    
    # Skip entries from skip list
    if (name %in% skip_list){
      print(paste(name, "skipped due to skip list"))
      return(NULL)
      }
    
    if (is.na(matches[1])) {
      stop(paste("Filename does not match expected pattern:", file_name))
    }
    
    condition <- case_when(
      matches[2] == "I" ~ "input",
      matches[2] == "L" ~ "lower",
      matches[2] == "U" ~ "upper"
    )
    
    sublib <- paste0("sublib_", matches[3])
    sample <- paste0("sample_", matches[4])
    
    # Read the file using your existing function
    df <- read_file_to_df(file_name = file_name,
                          folder_path = folder_path,
                          threshold_df = threshold_df,
                          check_alignments = check_alignments,
                          suffix_to_rm = suffix_to_remove)
    
    # Add the new columns
    df <- df %>%
      mutate(condition = condition, sublib = sublib, sample = sample) %>% 
      select(-length)
    
    return(df)
  }))
  
  return(combined_df)
}
read_john_data <- function(dir_path, sgRNA_df) {
  # Step 1: Read barcodes.tsv.gz and get seq values
  
  barcodes_path <- file.path(dir_path, "barcodes.tsv.gz")
  barcode_seqs <- read_tsv(barcodes_path, col_names = FALSE, show_col_types = FALSE) %>%
    pull(1) %>%
    basename()

  # Step 2: Read matrix.mtx.gz (only diagonal values matter)
  matrix_path <- file.path(dir_path, "matrix.mtx.gz")
  mat <- readMM(matrix_path)

  if (!is(mat, "dgTMatrix")) {
    mat <- as(mat, "dgTMatrix")
  }

  # Extract diagonal (should match barcodes length)
  diag_values <- Matrix::diag(mat)

  # Step 3: Construct dataframe with seq and count
  count_df <- tibble(
    seq = barcode_seqs,
    count = diag_values
  )

  # Step 4: Join with sgRNA_df by seq
  joined_df <- sgRNA_df %>%
    select(seq, sgrna_id) %>% 
    inner_join(count_df, by = "seq") %>% 
    select(sgrna_id,count) %>% 
    mutate(count = as.integer(count))

  return(joined_df)
}
read_john_rf_data  <- function(file_path, sgRNA_df){
  count_df <- read.table(file_path, sep = "\t", header = FALSE, col.names = c("seq", "count"))
 
  joined_df <- sgRNA_df %>%
    select(seq, sgrna_id) %>% 
    inner_join(count_df, by = "seq") %>% 
    select(sgrna_id,count) %>% 
    mutate(count = as.integer(count))
  
  return(joined_df)
}

# Helper function for process_john_rf_data and process_john_data
complete_sgrna_df <- function(df,
                              merged_sgRNA_df,
                              sublib,
                              name = NULL,
                              check_alignments = TRUE) {

  expected_ids <- merged_sgRNA_df %>%
    filter(sublib == !!sublib | grepl("^CONTROL_", sgrna_id)) %>%
    pull(sgrna_id)
  
  missing_ids <- base::setdiff(expected_ids, df$sgrna_id)
  
  new_rows <- tibble(sgrna_id = missing_ids, count = 0)
  
  complete_df <- bind_rows(df, new_rows)
  
  if (check_alignments == TRUE) {
    if (is.null(name)) {name <- sublib}

    # Join with merged_sgRNA_df to get sublib info
    annotated_df <- complete_df %>%
      left_join(merged_sgRNA_df %>% select(sgrna_id, sublib), by = "sgrna_id") %>%
      filter(!grepl("^CONTROL_", sgrna_id), count > 0)
    
    correct_sum <- annotated_df %>% filter(sublib == !!sublib) %>% summarise(total = sum(count)) %>% pull(total)
    wrong_sum   <- annotated_df %>% filter(sublib != !!sublib) %>% summarise(total = sum(count)) %>% pull(total)
    total_sum   <- correct_sum + wrong_sum

    cat("Checking wrong alignments for: ", name, "\n")
    cat("UMI/read count alignment Stats:\n")
    cat(sprintf("  Correct (aligned to sgRNA in sublibrary):     %d (%.2f%%)\n", 
                correct_sum, 100 * correct_sum / total_sum))
    cat(sprintf("  Wrong   (aligned to sgRNA not in sublibrary): %d (%.2f%%)\n\n", 
                wrong_sum, 100 * wrong_sum / total_sum))
    cat("--------------------------------------------\n")
  }


  return(complete_df)
}

process_john_rf_data <- function(parent_dir,
                                 merged_sgRNA_df = merged_sgRNA_df,
                                 data_type = "umis",
                                 skip_list = c("L_L4_3","U_L4_3"),
                                 suffix_to_rm = "_results.tsv",
                                 check_alignments = TRUE) {
  
  # Initialize list to collect data
  results <- list()
  file_paths <- list.files(path = parent_dir, pattern = "_results\\.tsv$", full.names = TRUE)
  merged_sgRNA_df$sublib <- gsub("ICS", "sublib", merged_sgRNA_df$sublib)
  for (file in file_paths){
    file_name <- basename(file)
    name <- sub(suffix_to_rm,"",file_name)
    # Skip entries from skip list
    if (name %in% skip_list){next}
    # Extract condition (X), sublib (L#), and sample (#) using regex
    pattern <- paste0("^([ILU])_L(\\d+)_(\\d+)", suffix_to_rm)
    matches <- str_match(file_name, pattern)
    
    if (is.na(matches[1])) {
      stop(paste("Filename does not match expected pattern:", file_name))
    }
    
    condition <- case_when(
      matches[2] == "I" ~ "input",
      matches[2] == "L" ~ "lower",
      matches[2] == "U" ~ "upper"
    )
    
    sublib <- paste0("sublib_", matches[3])
    sample <- paste0("sample_", matches[4])
    exp <- paste0("L", matches[3], "_", matches[4])
    
    # Safely read data
    df <- tryCatch({
      df <- read_john_rf_data(file, merged_sgRNA_df)
      df <- complete_sgrna_df(df,
                              merged_sgRNA_df,
                              sublib,
                              name = name,
                              check_alignments = check_alignments)
      
      df %>%
        mutate(
          condition = condition,
          sublib = sublib,
          sample = sample,
          exp = exp
        )
    }, error = function(e) {
      cat("Skipping due to error in", file_name, "->", e$message, "\n")
      return(NULL)
    })
    
    if (!is.null(df)) {
    # Rename and add group_category
    df <- df %>%
      rename(sgRNA = sgrna_id) %>%
      mutate(group_category = case_when(
        grepl("^CONTROL_C_NONTARG_", sgRNA) ~ "non_targeting_control",
        grepl("^CONTROL_C_", sgRNA) ~ "targeting_control",
        TRUE ~ "targeting"
      ))

    results[[length(results) + 1]] <- df
    }
  }

  # Combine all data frames
  final_df <- bind_rows(results)

  return(final_df)
}

process_john_data <- function(parent_dir,
                              merged_sgRNA_df = merged_sgRNA_df,
                              data_type = "umis",
                              skip_list = c("L_L4_3","U_L4_3"),
                              check_alignments = TRUE) {
  # Get list of matching subdirectories
  subdirs <- list.dirs(parent_dir, recursive = FALSE, full.names = TRUE)
  subdirs <- subdirs[grepl("_output_all$", basename(subdirs))]
  
  merged_sgRNA_df$sublib <- gsub("ICS", "sublib", merged_sgRNA_df$sublib)

  # Initialize list to collect data
  results <- list()

  for (dir_path in subdirs) {
    folder_name <- basename(dir_path)
    
    match <- str_match(folder_name, "^([A-Z])([A-Z])([0-9])([0-9])_output_all$")

    if (any(is.na(match))) {
      warning(paste("Skipping folder with unexpected name:", folder_name))
      next
    }
    name <- paste0(match[2],"_",match[3],match[4],"_",match[5])
    if (name %in% skip_list){next}
    
    condition <- case_when(
      match[2] == "I" ~ "input",
      match[2] == "L" ~ "lower",
      match[2] == "U" ~ "upper",
      TRUE ~ NA_character_
    )
    
    sublib <- paste0("sublib_", match[4])
    sample <- paste0("sample_", match[5])
    exp <- paste0(match[3], match[4], "_", match[5])


    # Path to raw_umis_bc_matrix
    if (data_type == "umis"){
      matrix_dir <- file.path(dir_path, "raw_umis_bc_matrix")
    }
    if (data_type == "reads"){
      matrix_dir <- file.path(dir_path, "raw_reads_bc_matrix")
    }

    # Safely read data
    df <- tryCatch({
      df <- read_john_data(matrix_dir, merged_sgRNA_df)
      df <- complete_sgrna_df(df,
                              merged_sgRNA_df,
                              sublib,
                              name = name,
                              check_alignments = check_alignments)
      
      df %>%
        mutate(
          condition = condition,
          sublib = sublib,
          sample = sample,
          exp = exp
        )
    }, error = function(e) {
      cat("Skipping due to error in", folder_name, "->", e$message, "\n")
      return(NULL)
    })

    if (!is.null(df)) {
      # Rename and add group_category
      df <- df %>%
        rename(sgRNA = sgrna_id) %>%
        mutate(group_category = case_when(
          grepl("^CONTROL_C_NONTARG_", sgRNA) ~ "non_targeting_control",
          grepl("^CONTROL_C_", sgRNA) ~ "targeting_control",
          TRUE ~ "targeting"
        ))

      results[[length(results) + 1]] <- df
    } else {
      print(paste("WARNING:",matrix_dir,"yielded df -> NULL"))
    }
  }

  # Combine all data frames
  final_df <- bind_rows(results)

  return(final_df)
}
normalize_count_df_long <- function(count_df_long, norm_method = "control_median"){
  allowed_norm_methods <- c("control_median")
  if (!(norm_method %in% allowed_norm_methods)){
    cat("ERROR: ", norm_method, "is not an allowed normalization method.\n")
    cat("Implemented normalization methods: ", allowed_norm_methods,"\n")
    stop()
  }
  
  if (norm_method == "control_median"){
  
    # 1. Determine normalization factors based on control categories
    norm_fac <- count_df_long %>%
      filter(group_category %in% c("targeting_control", "non_targeting_control", "kept_control")) %>%
      group_by(condition, sublib, sample) %>%
      summarise(norm_factor = median(count), .groups = "drop")
    
    # 2. Global median across all counts (entire dataset)
    med_count <- median(count_df_long$count)
    
    count_df_long_continue <- count_df_long
    
    if (med_count == 0 | any(norm_fac$norm_factor == 0)) {
      cat("WARNING: at least one normalization factor is 0\n")
      cat("Median of all counts:", med_count, "\n")
      
      zero_nf <- norm_fac %>% 
        filter(norm_factor == 0)
      
      if (!(nrow(zero_nf) == 0)) {
        cat("Groups with norm_factor == 0:\n")
        print(norm_fac)# shows condition | sublib | sample | norm_factor
        cat("Adding global pseudocount (+1).\n")
        pseudocount_added <<- TRUE
        
        count_df_long_plus_one <- count_df_long %>% mutate(count = count + 1)
        norm_fac <- count_df_long_plus_one %>%
          filter(group_category %in% c("targeting_control", "non_targeting_control", "kept_control")) %>%
          group_by(condition, sublib, sample) %>%
          summarise(norm_factor = median(count), .groups = "drop")
        
        # 2. Global median across all counts (entire dataset) #
        med_count <- median(count_df_long_plus_one$count)
        
        count_df_long_continue <- count_df_long_plus_one
      }
      
      cat("--------------------------------------------\n")
    }
    
    # 3. Normalize counts using (count * med_count / norm_factor)
    return_df <- count_df_long_continue %>%
      inner_join(norm_fac, by = c("condition", "sublib", "sample")) %>%
      mutate(norm_count = (count * med_count) / norm_factor) %>% 
      mutate(count = round(norm_count,2)) %>%
      select(-c(norm_factor,norm_count))
  }
  return_df <- return_df %>% mutate(count = round(count))
  return(return_df)
}

process_john_data_backup <- process_john_data
pseudocount_added <- FALSE

sink(get_file_path(rds_output_folder,paste0(file_info_suffix,"_coverage.txt")),
     split = TRUE) # capture output into a file

if (pipeline == "john"){
  count_df_long <- process_john_data(john_folder,
                                     data_type = data_type,
                                     merged_sgRNA_df = merged_sgRNA_df,
                                     skip_list = skip_list)
  if (extra_suffix == "rf"){
      count_df_long <- count_df_long %>% 
      mutate(count = ifelse(count < simplified_rf_threshold, 0, count))        
      }
} else {
  if (pipeline == "lukas"){
    if (data_type == "umis"){
      count_df_long <- process_folder_files(dedup_output_folder,
                                            skip_list = skip_list) #Add threshold df if thresholds should be applied 
    }
    if (data_type == "reads"){
      count_df_long <- process_folder_files(mapped_output_folder,
                                            skip_list = skip_list) #Add threshold df if thresholds should be applied 
      if (extra_suffix == "rf"){
        count_df_long <- count_df_long %>% 
        mutate(count = ifelse(count < simplified_rf_threshold, 0, count))        
      }

    }
       
  } else {
    if (pipeline == "john_rf"){
      count_df_long <- process_john_rf_data(john_rf_folder,
                                            data_type = data_type,
                                            merged_sgRNA_df = merged_sgRNA_df,
                                            skip_list = skip_list)
      
      process_john_data <- process_john_rf_data
      if (extra_suffix == "rf"){
        count_df_long <- count_df_long %>% 
        mutate(count = ifelse(count < simplified_rf_threshold, 0, count))        
      }
    } else {
      stop("Unsupported pipeline specified. Exiting. Pipline must be john, john_rf or lukas.")
    }
  }  
}
sink()
if (extra_suffix == "cf"){
  count_df_long <- count_df_long %>%
    filter(!(group != "targeting" & count < simplified_cf_threshold))
}

# Extend the include_controls_list if use_only_these_controls_list is given
if (exists("use_only_these_controls_list")) {
  if (length(use_only_these_controls_list) > 0){
    # list of sgRNAs that were not targeting (before) and not in allowed controls
    excluded_controls <- count_df_long %>%
      filter(group_category != "targeting", !sgRNA %in% use_only_these_controls_list) %>%
      distinct(sgRNA) %>%
      pull(sgRNA)
  
    include_controls_list <- c(include_controls_list, excluded_controls)
  }
}
if (length(include_controls_list) > 0){
  for (control_gene in include_controls_list){
    count_df_long$group_category[grepl(control_gene, count_df_long$sgRNA)] <- "targeting"
  }
}

```

```{r make_coverage_output, eval=True}
parse_coverage_file <- function(path) {
  lines <- readLines(path, warn = FALSE)

  # find each sample block start
  start_idx <- grep("^Checking wrong allignments for:", lines)
  if (length(start_idx) == 0) {
    stop("No sample blocks found. Expected lines starting with: 'Checking wrong allignments for:'")
  }

  # define block ends (right before next start, or end of file)
  end_idx <- c(start_idx[-1] - 1, length(lines))

  # small safe parsers
  parse_reads <- function(line) {
    if (is.na(line) || length(line) == 0) return(NA_real_)
    as.numeric(gsub(",", "", sub(".*?:\\s*([0-9,]+)\\s*\\(.*", "\\1", line)))
  }

  parse_perc <- function(line) {
    if (is.na(line) || length(line) == 0) return(NA_real_)
    as.numeric(sub(".*\\(([-0-9.]+)%\\).*", "\\1", line))
  }

  parse_coverage <- function(line) {
    if (is.na(line) || length(line) == 0) return(NA_real_)
    as.numeric(sub("^sgRNA coverage:\\s*([-0-9.]+)%.*", "\\1", line))
  }

  out <- lapply(seq_along(start_idx), function(k) {
    block <- lines[start_idx[k]:end_idx[k]]

    sample_name <- sub("^Checking wrong allignments for:\\s*", "", block[1])

    correct_line <- block[grep("^\\s*Correct", block)][1]
    wrong_line   <- block[grep("^\\s*Wrong", block)][1]
    cov_line     <- block[grep("^sgRNA coverage:", block)][1]

    correct_reads <- parse_reads(correct_line)
    correct_perc  <- parse_perc(correct_line)

    wrong_reads <- parse_reads(wrong_line)
    wrong_perc  <- parse_perc(wrong_line)

    coverage <- parse_coverage(cov_line)

    data.frame(
      sample_name   = sample_name,
      correct_reads = correct_reads,
      correct_perc  = paste0(sprintf("%.2f", correct_perc), "%"),
      wrong_reads   = wrong_reads,
      wrong_perc    = paste0(sprintf("%.2f", wrong_perc), "%"),
      coverage      = paste0(sprintf("%.2f", coverage), "%"),
      stringsAsFactors = FALSE
    ) %>% mutate(
      sample_name = sub(" ", "", sample_name)
    )
  })

  do.call(rbind, out)
}
add_star_log_stats <- function(df, mapped_output_folder) {

  # Map STAR log "labels" -> dataframe column names
  metrics_map <- c(
    "Number of input reads"                         = "input_reads",
    "Average input read length"                     = "avg_input_read_length",
    "Uniquely mapped reads number"                  = "uniquely_mapped_reads",
    "Uniquely mapped reads %"                       = "uniquely_mapped_perc",
    "Average mapped length"                         = "avg_mapped_length",
    "Mismatch rate per base, %"                     = "mismatch_rate_per_base_perc",
    "Deletion rate per base"                        = "deletion_rate_per_base_perc",
    "Deletion average length"                       = "deletion_avg_length",
    "Insertion rate per base, %"                    = "insertion_rate_per_base_perc",
    "Insertion average length"                      = "insertion_avg_length",
    "Number of reads mapped to multiple loci"       = "multi_loci_reads",
    "% of reads mapped to multiple loci"            = "multi_loci_reads_perc",
    "Number of reads mapped to too many loci"       = "too_many_loci_reads",
    "% of reads mapped to too many loci"            = "too_many_loci_reads_perc",
    "Number of reads unmapped: too many mismatches" = "unmapped_too_many_mismatches",
    "% of reads unmapped: too many mismatches"      = "unmapped_too_many_mismatches_perc",
    "Number of reads unmapped: too short"           = "unmapped_too_short",
    "% of reads unmapped: too short"                = "unmapped_too_short_perc",
    "Number of reads unmapped: other"               = "unmapped_other",
    "% of reads unmapped: other"                    = "unmapped_other_perc"
  )

  # Helper: parse a single STAR Log.final.out file -> one-row data.frame
  parse_star_log_file <- function(sample_name) {
    log_path <- get_file_path(mapped_output_folder,
                             paste0(sample_name, "_Log.final.out"))

    # If file missing, return all NAs
    if (!file.exists(log_path)) {
      warning("STAR log not found for sample '", sample_name, "': ", log_path)
      na_vals <- setNames(rep(NA_real_, length(metrics_map)), metrics_map)
      return(as.data.frame(as.list(na_vals)))
    }

    lines <- readLines(log_path, warn = FALSE)

    # Extract numeric value from the line after the "|" and remove "%"
    extract_value <- function(key) {
      idx <- which(grepl(key, lines, fixed = TRUE))[1]
      if (length(idx) == 0 || is.na(idx)) return(NA_real_)

      parts <- strsplit(lines[idx], "\\|")[[1]]
      if (length(parts) < 2) return(NA_real_)

      val_str <- trimws(parts[2])
      as.numeric(gsub("%", "", val_str))
    }

    vals <- vapply(names(metrics_map), extract_value, numeric(1))
    names(vals) <- base::unname(metrics_map)

    as.data.frame(as.list(vals), stringsAsFactors = FALSE)
  }

  # Parse all samples and bind into one df
  stats_df <- do.call(
    rbind,
    lapply(df$sample_name, parse_star_log_file)
  )

  # Append columns to the original df
  cbind(df, stats_df)
}

df_cov <- parse_coverage_file(get_file_path(
  rds_output_folder, paste0(file_info_suffix, "_coverage.txt")
))

mapping_results_df <- add_star_log_stats(df_cov, mapped_output_folder)

rm(df_cov)

overall_targeting <- count_df_long %>%
  summarise(
    total_counts     = sum(count, na.rm = TRUE),
    targeting_counts = sum(count[group_category == "targeting"], na.rm = TRUE),
    targeting_perc   = 100 * targeting_counts / total_counts
  ) %>%
  mutate(targeting_perc = sprintf("%.2f%%", targeting_perc))

targeting_by_group <- count_df_long %>%
  group_by(condition, sublib, sample) %>%
  summarise(
    total_counts     = sum(count, na.rm = TRUE),
    targeting_counts = sum(count[group_category == "targeting"], na.rm = TRUE),
    targeting_perc   = 100 * targeting_counts / total_counts,
    .groups = "drop"
  ) %>%
  mutate(targeting_perc = sprintf("%.2f%%", targeting_perc))

overall_targeting_merged <- merged_sgRNA_df %>%
  summarise(
    total_counts     = sum(count, na.rm = TRUE),
    targeting_counts = sum(count[!is.na(entrez)], na.rm = TRUE),
    targeting_perc   = 100 * targeting_counts / total_counts
  ) %>%
  mutate(targeting_perc = sprintf("%.2f%%", targeting_perc))


# ---- Write everything into ONE excel file as separate sheets ----
write_xlsx(
  list(
    mapping_results          = mapping_results_df,
    overall_targeting        = overall_targeting,
    targeting_by_group       = targeting_by_group,
    overall_targeting_reference = overall_targeting_merged
  ),
  get_file_path(results_output_folder,
                paste0(file_info_suffix, "_mapping_results.xlsx"))
)

```
## More detailed data exploration based on the long format read/umi counts 
Run this to check the plots
```{r data_exploration_violin, eval=FALSE}
plot_violin_by_sublib_sample <- function(count_df_long, norm_method = NULL) {
  df <- count_df_long
  
  if (!is.null(norm_method)){
    df <- normalize_count_df_long(count_df_long, norm_method)
    norm_title <- paste0("(normalization: ",norm_method,")")
  } else {
    norm_title <- "(no normalization)"
  }
  count_type <- get("data_type", envir = .GlobalEnv)
  if (!(count_type %in% c("umis","reads"))){
    cat("ERROR ", count_type, " is not a viable data_type.")
    cat("data_type must be umis or reads")
    stop()
  }
  if (count_type == "umis"){
    title_prefix <- "UMI counts for"
  }
  if (count_type == "reads"){
    title_prefix <- "Read counts for"
  }
  # Use exact matching for group_type
  df <- df %>%
    mutate(group_type = ifelse(group_category == "targeting", "targeting", "non-targeting"))

  # Get all unique (sublib, sample) pairs
  unique_groups <- df %>%
    distinct(sublib, sample)

  plot_list <- list()

  for (i in 1:nrow(unique_groups)) {
    
    sublib_val <- unique_groups$sublib[i]
    sample_val <- unique_groups$sample[i]
    title <- paste0("L",sub("sublib_","",sublib_val),"_",sub("sample_","",sample_val))
    # Subset for that combination
    df_subset <- df %>%
      filter(sublib == sublib_val, sample == sample_val)

    # Filter 3 unique conditions from each group_type
    df_subset <- df_subset %>%
      rename(Type = group_type) %>% 
      group_by(Type, condition) %>%
      filter(n() > 0) %>%
      ungroup()

    targeting_conds <- df_subset %>%
      filter(Type == "targeting") %>%
      pull(condition) %>%
      unique() %>%
      head(3)

    nontargeting_conds <- df_subset %>%
      filter(Type == "non-targeting") %>%
      pull(condition) %>%
      unique() %>%
      head(3)

    df_filtered <- df_subset %>%
      filter((Type == "targeting" & condition %in% targeting_conds) |
             (Type == "non-targeting" & condition %in% nontargeting_conds))

    # Plot
    p <- ggplot(df_filtered, aes(x = condition, y = count, fill = Type)) +
      geom_violin(trim = FALSE, scale = "width") +
      labs(
        title = paste0(title_prefix," ",sublib_val,", ", sample_val," ",norm_title),
        x = "",
        y = "Count"
      ) +
      theme_minimal() +
      theme(axis.text.x = element_text(angle = 45, hjust = 1))

    plot_list[[paste(sublib_val, sample_val, sep = "_")]] <- p
  }

  return(plot_list)
}
get_grouped_summary_wide <- function(count_df_long, stat = c("median", "mean")) {
  stat <- match.arg(stat)  # ensure valid input

  # Define function to apply
  summary_fun <- switch(
    stat,
    median = function(x) median(x, na.rm = TRUE),
    mean = function(x) round(mean(x, na.rm = TRUE), 2)
  )

  # Assign group_type via exact matching
  count_df_long <- count_df_long %>%
    mutate(group_type = ifelse(group_category == "targeting", "targeting", "non-targeting"))

  unique_groups <- count_df_long %>%
    distinct(sublib, sample)

  summary_rows <- list()

  for (i in 1:nrow(unique_groups)) {
    sublib_i <- unique_groups$sublib[i]
    sample_i <- unique_groups$sample[i]

    df_sub <- count_df_long %>%
      filter(sublib == sublib_i, sample == sample_i)

    for (grp in c("targeting", "non-targeting")) {
      df_grp <- df_sub %>%
        filter(group_type == grp)

      # Take up to 3 sorted conditions
      conds <- sort(unique(df_grp$condition))[1:min(3, length(unique(df_grp$condition)))]

      # Calculate summary values (median or mean)
      summaries <- df_grp %>%
        filter(condition %in% conds) %>%
        group_by(condition) %>%
        summarise(val = summary_fun(count), .groups = "drop") %>%
        arrange(condition)

      values <- c(summaries$val, rep(NA, 3 - nrow(summaries)))
      names(values) <- c("condition_lower", "condition_middle", "condition_upper")[1:length(values)]

      row <- tibble(
        group_id = paste(sublib_i, sample_i, grp, sep = "_"),
        !!!as.list(values)
      )

      summary_rows[[length(summary_rows) + 1]] <- row
    }
  }

  summary_df <- bind_rows(summary_rows)
  return(summary_df)
}


plot_violin_by_group_category_split_by_sublib <- function(df,
                                                          include_targeting = TRUE,
                                                          norm_method = NULL,
                                                          y_limit = 60,
                                                          box_col = "white",
                                                          viol_col = "#E0E0E0") {
  
  
  
  
  if (!is.null(norm_method)){
    df <- normalize_count_df_long(df, norm_method)
    norm_title <- paste0("(normalization: ",norm_method,")")
  } else {
    norm_title <- "(no normalization)"
  }
  count_type <- get("data_type", envir = .GlobalEnv)
  if (!(count_type %in% c("umis","reads"))){
    cat("ERROR ", count_type, " is not a viable data_type.")
    cat("data_type must be umis or reads")
    stop()
  }
  if (count_type == "umis"){
    title_prefix <- "UMI counts for"
  }
  if (count_type == "reads"){
    title_prefix <- "Read counts for"
  }
  
  # Filter based on group_category
  filtered_df <- df %>%
    filter(
      if (include_targeting) group_category == "targeting"
      else group_category != "targeting"
    ) %>%
    mutate(group = interaction(condition, exp, drop = TRUE))

  # Compute count summary (output + for annotation)
  count_summary <- filtered_df %>%
    group_by(condition, exp) %>%
    summarise(
      total_count = sum(count),
      mean_count = round(mean(count), 1),
      sd_count = round(sd(count), 1),
      .groups = "drop"
    ) %>%
    mutate(group = interaction(condition, exp, drop = TRUE))

  # Create one plot per unique sublib
  plots <- list()

  for (sublib_name in unique(filtered_df$sublib)) {
    sub_df <- filtered_df %>% filter(sublib == sublib_name)
    # Levels used by this sub-plot’s x axis
    x_levels <- levels(interaction(sub_df$condition, sub_df$exp, drop = TRUE))
  
    # Build label_df with matching factor levels
    label_df <- count_summary %>%
      filter(interaction(condition, exp, drop = TRUE) %in%
               unique(interaction(sub_df$condition, sub_df$exp, drop = TRUE))) %>%
      mutate(
        group_fac = factor(interaction(condition, exp, drop = TRUE), levels = x_levels),
        x_center  = as.numeric(group_fac)   # centers now 1..k, aligned with this sub-plot
      )
    
    # Plot with violin, boxplot, and text
    p <- ggplot(sub_df, aes(x = interaction(condition, exp), y = count)) +
      geom_violin(fill = viol_col, color = NA, scale = "width", trim = FALSE) +
      geom_boxplot(width = 0.1, outlier.size = 0.2, fill = box_col) +
      geom_rect(
        data = label_df,
        aes(xmin = x_center - 0.3, xmax = x_center + 0.3,
            ymin = y_limit - y_limit/8 - 0.1, ymax = y_limit + 0.1),
        inherit.aes = FALSE,
        fill = "white", color = "black", linewidth = 0.15
      ) +
      geom_text(
        data = label_df,
        aes(x = group, y = y_limit, label = total_count),
        size = 2.5, inherit.aes = FALSE
      ) +
      geom_text(
        data = label_df,
        aes(x = group, y = y_limit - y_limit/16, label = paste0("mean: ", mean_count)),
        size = 2.3, inherit.aes = FALSE
      ) +
      geom_text(
        data = label_df,
        aes(x = group, y = y_limit - y_limit/8, label = paste0("sd: ", sd_count)),
        size = 2.3, inherit.aes = FALSE
      ) +
      labs(
        title = paste(title_prefix,
                      ifelse(include_targeting, "targeting sgRNA", "non-targeting sgRNA"),
                      "–",
                      sublib_name, norm_title),
        x = "",
        y = "Count"
      ) +
      coord_cartesian(ylim = c(0, y_limit)) +
      theme_bw() +
      theme(axis.text.x = element_text(angle = 45, hjust = 1))

    plots[[sublib_name]] <- p
  }

  return(list(
    plots = plots,
    count_summary = count_summary
  ))
}
generate_all_violin_plots_and_summaries <- function(df,
                                                    norm_method=NULL,
                                                    targeting = TRUE,
                                                    non_targeting = FALSE,
                                                    summary_df = FALSE,
                                                    y_limit = 60) {
  # --- Print all 8 plots ---
  if (targeting == TRUE){
      # Run plotting function for targeting
    targeting_results <- plot_violin_by_group_category_split_by_sublib(df,
                                                                       include_targeting = TRUE,
                                                                       norm_method=norm_method,
                                                                       y_limit = y_limit,
                                                                       viol_col = "lightgreen")
    cat("Targeting plots:\n")
    for (sublib in names(targeting_results$plots)) {
      print(targeting_results$plots[[sublib]])
    }
    if (summary_df == TRUE){
      # --- Print summary tables ---
      cat("\nTargeting count summary:\n")
      print(targeting_results$count_summary)
    }

  }

  if (non_targeting == TRUE){
    non_targeting_results <- plot_violin_by_group_category_split_by_sublib(df,
                                                                         include_targeting = FALSE,
                                                                         norm_method=norm_method,
                                                                         y_limit = y_limit,
                                                                         viol_col = "lightblue")
    cat("\nNon-targeting plots:\n")
    for (sublib in names(non_targeting_results$plots)) {
      print(non_targeting_results$plots[[sublib]])
    }
    if (summary_df == TRUE){
      cat("\nNon-targeting count summary:\n")
      print(non_targeting_results$count_summary)
    }
  }
}
generate_all_violin_plots_and_summaries(count_df_long, y_limit = 8000, non_targeting = TRUE)
generate_all_violin_plots_and_summaries(count_df_long, norm_method = "control_median", y_limit = 8000, non_targeting = TRUE) 



summary_medians <- get_grouped_summary_wide(count_df_long)
summary_means <- get_grouped_summary_wide(count_df_long, stat = "mean")
print(summary_medians)
print(summary_means)
count_df_norm <- normalize_count_df_long(count_df_long, norm_method = "control_median")
plots <- plot_violin_by_sublib_sample(count_df_long)
for (i in 1:length(plots)) {
  print(plots[[i]])
}
plots <- plot_violin_by_sublib_sample(count_df_long, norm_method = "control_median")
for (i in 1:length(plots)) {
  print(plots[[i]])
}

```

## Bring the long form read/umi counts into a format accepted by MAUDE (wide format with input, upper and lower columns)

```{r prepare_data_for_maude, eval=TRUE}
#Select wether to use targeting_control or non_targeting_control for normalization (or both I guess)
ctrl_selection <- c("targeting_control","non_targeting_control")
subsample_controls_func_old <- function(count_df_long, merged_sgRNA_df, percentage_kept_controls = 0.1){
  
  percentage_used_controls = 1 - percentage_kept_controls
  count_df_long_merged <- merge(count_df_long, merged_sgRNA_df[, c("sgrna_id", "entrez")], 
                                by.x = "sgRNA", by.y = "sgrna_id", 
                                all.x = TRUE)
  count_df_long_merged <- count_df_long_merged %>%
    filter(group_category != "targeting") %>%
    distinct(sgRNA) %>% 
    mutate(
      unique_names = case_when(
        grepl("CONTROL_C_[A-Za-z0-9]+_", sgRNA) & !grepl("CONTROL_C_NONTARG", sgRNA) ~ sub("CONTROL_C_([A-Za-z0-9]+)_.*", "\\1", sgRNA),
        grepl("CONTROL_C_NONTARG", sgRNA) ~ sgRNA,  # Keep NONTARG as it is
        TRUE ~ NA_character_  # Default case, if needed
      )
    )
  unique_entries <- unique(count_df_long_merged$unique_names)
  assignments <- sample(c(TRUE, FALSE), length(unique_entries), 
                       prob = c(percentage_kept_controls, percentage_used_controls), replace = TRUE)
  # Step 3: Create a data frame to map unique entries to the TRUE/FALSE assignments
  assignment_map <- data.frame(unique_names = unique_entries, keep = assignments)
  # Step 4: Merge this map back into the original data frame to expand the assignments
  count_df_long_merged <- count_df_long_merged %>%
    left_join(assignment_map, by = "unique_names")
  return_df <- count_df_long %>%
    left_join(count_df_long_merged %>% select(sgRNA, keep), by = "sgRNA")
  # Replace NAs in 'keep' with FALSE
  return_df <- return_df %>%
    mutate(keep = ifelse(is.na(keep), FALSE, keep)) %>%
    mutate(
      # Assign 'kept_control' to group_category when keep is TRUE
      group_category = ifelse(keep == TRUE, "kept_control", group_category)
    ) %>%
    select(-keep)  # Remove the 'keep' column
  
  return(return_df)
}
subsample_controls_func <- function(count_df_long, merged_sgRNA_df, percentage_kept_controls = 0.2){
  
  percentage_used_controls = 1 - percentage_kept_controls
  
  # Merge count_df_long with merged_sgRNA_df to include 'entrez'
  count_df_long_merged <- merge(count_df_long, merged_sgRNA_df[, c("sgrna_id", "entrez")], 
                                by.x = "sgRNA", by.y = "sgrna_id", 
                                all.x = TRUE)
  
  # Filter out the "targeting" group
  count_df_long_merged <- count_df_long_merged %>%
    filter(group_category != "targeting")
  
  # Select only unique sgRNA entries (no duplicates) for subsampling
  unique_entries <- unique(count_df_long_merged$sgRNA)
  
  # Randomly assign TRUE/FALSE based on percentage_kept_controls
  assignments <- sample(c(TRUE, FALSE), length(unique_entries), 
                       prob = c(percentage_kept_controls, percentage_used_controls), replace = TRUE)
  
  # Create a data frame that maps unique sgRNAs to their keep assignments
  assignment_map <- data.frame(sgRNA = unique_entries, keep = assignments)
  
  # Merge assignment_map with the original count_df_long
  return_df <- count_df_long %>%
    left_join(assignment_map, by = "sgRNA") %>%
    mutate(
      # Change group_category based on keep and conditions
      group_category = ifelse(keep == TRUE & group_category != "targeting", "kept_control", group_category)
    ) %>%
    select(-keep)  # Drop the 'keep' column after mutation
  
  return(return_df)
}

count_df_long_to_wide <- function(count_df_long,
                                  print = TRUE,
                                  drop_0s = TRUE,
                                  recover_input = FALSE,
                                  for_sum = FALSE){
  if (print == TRUE){
    print(paste("NAs in count_df_long:",sum(is.na(count_df_long))))
  }
  if (for_sum == TRUE){
    # recover_input <- FALSE
  }
  maude_counts_df <- count_df_long %>%
    mutate(isNontargeting = ifelse(group_category %in% ctrl_selection, T, F)) %>%  
    select(-c(group_category)) %>%
    pivot_wider(names_from = condition, values_from = count) %>%
    mutate(
      upper = ifelse(is.na(upper) & !is.na(lower), 0, upper), # Replace NA in upper with 0
      lower = ifelse(is.na(lower) & !is.na(upper), 0, lower)  # Replace NA in lower with 0
    ) %>% 
    as.data.frame()
  if (print == TRUE){
    print(paste("Dimension of wide_df:",dim(maude_counts_df)))
    print(paste("NA's in maude_counts_df:", sum(is.na(maude_counts_df))))
    print(paste("NA's in Input:", sum(is.na(maude_counts_df$input))))
    print(paste("NA's in Upper:", sum(is.na(maude_counts_df$upper))))
    print(paste("NA's in Lower:", sum(is.na(maude_counts_df$lower))))
  } 
  
  if (recover_input == TRUE){
    # Step 2: Impute 'input' values where both upper and lower exist
    # First, compute the average input for each sgRNA from non-NA values
    input_means <- maude_counts_df %>%
      group_by(sgRNA, sublib) %>%
      summarize(mean_input = mean(input, na.rm = TRUE), .groups = "drop")
    
    # Step 3: Join back the means and impute missing 'input' values if upper and lower exist
    maude_counts_df <- maude_counts_df %>%
      left_join(input_means, by = c("sgRNA","sublib")) %>%
      mutate(
        input = ifelse(is.na(input) & !is.na(upper) & !is.na(lower), mean_input, input)
      ) %>%
      select(-mean_input)  # clean up
  } else {
    if (for_sum == FALSE){
      maude_counts_df <- maude_counts_df %>% 
      drop_na() # Drop any row with NA that were introduced by pivot wider
    }
  }
  
  if (drop_0s == TRUE){
    maude_counts_df <- maude_counts_df %>%
      filter(!(input == 0 & upper == 0 & lower == 0))
  }
  
  if (for_sum == FALSE){
    maude_counts_df <- maude_counts_df %>% 
      mutate(input = input + 1,
             upper = upper + 1,
             lower = lower + 1)
  }

  if (print == TRUE){
    print(paste("Dimension of wide_df:",dim(maude_counts_df)))
    print(paste("NA's in maude_counts_df:", sum(is.na(maude_counts_df))))
    print(paste("NA's in Input:", sum(is.na(maude_counts_df$input))))
    print(paste("NA's in Upper:", sum(is.na(maude_counts_df$upper))))
    print(paste("NA's in Lower:", sum(is.na(maude_counts_df$lower))))
  }
  # MAUDE seems to not like floats, so we round to integers
  # TO DO: check how I can make maude use floats.
  maude_counts_df <- maude_counts_df %>% 
    mutate(input = round(input),
           lower = round(lower),
           upper = round(upper))
  return(maude_counts_df)
}

if (subsample_controls == TRUE){
  # count_df_long_old <- subsample_controls_func_old(count_df_long, merged_sgRNA_df)
  count_df_long <- subsample_controls_func(count_df_long, merged_sgRNA_df)
}

if (!(norm_method %in% c("","control_median"))){
  stop("Error: 'norm_method' must be one of '', 'control_median'. The script will now stop.")
}
if (norm_method == "control_median"){
  count_df_long <- normalize_count_df_long(count_df_long,
                                           norm_method = norm_method)
}


  
maude_counts_df <- count_df_long_to_wide(count_df_long = count_df_long,
                                         print = FALSE,
                                         drop_0s = drop_0s,
                                         recover_input = recover_input)
if (!(method %in% c("","rep","sum",'rep_sample','rep_sublib'))){
  stop("Error: 'method' must be one of '', 'rep', 'rep_sample', 'rep_sublib', or 'sum'. The script will now stop.")
}

if (method == ""){
  maude_counts_df <- maude_counts_df %>% 
    mutate(exp = "rep1")
}
if (method == "rep"){

}
if (method == "rep_sample"){
  maude_counts_df <- maude_counts_df %>%
    mutate(exp = sample)
}
if (method == "rep_sublib"){
  maude_counts_df <- maude_counts_df %>%
    mutate(exp = sublib)
}
if (method == "sum"){
  maude_counts_df <- count_df_long_to_wide(count_df_long = count_df_long,
                                         print = FALSE,
                                         drop_0s = drop_0s,
                                         recover_input = TRUE,
                                         for_sum = TRUE)
  # Group by sgRNA and summarize the required columns
  maude_counts_df <- maude_counts_df %>%
    group_by(sgRNA, sublib) %>%
    summarize(
      input = pmax(sum(input, na.rm = TRUE), 0),  # Sum and ensure minimum is 0
      upper = pmax(sum(upper, na.rm = TRUE), 0),  # Sum and ensure minimum is 0
      lower = pmax(sum(lower, na.rm = TRUE), 0),  # Sum and ensure minimum is 0
      isNontargeting = dplyr::first(isNontargeting),  # Take the first value of isNontargeting (same for all in the group)
      .groups = 'drop'  # Drop the group structure after summarizing
    ) %>%
    mutate(
      exp = "rep1",
      input = input + 1,
      upper = upper + 1,
      lower = lower + 1
    )
}

if (strict_mode){
  if (pseudocount_added){
    umi_threshold <- 2
  } else {
    umi_threshold <- 1
  } 
  cat("Strict Mode enabled\n")
  cat("Rows before strict mode: \t", nrow(maude_counts_df),"\n")
  maude_counts_df <- maude_counts_df %>%
    filter(if_any(c(input, upper, lower), ~ . <= umi_threshold))
  cat("Rows after strict mode: \t", nrow(maude_counts_df),"\n")
}
if (length(include_controls_list) > 0) {
  for (control_gene in include_controls_list) {
    maude_counts_df$isNontargeting[grepl(control_gene, maude_counts_df$sgRNA)] <- FALSE
  }
}
if (exists("use_only_these_controls_list")) {
  if (length(use_only_these_controls_list) > 0){
    maude_counts_df$isNontargeting[ !(maude_counts_df$sgRNA %in% use_only_these_controls_list) ] <- FALSE
  }
}
if (combine_samples != ""){
  if (combine_samples == "sample"){
    maude_counts_df <- maude_counts_df %>%
      group_by(sgRNA, sublib) %>%
      summarise(
        # set sample name for the combined rows
        sample = "sample_1",
        
        # add up integer count columns
        input = sum(input, na.rm = TRUE),
        lower = sum(lower, na.rm = TRUE),
        upper = sum(upper, na.rm = TRUE),
        
        # keep the first value for everything else
        exp = dplyr::first(exp),
        isNontargeting = dplyr::first(isNontargeting),
        
        # keep one sublib/sgRNA (also fine even though they're grouping keys)
        .groups = "drop"
      )
  }
  if (combine_samples == "sublib"){
    maude_counts_df <- maude_counts_df %>%
      group_by(sgRNA, sample) %>%
      summarise(
        # set sample name for the combined rows
        sublib = "sublib_1",
        
        # add up integer count columns
        input = sum(input, na.rm = TRUE),
        lower = sum(lower, na.rm = TRUE),
        upper = sum(upper, na.rm = TRUE),
        
        # keep the first value for everything else
        exp = dplyr::first(exp),
        isNontargeting = dplyr::first(isNontargeting),
        
        # keep one sublib/sgRNA (also fine even though they're grouping keys)
        .groups = "drop"
      )    
  }
}  
```

## Exploration of the read/umi counts in MAUDE format

```{r check_data_for_maude, eval=FALSE}
if (data_type == "umis"){
    data_name <- "UMIs"
  }
if (data_type == "reads"){
    data_name <- "reads"
  } 
plot_maude_qc <- function(maude_counts_df, print = TRUE, add_0s = FALSE) {
  
  if (add_0s == TRUE){
    maude_counts_df <- maude_counts_df %>%
      mutate(
        upper = ifelse(is.na(upper), 0, upper),
        lower = ifelse(is.na(lower), 0, lower)
      )
  }
  # --- 1. Overall NA counts ---
  na_summary_overall <- maude_counts_df %>%
    pivot_longer(cols = c(input, lower, upper), names_to = "condition", values_to = "value") %>%
    mutate(is_na = is.na(value)) %>%
    group_by(condition) %>%
    summarise(na_count = sum(is_na), .groups = "drop")

  p1 <- ggplot(na_summary_overall, aes(x = condition, y = na_count, fill = condition)) +
    geom_col() +
    labs(title = "Missing Entries per Bin", y = "Number of NAs", x = "Condition") +
    theme_bw()

  # --- 2. NA counts by exp ---
  na_summary_by_exp <- maude_counts_df %>%
    pivot_longer(cols = c(input, lower, upper), names_to = "condition", values_to = "value") %>%
    mutate(is_na = is.na(value)) %>%
    group_by(exp, condition) %>%
    summarise(na_count = sum(is_na), .groups = "drop")

  p2 <- ggplot(na_summary_by_exp, aes(x = exp, y = na_count, fill = condition)) +
    geom_col(position = "dodge") +
    labs(title = "Missing Entries per Bin by Experiment", x = "Experiment", y = "Number of NAs") +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

  # --- 3. sgRNA duplicate count distribution ---
  sgRNA_counts_per_exp <- maude_counts_df %>%
    group_by(exp, sgRNA) %>%
    summarise(dup_count = n(), .groups = "drop")

  p3 <- ggplot(sgRNA_counts_per_exp, aes(x = exp, y = dup_count)) +
    geom_boxplot(fill = "skyblue") +
    labs(
      title = "How Often Do Guides Appear Per Sample?",
      x = "Experiment",
      y = "Duplicated Guides"
    ) +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  if (print == TRUE){
    print(p1)
    print(p2)
    print(p3)
  } else {
    return(list(
      overall_na_plot = p1,
      na_by_exp_plot = p2,
      sgRNA_duplicates_plot = p3
    ))
  }

  # Optionally return all plots

}

control_sanity_check <- function(maude_counts_df){
  # Create a list to store plots for each sublib
  plot_list <- list()
  
  # Loop through each unique sublib in the dataset
  for (sublib in unique(maude_counts_df$sublib)) {
    
    # Select data for the current sublib
    sublib_data <- maude_counts_df[maude_counts_df$sublib == sublib, ]
    
    # Select rows where sgRNA starts with "CONTROL_"
    control_data <- sublib_data[grepl("^CONTROL_", sublib_data$sgRNA), ]
    
    # Calculate log2 fold changes between upper/input and lower/input
    control_data$log2_upper_input <- log2(control_data$upper / control_data$input)
    control_data$log2_lower_input <- log2(control_data$lower / control_data$input)
    
    # Reshape the data for boxplot (long format with log2 fold change values)
    log2_values <- data.frame(
      sgRNA = rep(control_data$sgRNA, 2),
      log2_fold_change = c(control_data$log2_upper_input, control_data$log2_lower_input),
      comparison = rep(c("upper vs input", "lower vs input"), each = nrow(control_data))
    )
    
    # Create a boxplot for the current sublib
    p <- ggplot(log2_values, aes(x = comparison, y = log2_fold_change, fill = comparison)) +
      geom_boxplot(width = 0.5, alpha = 0.7) +
      scale_fill_manual(values = c("upper vs input" = "lightblue", "lower vs input" = "lightgreen")) +
      theme_bw() +
      labs(
        title = paste("Log2 Fold Change Between Upper/Lower and Input for", sublib),
        x = "",
        y = "Log2 Fold Change"
      ) +
      theme(
        axis.text.x = element_text(angle = 50, hjust = 1, face = "bold", size = 12),
        plot.title = element_text(size = 12),
        legend.position = "none"
      )
    
    # Store the plot for the current sublib
    plot_list[[sublib]] <- p
    
    # Print the plot for the current sublib
    print(p)
  }
  
  # Also, calculate for the whole dataset (without sublib filtering)
  # Select rows where sgRNA starts with "CONTROL_"
  control_data_all <- maude_counts_df[grepl("^CONTROL_", maude_counts_df$sgRNA), ]
  
  # Calculate log2 fold changes between upper/input and lower/input for the entire dataset
  control_data_all$log2_upper_input <- log2(control_data_all$upper / control_data_all$input)
  control_data_all$log2_lower_input <- log2(control_data_all$lower / control_data_all$input)
  
  # Reshape the data for boxplot (long format with log2 fold change values)
  log2_values_all <- data.frame(
    sgRNA = rep(control_data_all$sgRNA, 2),
    log2_fold_change = c(control_data_all$log2_upper_input, control_data_all$log2_lower_input),
    comparison = rep(c("upper vs input", "lower vs input"), each = nrow(control_data_all))
  )
  
  # Create a boxplot for the entire dataset
  p_all <- ggplot(log2_values_all, aes(x = comparison, y = log2_fold_change, fill = comparison)) +
    geom_boxplot(width = 0.5, alpha = 0.7) +
    scale_fill_manual(values = c("upper vs input" = "lightblue", "lower vs input" = "lightgreen")) +
    theme_bw() +
    labs(
      title = "Log2 Fold Change Between Upper/Lower and Input for All Data",
      x = "",
      y = "Log2 Fold Change"
    ) +
    theme(
      axis.text.x = element_text(angle = 50, hjust = 1, face = "bold", size = 12),
      plot.title = element_text(size = 12),
      legend.position = "none"
    )
  
  # Print the plot for the entire dataset
  print(p_all)
}

control_sanity_check(maude_counts_df)

# Change FALSE to input_recovery if desired
if (FALSE){
  title_sufix_1 <- "(without input recovery)"
  title_sufix_2 <- "(with input recovery)"
} else {
  title_sufix_1 <- "(before MAUDE preperation)"
  title_sufix_2 <- "(ready for MAUDE)"
}

# 1. Count unique sgRNAs per (condition, exp)
sgRNA_counts <- count_df_long %>%
  group_by(condition, exp) %>%
  summarise(total_count = sum(count), .groups = "drop") %>%
  mutate(Sample = interaction(condition, exp, drop = TRUE),
         Bin = condition)  # for x-axis

# 2. Plot
o <- ggplot(sgRNA_counts, aes(x = Sample, y = total_count, fill = Bin)) +
  geom_col() +
  labs(
    title = paste("Sum of", data_name, "per sample"),
    x = "Sample",
    y = paste("Sum of", data_name)
  ) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, face = "bold"),
        axis.text.y = element_text(face = "bold"),
        legend.position = "none")


# 1. Count unique sgRNAs per (condition, exp)
sgRNA_counts <- count_df_long %>%
  group_by(condition, exp) %>%
  summarise(num_sgRNAs = n(), .groups = "drop") %>%
  mutate(Sample = interaction(condition, exp, drop = TRUE),
         Bin = condition)  # for x-axis

# 2. Plot
p <- ggplot(sgRNA_counts, aes(x = Sample, y = num_sgRNAs, fill = Bin)) +
  geom_col() +
  labs(
    title = paste("Number of sgRNA entries per sample",title_sufix_1),
    x = "Sample",
    y = "Number of sgRNA entries"
  ) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, face = "bold"),
        axis.text.y = element_text(face = "bold"),
        legend.position = "none")

# 1. Count unique sgRNAs per (condition, exp)
sgRNA_counts <- count_df_long %>%
  group_by(condition) %>%
  summarise(num_sgRNAs = n(), .groups = "drop") %>%
  mutate(Bin = condition)  # for x-axis

# 2. Plot
q <- ggplot(sgRNA_counts, aes(x = Bin, y = num_sgRNAs, fill = Bin)) +
  geom_col() +
  labs(
    title = paste("Number of sgRNA entries per bin", title_sufix_1),
    x = "Bin",
    y = "sgRNA entries"
  ) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, face = "bold"),
        axis.text.y = element_text(face = "bold"),
        legend.position = "none")

totals_df <- maude_counts_df %>% 
  summarise(
    input = sum(!is.na(input)),
    upper = sum(!is.na(upper)),
    lower = sum(!is.na(lower))
  ) %>% 
  pivot_longer(
    cols       = everything(),
    names_to   = "Bin",
    values_to  = "count_non_na"
  )

r <- ggplot(totals_df, aes(x = Bin, y = count_non_na, fill = Bin)) +
  geom_col() +
  labs(
    title = paste("Number of sgRNA entries per bin", title_sufix_2),
    x = "Bin",
    y = "Number of sgRNA entries"
  ) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, face = "bold"),
        axis.text.y = element_text(face = "bold"),
        legend.position = "none")

# 1. Summarise total counts per condition
totals_df <- maude_counts_df %>% 
  summarise(
    input = sum(input, na.rm=TRUE),
    upper = sum(upper, na.rm=TRUE),
    lower = sum(lower, na.rm=TRUE)
  ) %>% 
  pivot_longer(
    cols = everything(),
    names_to  = "Bin",
    values_to = "total_count"
  )

# 2. Plot
s <- ggplot(totals_df, aes(x = Bin, y = total_count, fill = Bin)) +
  geom_col() +
  labs(
    title = paste("Sum of", data_name, "per bin"),
    x     = "Bin",
    y     = "Total counts"
  ) +
  theme_bw() +
  theme(
    axis.text.x  = element_text(angle = 45, hjust = 1),
    legend.position = "none"
  )


print(q)
print(r)
print(s)
print(o)
print(p)        
plot_maude_qc(maude_counts_df)
plot_maude_qc(maude_counts_df, add_0s = TRUE)
```

## Run MAUDE and generate maude_guide_hits and maude_gene_hits

```{r run_MAUDE, eval=TRUE}

unique_exp <- unique(maude_counts_df$exp)

# Define bin stats with 10% for lower/upper each
lower_bin_end = upper_lower_percentage
upper_bin_start = 1 - upper_lower_percentage

maude_bins <- tibble(Bin = rep(c('upper', 'lower'), length(unique_exp)),  # Repeat 'upper' and 'lower' for each exp
                     exp = rep(unique_exp, each = 2),  # Repeat each exp value twice for 'upper' and 'lower'
                     binStartQ = ifelse(rep(c('upper', 'lower'), length(unique_exp)) == 'lower', 0.001, upper_bin_start),
                     binEndQ = ifelse(rep(c('upper', 'lower'), length(unique_exp)) == 'lower', lower_bin_end, 0.999),
                     fraction = binEndQ - binStartQ,
                     binStartZ = qnorm(binStartQ),
                     binEndZ = qnorm(binEndQ)) %>%
  select(Bin, binStartQ, binEndQ, fraction, binStartZ, binEndZ, exp) %>%
  as.data.frame()



if (first_time == TRUE){
  ## The input dataframe needs to have the lower, upper and input columns.
  ## use maude to calculate guide level statistics.
  maude_guide_stats <- findGuideHitsAllScreens(
    experiments = unique(maude_counts_df['exp']),
    countDataFrame = maude_counts_df,
    binStats = maude_bins,
    sortBins = c('lower', 'upper'),
    unsortedBin = 'input',
    negativeControl = 'isNontargeting'
  )
  
  saveRDS(maude_guide_stats,paste0(rds_output_folder,"MAUDE_guide_stats", file_suffix))
} else {
  maude_guide_stats <- readRDS(paste0(rds_output_folder,"MAUDE_guide_stats", file_suffix))
}


if (first_time == TRUE){
  
  maude_guide_stats <- maude_guide_stats %>%
    left_join(
      merged_sgRNA_df %>%
        select(sgrna_id, entrez) %>%
        distinct(sgrna_id, .keep_all = TRUE),
      by = c("sgRNA" = "sgrna_id")
    ) %>%
    mutate(entrez = coalesce(as.character(entrez), sgRNA))
  
  # any entries from include_controls_list are manually turned into genes
  if (length(include_controls_list) > 0) {
    for (control_gene in include_controls_list) {
      # here we remove everything after the last _, so stuff like AAVS1_9 and
      # AAVS1_13 are both treated as AAVS1
      control_gene <- sub("_[^_]*$", "", control_gene)
      maude_guide_stats$entrez[grepl(control_gene, maude_guide_stats$sgRNA)] <- control_gene
    }
  }
 
  ## calculate gene-level summarized scores
  maude_gene_stats <- getElementwiseStats(
    experiments = unique(maude_guide_stats['exp']),
    normNBSummaries = maude_guide_stats,
    negativeControl = 'isNontargeting',
    elementIDs = 'entrez'
  )
  
  # Filter out all genes with not enough guides pointing to them
  maude_gene_stats <- maude_gene_stats %>%
    filter(numGuides >= min_guides_per_gene)
  
  saveRDS(maude_gene_stats,paste0(rds_output_folder,"MAUDE_gene_stats", file_suffix))
} else {
  maude_gene_stats <- readRDS(paste0(rds_output_folder,"MAUDE_gene_stats", file_suffix))
}

maude_guide_stats <- readRDS(paste0(rds_output_folder,"MAUDE_guide_stats", file_suffix))
maude_gene_stats <- readRDS(paste0(rds_output_folder,"MAUDE_gene_stats", file_suffix))


```
## Functions that add more information to the results, like the gene symbol

```{r check_MAUDE_results, eval=TRUE}
add_info_to_gene_stats <- function(maude_guide_stats, maude_gene_stats){

  maude_guide_stats <- maude_guide_stats %>%
    left_join(
      merged_sgRNA_df %>%
        mutate(entrez = as.character(entrez)) %>% 
        select(sgrna_id, entrez, seq, symbol) %>%
        distinct(sgrna_id, .keep_all = TRUE),
      by = c("sgRNA" = "sgrna_id")
    ) %>%
    mutate(entrez = coalesce(as.character(entrez), sgRNA))
    
  maude_guide_stats <- maude_guide_stats %>%
    mutate(abs_meanZ = abs(mean)) %>%
    group_by(entrez) %>%
    slice_max(order_by = abs_meanZ, n = 1, with_ties = FALSE) %>%
    ungroup()
  
  
  maude_gene_stats <- maude_gene_stats %>%
    left_join(maude_guide_stats %>%
                select(entrez, seq, sgRNA, symbol), by = "entrez")
  
  export_df <- maude_gene_stats %>% 
    select(c(symbol, entrez, numGuides,stoufferZ,meanZ,significanceZ,p.value, FDR, seq, sgRNA)) %>% 
    arrange(significanceZ)
  
  HepG2_tpm <- readRDS("/g/steinmetz/link/Liangfu_Expression_Heatmaps/rds_files/hepato_df_tpm.rds")
  
  export_df <- export_df %>%
  left_join(
    HepG2_tpm %>%
      filter(!is.na(entrez_id)) %>%
      select(entrez_id, HepG2_TPM = HepG2, primary_hepato_TPM = primary),
    by = c("entrez" = "entrez_id")
  )
  
  return(export_df)
}

add_info_wrapper <- function(suffix,
                             folder = rds_output_folder,
                             preffix_gene = "MAUDE_gene_stats",
                             preffix_guide = "MAUDE_guide_stats"){
  gene <- readRDS(paste0(folder,preffix_gene,"_",suffix,".rds"))
  guide <- readRDS(paste0(folder,preffix_guide,"_",suffix,".rds"))
  result <- add_info_to_gene_stats(guide, gene)
  
  return(result)
}
check_UMI_counts <- function(guide_df, reference_df) {
  # Step 1: Merge reference_df's entrez column to guide_df based on matching sgRNA and sgrna_id
  guide_df <- guide_df %>%
    left_join(reference_df %>%
                select(sgrna_id, entrez), 
              by = c("sgRNA" = "sgrna_id"))
  
  # Step 2: Group by unique combinations of sublib and sample
  result_df <- guide_df %>%
    group_by(sublib, sample) %>%
    summarise(
      input_sum = sum(input, na.rm = TRUE),
      lower_sum = sum(lower, na.rm = TRUE),
      upper_sum = sum(upper, na.rm = TRUE),
      .groups = "drop"
    )
  
  # Return the result as a dataframe
  return(result_df)
}
```


## Generate Waterfall plots for the data
```{r Waterfall_plot, eval=FALSE}
Hits_current_settings <- add_info_wrapper(file_info_suffix)
if (length(include_controls_list) > 0) {
  for (control_gene in include_controls_list) {
    # here we remove everything after the last _, so stuff like AAVS1_9 and
    # AAVS1_13 are both treated as AAVS1
    control_gene <- sub("_[^_]*$", "", control_gene)
    Hits_current_settings$symbol[grepl(control_gene, Hits_current_settings$entrez)] <- control_gene
  }
  # Filter out rows where the 'symbol' is in the include_controls_list
  Hits_current_settings_no_controls <- Hits_current_settings %>% 
    filter(!symbol %in% include_controls_list | is.na(symbol))
}

plot_significance_by_rank <- function(Hits_df,
                                      mark_cntrl = TRUE,
                                      mark_special = NULL,
                                      mark_N_top_hits = 0,
                                      box_padding = 0.8,
                                      no_text = FALSE,
                                      signif_lines = FALSE,
                                      mark_all_signif_level = NULL) {
  # Create rank column
  Hits_df <- Hits_df %>%
    mutate(rank = rank(significanceZ, ties.method = "first"))
  
  # Define the Limits for my two label boxes
  y_min   <- min(Hits_df$significanceZ, na.rm = TRUE)
  y_max   <- max(Hits_df$significanceZ, na.rm = TRUE)
  y_range <- y_max - y_min
  
  # Box geometry (relative to overall range)
  box_height <- 0.06 * y_range   # 8% of range high
  box_gap    <- 0.02 * y_range   # 3% of range between boxes
  
  # Centers of the two boxes (on y-axis)
  y_center1 <- y_min           # lower box
  y_center2 <- y_center1 + box_height + box_gap    # upper box
  
  # x range (can reuse for both boxes)
  x_min_box <- max(Hits_df$rank) - 3000
  x_max_box <- max(Hits_df$rank) + 500
  
  # Start base plot
  p <- ggplot(Hits_df, aes(x = rank, y = significanceZ)) +
    geom_point(color = "lightgrey", size = 1) +
    geom_hline(yintercept = 0, linetype = "dashed", color = "black", size = 0.3) +
    theme_bw() +
    labs(
      x = "Gene rank",
      y = "Significance Z-score",
      title = "Significance Z-score by gene rank"
    )

  # Mark control (NA in symbol column)
  if (mark_cntrl && "symbol" %in% names(Hits_df)) {
    p <- p + geom_point(
      data = Hits_df %>% filter(is.na(symbol)),
      aes(x = rank, y = significanceZ),
      color = "blue", size = 1.5
    ) +
      annotate("rect",
               xmin = x_min_box,
               xmax = x_max_box,
               ymin = y_center2 - box_height / 2,
               ymax = y_center2 + box_height / 2,
               fill = "white", color = "black", size = 0.3) +
      annotate("point",
               x = x_min_box + 200,
               y = y_center2,
               color = "blue", size = 2) +
      annotate("text",
               x = x_min_box + 400,
               y = y_center2,
               label = "Control sgRNA", hjust = 0, size = 3)
  }

  if (!is.null(mark_all_signif_level)) {
    signif_df <- Hits_df %>%
      filter(FDR <= mark_all_signif_level)
    signif_label_text <- paste0("Hits: FDR <= ",mark_all_signif_level*100,"%")
    
    if (nrow(signif_df) > 0) {
      # Highlight significant points
      p <- p +
        geom_point(
          data = signif_df,
          aes(x = rank, y = significanceZ),
          color = "red",
          size = 1.5
        ) +
        annotate("rect",
                 xmin = x_min_box,
                 xmax = x_max_box,
                 ymin = y_center1 - box_height / 2,
                 ymax = y_center1 + box_height / 2,
                 fill = "white", color = "black", size = 0.3) +
        annotate("point",
                 x = x_min_box + 200,
                 y = y_center1,
                 color = "red", size = 2) +
        annotate("text",
                 x = x_min_box + 400,
                 y = y_center1,
                 label = signif_label_text, hjust = 0, size = 3)
    }
  
      # Add lines if requested
      if (isTRUE(signif_lines)) {
  
        ## Lowest positive significanceZ (closest to zero, > 0)
        pos_df <- signif_df %>% filter(significanceZ > 0)
        if (nrow(pos_df) > 0) {
          y_pos <- min(pos_df$significanceZ, na.rm = TRUE)
          p <- p +
            geom_hline(
              yintercept = y_pos,
              linetype = "dashed",
              color = "red",
              size = 0.3
            )
        }
  
        ## Negative significanceZ with smallest absolute value (closest to zero)
        neg_df <- signif_df %>% filter(significanceZ < 0)
        if (nrow(neg_df) > 0) {
          # largest negative value, e.g. -1 is "closer to zero" than -3
          y_neg <- max(neg_df$significanceZ, na.rm = TRUE)
          p <- p +
            geom_hline(
              yintercept = y_neg,
              linetype = "dashed",
              color = "red",
              size = 0.3
            )
        }
      }
    }
  

  # Mark top hits (both ends), excluding special symbols
  if (mark_N_top_hits >= 1 && "symbol" %in% names(Hits_df)) {
    top_hits_df <- Hits_df %>%
      filter(!(symbol %in% mark_special)) %>%  # exclude special symbol
      arrange(significanceZ) %>%
      slice(c(1:mark_N_top_hits, (n() - mark_N_top_hits + 1):n()))
    
    top_hits_pos <- top_hits_df %>% filter(significanceZ >= 0)
    top_hits_neg <- top_hits_df %>% filter(significanceZ < 0)
    
    if (no_text == TRUE){
      p <- p +
        geom_point(data = top_hits_df, aes(x = rank, y = significanceZ),
                   color = "red", size = 1.5)
    } else {
      p <- p +
        geom_point(data = top_hits_df, aes(x = rank, y = significanceZ),
                   color = "red", size = 1.5) +
        geom_text_repel(
          data = top_hits_df,
          aes(x = rank, y = significanceZ, label = symbol),
          color = "red",           # or "orange" for special symbol
          size = 3,
          box.padding = box_padding,       # space around the label box
          point.padding = 0.6,     # space around the point
          force = 10,               # strength of repulsion between labels
          force_pull = 0.5,          # how strongly labels are pulled back to points
          max.overlaps = Inf,      # allow all overlaps to be considered
          max.time = 5,           # more time for optimization
          min.segment.length = 0,
          segment.color = "red",# line color from label to point
          segment.size = 0.3       # line thickness
        )
    }
  }
    # Mark special symbols (can be multiple)
  if (!is.null(mark_special) && length(mark_special) > 0 && "symbol" %in% names(Hits_df)) {
    special_df <- Hits_df %>% filter(symbol %in% mark_special)
    
    if (nrow(special_df) > 0) {
      p <- p +
        geom_point(
          data = special_df,
          aes(x = rank, y = significanceZ),
          shape = 17,
          color = "orange",
          size = 4
        ) +
        geom_text_repel(
          data = special_df,
          aes(x = rank, y = significanceZ, label = symbol),
          color = "orange",
          size = 4,
          box.padding = 1,
          nudge_x = ifelse(special_df$significanceZ > 0, -500, 500),
          nudge_y = ifelse(special_df$significanceZ > 0, y_range * (0.05), y_range * (-0.05)),
          force = 4
        )
    }
  }
  return(p)
}
# Basic plot
plot_significance_by_rank(Hits_current_settings)

# Mark a special gene and top 10 hits
plot_significance_by_rank(Hits_current_settings,
                          mark_special = "EGFP",
                          mark_cntrl = FALSE,
                          mark_all_signif_level = 0.05,
                          signif_lines = TRUE,
                          box_padding = 0.6)

plot_significance_by_rank(Hits_current_settings_no_controls,
                          mark_special = c("AHSA1","AGO2"),
                          mark_all_signif_level = 0.05,
                          mark_cntrl = FALSE,
                          signif_lines = TRUE,
                          mark_N_top_hits = 3,
                          box_padding = 0.6)

plot_significance_by_rank(Hits_current_settings,
                          mark_special = "AHSA1",
                          mark_N_top_hits = 3,
                          box_padding = 0.6,
                          no_text = TRUE)
# Just highlight controls
plot_significance_by_rank(Hits_current_settings, mark_cntrl = TRUE)
plot_significance_by_rank(export_df, mark_cntrl = TRUE, mark_N_top_hits = 3, box_padding = 0.9)
```

# Combine replicas if auto_combine_repicates is set to TRUE

``` {r auto_combine_replicates, eval=TRUE}
if (auto_combine_replicates){
  # if we have replicates, handle them now
  if (length(unique(maude_gene_stats$exp)) > 1){
    genes_with_rep <- add_info_wrapper(file_info_suffix)
  
    export_df <- genes_with_rep %>%
      group_by(symbol, entrez) %>%
      summarise(
        numGuides = sum(numGuides, na.rm = TRUE),
        seq       = first(seq),
        sgRNA     = first(sgRNA),
        meanZ     = mean(meanZ, na.rm = TRUE),
  
        # Stouffer’s method (equal weights); use count of non-NA Zs in the denominator
        stoufferZ = sum(significanceZ, na.rm = TRUE) /
                    sqrt(sum(!is.na(significanceZ))),
        # For clarity: final significance Z = stoufferZ
        significanceZ = stoufferZ,
        
        .groups = "drop"
      ) %>%
      mutate(
        # two-sided p from Stouffer Z
        p.value = 2 * pnorm(abs(stoufferZ), lower.tail = FALSE),
        FDR     = p.adjust(p.value, method = "BH")
      )
    export_df <- export_df %>%
      select(symbol, entrez, numGuides, stoufferZ, meanZ, significanceZ, p.value, FDR, seq, sgRNA)
  } else {
    print("No replicates present, skipping replicate combination")
    export_df <- add_info_wrapper(file_info_suffix)
  }
} else {
  export_df <- add_info_wrapper(file_info_suffix)
}

if (length(include_controls_list) > 0) {
  for (control_gene in include_controls_list) {
    export_df$symbol[export_df$entrez == control_gene] <- control_gene
  }
}

```

# Export the Data as CSV and excel file

``` {r basic_export, eval=TRUE}

# Write to Excel
csv_file_path <- sub(".rds",".csv",paste0(results_output_folder, "/", "MAUDE_Hits", file_suffix))
write_csv(export_df, csv_file_path)
excel_file_path <- sub("\\.rds$", ".xlsx", paste0(results_output_folder, "/", "MAUDE_Hits", file_suffix))
write_xlsx(export_df, excel_file_path)
```


